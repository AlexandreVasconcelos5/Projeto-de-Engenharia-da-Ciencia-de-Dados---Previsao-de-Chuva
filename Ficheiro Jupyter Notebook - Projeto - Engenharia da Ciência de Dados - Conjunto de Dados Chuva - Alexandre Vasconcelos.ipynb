{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9e27e4",
   "metadata": {},
   "source": [
    "<H3>DaSh: Engenharia da Ciência de Dados</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02265f",
   "metadata": {},
   "source": [
    "- Alexandre Vaz Marques Vasconcelos - alex-0.5@hotmail.com\n",
    "- Conjunto de Dados - Chuva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1c359",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f90b1d",
   "metadata": {},
   "source": [
    "<H4>1. Parte 1 - Perfilamento dos Dados:</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741ed06",
   "metadata": {},
   "source": [
    "<H5>1.1. Carregamento dos Dados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv(\"weatherAUS.csv\")\n",
    "\n",
    "#Resultados - Mostrar os 5 Primeiros Registos:\n",
    "conjunto_dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e786cd0",
   "metadata": {},
   "source": [
    "<H5>1.2. Tradução dos Dados de Inglês para Português:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c97bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Módulo para Operações no Sistema Operativo:\n",
    "import os\n",
    "\n",
    "#Definir o Nome Original do Conjunto de Dados:\n",
    "nome_original = 'weatherAUS.csv'\n",
    "\n",
    "#Definir o Nome Final do Conjunto de Dados:\n",
    "nome_final = 'conjunto_dados_meteorologia_austrália.csv'\n",
    "\n",
    "#Renomear o Conjunto de Dados:\n",
    "os.rename(nome_original, nome_final)\n",
    "print(f'O Conjunto de Dados foi Renomeado de {nome_original} para {nome_final}')\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv(nome_final)\n",
    "\n",
    "#Guardar o Conjunto de Dados Original:\n",
    "conjunto_dados.to_csv('weatherAUS.csv', index=False)\n",
    "print('\\nO Conjunto de Dados Original Foi Guardado com Sucesso como weatherAUS.csv')\n",
    "\n",
    "#Dicionário das Traduções - Inglês para Português:\n",
    "dicionario_traducoes = {'Date': 'Data',\n",
    "                        'Location': 'Localizacao',\n",
    "                        'MinTemp': 'Temperatura_Minima',\n",
    "                        'MaxTemp': 'Temperatura_Maxima',\n",
    "                        'Rainfall': 'Precipitacao',\n",
    "                        'Evaporation': 'Evaporacao',\n",
    "                        'Sunshine': 'Sol',\n",
    "                        'WindGustDir': 'Direcao_Rajada_Vento',\n",
    "                        'WindGustSpeed': 'Velocidade_Rajada_Vento',\n",
    "                        'WindDir9am': 'Direcao_Vento_09h',\n",
    "                        'WindDir3pm': 'Direcao_Vento_15h',\n",
    "                        'WindSpeed9am': 'Velocidade_Vento_09h',\n",
    "                        'WindSpeed3pm': 'Velocidade_Vento_15h',\n",
    "                        'Humidity9am': 'Humidade_09h',\n",
    "                        'Humidity3pm': 'Humidade_15h',\n",
    "                        'Pressure9am': 'Pressao_Atmosferica_09h',\n",
    "                        'Pressure3pm': 'Pressao_Atmosferica_15h',\n",
    "                        'Cloud9am': 'Nuvens_09h',\n",
    "                        'Cloud3pm': 'Nuvens_15h',\n",
    "                        'Temp9am': 'Temperatura_09h',\n",
    "                        'Temp3pm': 'Temperatura_15h',\n",
    "                        'RainToday': 'Chuva_Hoje',\n",
    "                        'RainTomorrow': 'Chuva_Amanha'}\n",
    "\n",
    "#Traduzir os Nomes das Variáveis e dos Valores de Inglês para Português:\n",
    "conjunto_dados = conjunto_dados.rename(columns=dicionario_traducoes).replace({'Yes': 'Sim', 'No': 'Nao'})\n",
    "\n",
    "#Resultados - Guardar o Conjunto de Dados Traduzido:\n",
    "conjunto_dados.to_csv(nome_final, index=False)\n",
    "print(f'\\nO Conjunto de Dados Traduzido Foi Guardado com Sucesso como {nome_final}')\n",
    "\n",
    "#Resultados - Mostrar os 5 Primeiros Registos:\n",
    "conjunto_dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be8b5e",
   "metadata": {},
   "source": [
    "<H5>1.3. Dimensionalidade:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bb420",
   "metadata": {},
   "source": [
    "<H5>1.3.1. Número de Registos vs Número de Variáveis:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf701e",
   "metadata": {},
   "source": [
    "<H5>1.3.1.1. Número de Registos vs Número de Variáveis - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff599f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Calcular o Número de Registos do Conjunto de Dados:\n",
    "numero_registos_conjunto_dados = \"{:,}\".format(conjunto_dados.shape[0]).replace(\",\", \".\")\n",
    "\n",
    "#Calcular o Número de Variáveis do Conjunto de Dados:\n",
    "numero_variaveis_conjunto_dados = \"{:,}\".format(conjunto_dados.shape[1]).replace(\",\", \".\")\n",
    "\n",
    "#Resultados - Número de Registos e Número de Variáveis do Conjunto de Dados:\n",
    "print(f\"Número de Registos do Conjunto de Dados: {numero_registos_conjunto_dados}\")\n",
    "print(f\"\\nNúmero de Variáveis do Conjunto de Dados: {numero_variaveis_conjunto_dados}\")\n",
    "print(f\"\\nNúmero de Registos vs Número de Variáveis do Conjunto de Dados: ({numero_registos_conjunto_dados}, {numero_variaveis_conjunto_dados})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d2210",
   "metadata": {},
   "source": [
    "<H5>1.3.1.2. Número de Registos vs Número de Variáveis - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Obter o Número de Registos do Conjunto de Dados:\n",
    "numero_registos_conjunto_dados = conjunto_dados.shape[0]\n",
    "\n",
    "#Obter o Número de Variáveis do Conjunto de Dados:\n",
    "numero_variaveis_conjunto_dados = conjunto_dados.shape[1]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Figura - Tamanho:\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "#Configurações do Gráfico de Barras - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "plt.title(\"Conjunto de Dados 1 - Número de Registos vs Número de Variáveis\", color='black', fontsize=16, pad=20)\n",
    "\n",
    "#Criar o Gráfico de Barras - Configurações das Barras - Títulos, Cores e Sobreposição:\n",
    "grafico_barras = plt.bar(['Número de Registos', 'Número de Variáveis'], [numero_registos_conjunto_dados, numero_variaveis_conjunto_dados], color='#2ca02c', edgecolor='#2ca02c', zorder=2)\n",
    "\n",
    "#Obter o Eixo Atual:\n",
    "eixo_atual = plt.gca()\n",
    "\n",
    "#Configurações do Gráfico de Barras - Fundo - Cor:\n",
    "eixo_atual.set_facecolor('white')\n",
    "\n",
    "#Configurações do Gráfico de Barras - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Iterar sobre cada Barra do Gráfico:\n",
    "for barra in grafico_barras:\n",
    "\n",
    "    #Obter a Altura da Barra:\n",
    "    altura_barra = barra.get_height()\n",
    "    \n",
    "    #Configurações das Barras - Valores - Posição, Cor e Tamanho:\n",
    "    plt.text(barra.get_x() + barra.get_width() / 2, altura_barra, f\"{altura_barra:,.0f}\".replace(\",\", \".\"), ha='center', va='bottom', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Título - Cor e Tamanho:\n",
    "plt.xlabel('', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor, Tamanho e Rotação:\n",
    "plt.xticks(color='black', fontsize=14, rotation=0)\n",
    "\n",
    "#Configurações do Eixo X - Desativar as Linhas de Grelha:\n",
    "eixo_atual.xaxis.grid(False)\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "plt.ylabel('Valor', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Valores dos Marcadores - Limites Mínimo e Máximo e Intervalo:\n",
    "eixo_atual.set_yticks(range(0, 160001, 20000))\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Limites Mínimo e Máximo e Intervalo:\n",
    "eixo_atual.set_yticklabels([f\"{valor:,.0f}\".replace(\",\", \".\") for valor in range(0, 160001, 20000)])\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Tamanho:\n",
    "eixo_atual.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Linhas de Grelha - Cor, Espessura e Sobreposição:\n",
    "eixo_atual.yaxis.grid(True, color='gray', linewidth=0.5, zorder=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixo_atual.spines[margem].set_color('black')\n",
    "    eixo_atual.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "#Ocultar as Margens Superior e Direita:\n",
    "eixo_atual.spines['top'].set_visible(False)\n",
    "eixo_atual.spines['right'].set_visible(False)\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f54fab",
   "metadata": {},
   "source": [
    "<H5>1.3.2. Tipos de Variáveis:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8d72d",
   "metadata": {},
   "source": [
    "<H5>1.3.2.1. Tipos de Variáveis - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff0c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Resultados - Tipos de Variáveis do Conjunto de Dados:\n",
    "print('Tipos de Variáveis do Conjunto de Dados:')\n",
    "conjunto_dados.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb197a9b",
   "metadata": {},
   "source": [
    "<H5>1.3.2.2. Tipos de Variáveis - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Tipos de Variáveis:\n",
    "tipos_variaveis = ['Variáveis Numéricas', 'Variáveis Simbólicas', 'Variáveis Binárias', 'Variáveis Temporais']\n",
    "\n",
    "#Quantidades dos Tipos de Variáveis:\n",
    "quantidades_tipos_variaveis = [16, 4, 2, 1]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Figura - Tamanho:\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "#Configurações do Gráfico de Barras - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "plt.title(\"Conjunto de Dados 1 - Número de Variáveis por Tipo\", color='black', fontsize=16, pad=10)\n",
    "\n",
    "#Configurações das Barras - Cores:\n",
    "cores_barras = ['#2ca02c', '#ff7f0e', '#ffdd57', 'skyblue']\n",
    "\n",
    "#Criar o Gráfico de Barras - Configurações das Barras - Espessura e Sobreposição:\n",
    "grafico_barras = plt.bar(range(len(tipos_variaveis)), quantidades_tipos_variaveis, color=cores_barras, edgecolor=cores_barras, width=0.4, zorder=2)\n",
    "\n",
    "#Obter o Eixo Atual:\n",
    "eixo_atual = plt.gca()\n",
    "\n",
    "#Configurações do Gráfico de Barras - Fundo - Cor:\n",
    "eixo_atual.set_facecolor('white')\n",
    "\n",
    "#Configurações do Gráfico de Barras - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Iterar sobre cada Barra do Gráfico:\n",
    "for barra in grafico_barras:\n",
    "    \n",
    "    #Obter a Altura da Barra:\n",
    "    altura_barra = barra.get_height()\n",
    "    \n",
    "    #Configurações das Barras - Valores - Altura, Posição, Cor, Tamanho e Sobreposição:\n",
    "    plt.text(barra.get_x() + barra.get_width() / 2, altura_barra, f'{altura_barra:,.0f}'.replace(',', '.'), ha='center', va='bottom', color='black', fontsize=14, zorder=3)\n",
    "\n",
    "#Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "plt.xlabel(\"Variáveis por Tipo\", color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "plt.xticks(range(len(tipos_variaveis)), tipos_variaveis, color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo X - Desativar as Linhas de Grelha:\n",
    "eixo_atual.xaxis.grid(False)\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "plt.ylabel(\"Número de Variáveis\", color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "plt.yticks(color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "plt.ylim(0, 18)\n",
    "\n",
    "#Configurações do Eixo Y - Linhas de Grelha - Cor, Espessura e Sobreposição:\n",
    "eixo_atual.yaxis.grid(True, color='gray', linewidth=0.5, zorder=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixo_atual.spines[margem].set_color('black')\n",
    "    eixo_atual.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "#Ocultar as Margens Superior e Direita:\n",
    "eixo_atual.spines['top'].set_visible(False)\n",
    "eixo_atual.spines['right'].set_visible(False)\n",
    "\n",
    "#Resultados - Mostrar o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f4ef4",
   "metadata": {},
   "source": [
    "<H5>1.3.3. Valores Omissos:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66799ee",
   "metadata": {},
   "source": [
    "<H5>1.3.3.1. Valores Omissos - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Contar o Número de Valores Omissos para cada variavel:\n",
    "numero_valores_omissos_variavel = conjunto_dados.isnull().sum()\n",
    "\n",
    "#Calcular o Número Total de Valores Omissos no Conjunto de Dados:\n",
    "numero_total_valores_omissos_conjunto_dados = numero_valores_omissos_variavel.sum()\n",
    "\n",
    "#Título - variavel | Número de Valores Omissos:\n",
    "print(f'{\"variavel:\":<30}{\"Número de Valores Omissos:\\n\"}')\n",
    "\n",
    "#Iterar Sobre as Variáveis e os seus Valores Omissos:\n",
    "for variavel, numero_valores_omissos_variavel in numero_valores_omissos_variavel.items():\n",
    "\n",
    "    #Resultados - Número de Valores Omissos por variavel:\n",
    "    print(f'{variavel:<30}{numero_valores_omissos_variavel:,.0f}'.replace(\",\", \".\"))\n",
    "\n",
    "#Resultados - Número Total de Valores Omissos no Conjunto de Dados:\n",
    "print(f'\\nNúmero Total de Valores Omissos no Conjunto de Dados: {numero_total_valores_omissos_conjunto_dados:,.0f}'.replace(\",\", \".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda7b790",
   "metadata": {},
   "source": [
    "<H5>1.3.3.2. Valores Omissos - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2534e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Calcular o Número Total de Valores Omissos para todas as Variáveis:\n",
    "numero_total_valores_omissos_variaveis = conjunto_dados.isna().sum()[conjunto_dados.isna().sum() > 0].to_dict()\n",
    "\n",
    "#Configurações do Gráfico de Barras - Figura - Tamanho:\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "#Configurações do Gráfico de Barras - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "plt.title(\"Conjunto de Dados 1 - Número de Valores Omissos por variavel\", color='black', fontsize=16, pad=20)\n",
    "\n",
    "#Configurações do Gráfico de Barras - Margens Superior, Direita, Inferior e Esquerda:\n",
    "plt.subplots_adjust(top=0.9, right=0.95, bottom=0.35, left=0.15)\n",
    "\n",
    "#Obter o Eixo Atual:\n",
    "eixo_atual = plt.gca()\n",
    "\n",
    "#Configurações do Gráfico de Barras - Fundo - Cor:\n",
    "eixo_atual.set_facecolor('white')\n",
    "\n",
    "#Configurações das Barras - Posições:\n",
    "posicoes_barras = range(len(numero_total_valores_omissos_variaveis))\n",
    "\n",
    "#Criar o Gráfico de Barras - Cores, Espessura e Sobreposição:\n",
    "grafico_barras = plt.bar(posicoes_barras, list(numero_total_valores_omissos_variaveis.values()), color='#2ca02c', edgecolor='#2ca02c', width=0.6, zorder=3)\n",
    "\n",
    "#Iterar sobre cada Barra do Gráfico:\n",
    "for barra in grafico_barras:\n",
    "    \n",
    "    #Obter a Altura da Barra:\n",
    "    altura_barra = barra.get_height()\n",
    "    \n",
    "    #Configurações das Barras - Valores - Posição, Cor e Tamanho:\n",
    "    plt.text(barra.get_x() + barra.get_width() / 2, altura_barra, f'{altura_barra:,.0f}'.replace(',', '.'), ha='center', va='bottom', color='black', fontsize=11)\n",
    "\n",
    "#Configurações do Eixo X - Título - Designação, Cor, Tamanho e Espaçamento:\n",
    "plt.xlabel(\"Variáveis com Valores Omissos\", color='black', fontsize=14, labelpad=15)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor, Tamanho e Rotação:\n",
    "plt.xticks(posicoes_barras, list(numero_total_valores_omissos_variaveis.keys()), color='black', fontsize=11, rotation=45)\n",
    "\n",
    "#Configurações do Eixo X - Desativar as Linhas de Grelha:\n",
    "eixo_atual.xaxis.grid(False)\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "plt.ylabel(\"Número de Valores Omissos\", color='black', fontsize=11)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "plt.yticks(color='black', fontsize=11)\n",
    "\n",
    "#Definir Função para Formatar os Valores do Eixo Y:\n",
    "def funcao_formatar_valores_eixo_Y(valores_Y, posição=None):\n",
    "    \n",
    "    #Formatar os Valores do Eixo Y:\n",
    "    return f'{int(valores_Y):,}'.replace(',', '.')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Formatação:\n",
    "eixo_atual.yaxis.set_major_formatter(plt.FuncFormatter(funcao_formatar_valores_eixo_Y))\n",
    "\n",
    "#Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "eixo_atual.set_ylim(0, 70000)\n",
    "\n",
    "#Configurações do Eixo Y - Linhas de Grelha - Cor, Espessura e Sobreposição:\n",
    "eixo_atual.yaxis.grid(True, color='gray', linewidth=0.5, zorder=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixo_atual.spines[margem].set_color('black')\n",
    "    eixo_atual.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "#Ocultar as Margens Superior e Direita:\n",
    "eixo_atual.spines['top'].set_visible(False)\n",
    "eixo_atual.spines['right'].set_visible(False)\n",
    "\n",
    "#Resultados - Mostrar o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcb338",
   "metadata": {},
   "source": [
    "<H5>1.4. Distribuição dos Dados:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda57ff",
   "metadata": {},
   "source": [
    "<H5>1.4.1. Diagramas de Caixa e Bigodes:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bff0a7",
   "metadata": {},
   "source": [
    "<H5>1.4.1.1. Diagramas de Caixa e Bigodes Globais das Variáveis Numéricas - Gráfico:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546407da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#A partir do Módulo Funções do DSLabs, Importar a Função Obter Tipos de Variáveis:\n",
    "from dslabs_functions import get_variable_types\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Configurações da Figura - Tamanho:\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "#Obter a Lista de Tipos de Variáveis do Conjunto de Dados:\n",
    "lista_tipos_variaveis_conjunto_dados = get_variable_types(conjunto_dados)\n",
    "\n",
    "#Obter as Variáveis Numéricas da Lista de Tipos de Variáveis do Conjunto de Dados:\n",
    "variaveis_numericas = lista_tipos_variaveis_conjunto_dados.get(\"numeric\", [])\n",
    "\n",
    "#Se Existirem Variáveis Numéricas:\n",
    "if variaveis_numericas:\n",
    "    \n",
    "    #Configurações da Figura - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "    plt.title(\"Conjunto de Dados 1 - Diagramas de Caixa e Bigodes Globais para as Variáveis Numéricas\", color='black', fontsize=16, pad=20)\n",
    "    \n",
    "    #Configurações da Figura - Margens Superior, Direita, Inferior e Esquerda:\n",
    "    plt.subplots_adjust(top=0.9, right=0.95, bottom=0.35, left=0.15, )\n",
    "\n",
    "    #Obter o Eixo Atual:\n",
    "    eixo_atual = plt.gca()\n",
    "    \n",
    "    #Configurações da Figura - Fundo - Cor:\n",
    "    eixo_atual.set_facecolor('white')\n",
    "\n",
    "    #Criar os Diagramas de Caixa e Bigodes Globais das Variáveis Numéricas - Configurações da Caixa, Valores Atípicos, Mediana, Limites e Bigodes - Cores e Tamanho:\n",
    "    conjunto_dados[variaveis_numericas].boxplot(rot=45, boxprops=dict(facecolor='#2ca02c', edgecolor='#2ca02c'), flierprops=dict(marker='o',\n",
    "                                                      markerfacecolor='#2ca02c', markeredgecolor='#2ca02c', markersize=5), medianprops=dict(color='#ff7f0e'),\n",
    "                                                      capprops=dict(color='black'), whiskerprops=dict(color='black'))\n",
    "\n",
    "    #Configurações do Eixo X - Título - Designação, Cor, Tamanho e Espaçamento:\n",
    "    plt.xlabel(\"Variáveis Numéricas\", color='black', fontsize=14, labelpad=15)\n",
    "    \n",
    "    #Configurações do Eixo X - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "    eixo_atual.tick_params(axis='x', colors='black', labelsize=12)\n",
    "    \n",
    "    #Configurações do Eixo X - Desativar as Linhas de Grelha:\n",
    "    eixo_atual.xaxis.grid(False)\n",
    "    \n",
    "    #Configurações do Eixo Y - Título - Designação, Cor, Tamanho e Espaçamento:\n",
    "    plt.ylabel(\"Valor da variavel\", color='black', fontsize=14, labelpad=15)\n",
    "    \n",
    "    #Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "    eixo_atual.tick_params(axis='y', colors='black', labelsize=14)\n",
    "    \n",
    "    #Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "    eixo_atual.set_ylim(-200, 1200)\n",
    "    \n",
    "    #Configurações do Eixo Y - Linhas de Grelha - Cor, Estilo de Linha, Espessura e Sobreposição:\n",
    "    eixo_atual.yaxis.grid(True, color='gray', linestyle='-', linewidth=0.5, zorder=0)\n",
    "    \n",
    "    #Definir Função para Formatar os Valores do Eixo Y:\n",
    "    def funcao_formatar_valores_eixo_Y(valores_Y, posição=None):\n",
    "\n",
    "        #Formatar os Valores do Eixo Y:\n",
    "        return f\"{int(valores_Y):,}\".replace(\",\", \".\")\n",
    "    \n",
    "    #Configurações do Eixo Y - Rótulos dos Marcadores - Formatação:\n",
    "    eixo_atual.yaxis.set_major_formatter(FuncFormatter(funcao_formatar_valores_eixo_Y))\n",
    "\n",
    "    #Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "    for margem in ['bottom', 'left']:\n",
    "        eixo_atual.spines[margem].set_color('black')\n",
    "        eixo_atual.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "    #Resultados - Mostrar os Diagramas de Caixa e Bigodes Globais das Variáveis Numéricas:\n",
    "    plt.show()\n",
    "\n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Não Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f36285",
   "metadata": {},
   "source": [
    "<H5>1.4.1.2. Diagramas de Caixa e Bigodes Individuais para as Variáveis Numéricas - Gráficos:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98379eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Pyplot da Biblioteca Matplotlib, Importar as Funções Mostrar, Subgráficos e Ajustar os Subgráficos:\n",
    "from matplotlib.pyplot import show, subplots, subplots_adjust\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar Função Obter Tipos de Variáveis:\n",
    "from dslabs_functions import get_variable_types\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Obter os Tipos de Variáveis do Conjunto de Dados:\n",
    "tipos_variaveis_conjunto_dados = get_variable_types(conjunto_dados)\n",
    "\n",
    "#Filtrar as Variáveis Numéricas do Dicionário de Tipos de Variáveis:\n",
    "dicionario_variaveis_numericas = tipos_variaveis_conjunto_dados[\"numeric\"]\n",
    "\n",
    "#Verificar se Existem Variáveis Numéricas no Dicionário de Tipos de Variáveis:\n",
    "if dicionario_variaveis_numericas:\n",
    "\n",
    "    #Definir o Número de Colunas:\n",
    "    numero_colunas = 4\n",
    "    \n",
    "    #Calcular o Número de Linhas:\n",
    "    numero_linhas = (len(dicionario_variaveis_numericas) + numero_colunas - 1) // numero_colunas\n",
    "\n",
    "    #Definir a Altura do Diagrama de Caixa e Bigodes:\n",
    "    altura_diagrama_caixa_bigodes = 5\n",
    "\n",
    "    #Definir o Comprimento do Eixo Horizontal:\n",
    "    comprimento_eixo_horizontal = altura_diagrama_caixa_bigodes * 2\n",
    "\n",
    "    #Definir a Altura do Eixo Vertical:\n",
    "    altura_eixo_vertical = altura_diagrama_caixa_bigodes * 2\n",
    "\n",
    "    #Criar a Figura e a Matriz dos Diagramas de Caixa e Bigodes Individuais para as Variáveis Numéricas:\n",
    "    figura, matriz_diagramas_caixa_bigodes = subplots(numero_linhas, numero_colunas, figsize=(numero_colunas * comprimento_eixo_horizontal, numero_linhas * altura_eixo_vertical), squeeze=False)\n",
    "\n",
    "    #Configurações da Figura - Título Geral - Designação, Cor, Tamanho e Posição Vertical:\n",
    "    figura.suptitle(\"Conjunto de Dados 1 - Diagramas de Caixa e Bigodes Individuais para as Variáveis Numéricas\", color='black', fontsize=36, y=0.98)\n",
    "    \n",
    "    #Configurações da Figura - Margens Superior, Direita, Inferior e Esquerda:\n",
    "    subplots_adjust(top=0.9, right=0.95, bottom=0.15, left=0.15)\n",
    "\n",
    "    #Configurações dos Diagramas de Caixa e Bigodes - Espaçamentos Horizontal e Vertical:\n",
    "    subplots_adjust(wspace=1.5, hspace=0.4)\n",
    "\n",
    "    #Iterar Sobre as Variáveis Numéricas no Dicionário de Tipos de Variáveis:\n",
    "    for indice_variavel_numerica, valor_variavel_numerica in enumerate(dicionario_variaveis_numericas):\n",
    "\n",
    "        #Calcular a Posição (Linha e Coluna) de uma variavel Numérica na Matriz de Diagramas de Caixa e Bigodes:\n",
    "        linha, coluna = divmod(indice_variavel_numerica, numero_colunas)\n",
    "\n",
    "        #Configurações dos Diagramas de Caixa e Bigodes - Título - Designação, Cor e Tamanho:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].set_title(f\"Diagrama de Caixa e Bigodes para a variavel {valor_variavel_numerica}\", color='black', fontsize=20)\n",
    "\n",
    "        #Criar os Diagramas de Caixa e Bigodes - Configurações da Caixa, Valores Atípicos, Mediana, Limites e Bigodes - Cores e Tamanho:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].boxplot(conjunto_dados[valor_variavel_numerica].dropna().values, boxprops=dict(facecolor='#2ca02c', edgecolor='#2ca02c'),\n",
    "                                           flierprops=dict(marker='o', markerfacecolor='#2ca02c', markeredgecolor='#2ca02c', markersize=5), medianprops=dict(color='#ff7f0e'),\n",
    "                                           capprops=dict(color='black'), whiskerprops=dict(color='black'))\n",
    "\n",
    "        #Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].set_xlabel(f\"variavel Numérica {valor_variavel_numerica}\", color='black', fontsize=20)\n",
    "\n",
    "        #Configurações do Eixo X - Rótulos dos Marcadores - Cor:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].tick_params(axis='x', colors='black')\n",
    "\n",
    "        #Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].set_ylabel(\"Valor\", color='black', fontsize=20)\n",
    "\n",
    "        #Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].tick_params(axis='y', colors='black', labelsize=14)\n",
    "\n",
    "        #Configurações do Eixo Y - Valores dos Rótulos - Formatação:\n",
    "        matriz_diagramas_caixa_bigodes[linha, coluna].yaxis.set_major_formatter(FuncFormatter(lambda valor, _: f\"{int(valor):,}\".replace(\",\", \".\")))\n",
    "\n",
    "        #Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "        for margem in ['bottom', 'left']:\n",
    "            matriz_diagramas_caixa_bigodes[linha, coluna].spines[margem].set_color('black')\n",
    "            matriz_diagramas_caixa_bigodes[linha, coluna].spines[margem].set_linewidth(2.5)\n",
    "\n",
    "    #Iterar sobre os indices no Dicionário das Variáveis Numéricas:\n",
    "    for indice_dicionario_variaveis_numericas in range(len(dicionario_variaveis_numericas), numero_linhas * numero_colunas):\n",
    "        \n",
    "        #Calcular a Posição (Linha e Coluna) dos Subgráficos Não Utilizados na Matriz de Diagramas de Caixa e Bigodes:\n",
    "        linha, coluna = divmod(indice_dicionario_variaveis_numericas, numero_colunas)\n",
    "        \n",
    "        #Remover da Figura os Subgráficos Não Utilizados na Matriz de Diagramas de Caixa e Bigodes:\n",
    "        figura.delaxes(matriz_diagramas_caixa_bigodes[linha, coluna])\n",
    "\n",
    "    #Resultados - Mostrar os Diagramas de Caixa e Bigodes Individuais para as Variáveis Numéricas:\n",
    "    show()\n",
    "\n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Não Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87286dc",
   "metadata": {},
   "source": [
    "<H5>1.4.2. Histogramas para as Variáveis Numéricas:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6a410",
   "metadata": {},
   "source": [
    "<H5>1.4.2.1. Histogramas para as Variáveis Numéricas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Pyplot da Biblioteca Matplotlib, Importar as Funções Mostrar e Subgráficos:\n",
    "from matplotlib.pyplot import show, subplots\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Dados:\n",
    "lista_variaveis_numericas = conjunto_dados.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "#Definir o Número de Colunas:\n",
    "colunas = 4\n",
    "\n",
    "#Definir a Altura dos Histogramas:\n",
    "altura_histogramas = 5\n",
    "\n",
    "#Verificar Se Existem Variáveis Numéricas:\n",
    "if lista_variaveis_numericas:\n",
    "\n",
    "    #Calcular o Número Total de Variáveis Numéricas:\n",
    "    numero_total_variaveis_numericas = len(lista_variaveis_numericas)\n",
    "    \n",
    "    #Calcular o Número de Linhas:\n",
    "    número_linhas = (numero_total_variaveis_numericas // colunas) + (numero_total_variaveis_numericas % colunas > 0)\n",
    "\n",
    "    #Criar a Figura e a Matriz dos Histogramas:\n",
    "    figura, matriz_histogramas = subplots(número_linhas, colunas, figsize=(colunas * altura_histogramas, número_linhas * altura_histogramas), squeeze=False)\n",
    "\n",
    "    #Configurações da Figura - Título Geral - Designação, Cor e Tamanho:\n",
    "    figura.suptitle(\"Conjunto de Dados 1 - Histogramas para as Variáveis Numéricas\", color='black', fontsize=20)\n",
    "\n",
    "    #Configurações da Figura - Margens Superior, Direita, Inferior e Esquerda:\n",
    "    figura.subplots_adjust(top=0.92, right=0.95, bottom=0.35, left=0.15)\n",
    "\n",
    "    #Configurações da Figura - Espaçamentos Horizontal e Vertical:\n",
    "    figura.subplots_adjust(wspace=1.5, hspace=0.6)\n",
    "\n",
    "    #Iniciar as Coordenadas X e Y para Navegação na Matriz dos Histogramas:\n",
    "    X, Y = 0, 0\n",
    "\n",
    "    #Iterar sobre o indice das Variáveis Numéricas:\n",
    "    for indice_variavel_numerica in range(numero_total_variaveis_numericas):\n",
    "\n",
    "        #Criar os Histogramas para as Variáveis Numéricas - Configurações das Barras - Cores e Número de Intervalos:\n",
    "        matriz_histogramas[X, Y].hist(conjunto_dados[lista_variaveis_numericas[indice_variavel_numerica]].dropna().values, color='#2ca02c', edgecolor='#2ca02c', bins='auto')\n",
    "\n",
    "        #Configurações dos Histogramas - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_title(f\"Histograma para a variavel {lista_variaveis_numericas[indice_variavel_numerica]}\", color='black', fontsize=13)\n",
    "\n",
    "        #Configurações do Eixo Atual - Definir Exibição dos Elementos Abaixo do Eixo Atual:\n",
    "        matriz_histogramas[X, Y].set_axisbelow(True)\n",
    "\n",
    "        #Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_xlabel(f\"variavel Numérica {lista_variaveis_numericas[indice_variavel_numerica]}\", color='black', fontsize=13)\n",
    "\n",
    "        #Configurações do Eixo X - Rótulos dos Marcadores - Cor:\n",
    "        matriz_histogramas[X, Y].tick_params(axis='x', colors='black')\n",
    "\n",
    "        #Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_ylabel(\"Número de Registos\", color='black', fontsize=13)\n",
    "\n",
    "        #Configurações do Eixo Y - Rótulos dos Marcadores - Cor:\n",
    "        matriz_histogramas[X, Y].tick_params(axis='y', colors='black')\n",
    "\n",
    "        #Configurações do Eixo Y - Valores dos Rótulos - Formatação:\n",
    "        matriz_histogramas[X, Y].yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'.replace(\",\", \".\")))\n",
    "\n",
    "        #Configurações do Eixo Y - Linhas de Grelha - Cor, Estilo de Linha e Transparência:\n",
    "        matriz_histogramas[X, Y].grid(True, axis='y', color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "        #Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "        for margem in matriz_histogramas[X, Y].spines.values():\n",
    "            margem.set_color('black')\n",
    "            margem.set_linewidth(2.5)\n",
    "        \n",
    "        #Ocultar as Margens Superior e Direita:\n",
    "        matriz_histogramas[X, Y].spines['top'].set_visible(False)\n",
    "        matriz_histogramas[X, Y].spines['right'].set_visible(False)\n",
    "\n",
    "        #Se a variavel Numérica Atual Estiver Na Última Coluna da Matriz de Histogramas:\n",
    "        if (indice_variavel_numerica + 1) % colunas == 0:\n",
    "            \n",
    "            #Avançar para a Próxima Linha e Reiniciar a Coluna na Matriz de Histogramas\n",
    "            X, Y = X + 1, 0\n",
    "        \n",
    "        #Senão: Avançar para a Próxima Coluna na Matriz de Histogramas:\n",
    "        else:\n",
    "            Y += 1\n",
    "\n",
    "    #Ocultar os Subgráficos Vazios da Matriz dos Histogramas:\n",
    "    for subgráficos in matriz_histogramas.flat[numero_total_variaveis_numericas:]:\n",
    "        subgráficos.set_visible(False)\n",
    "    \n",
    "    #Resultados - Mostrar os Histogramas para as Variáveis Numéricas:\n",
    "    show()\n",
    "\n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Senão: Não Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e29e1b",
   "metadata": {},
   "source": [
    "<H5>1.4.2.2. Histogramas para as Variáveis Numéricas com as Distribuições Normal/Gaussiana, Exponencial e Log-Normal Ajustadas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Pyplot da Biblioteca Matplotlib, Importar as Funções Mostrar e Subgráficos:\n",
    "from matplotlib.pyplot import show, subplots\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Submódulo Stats da Biblioteca SciPy, Importar as Distribuições Estatísticas Normal, Exponencial e Log-Normal:\n",
    "from scipy.stats import norm, expon, lognorm\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Dados:\n",
    "lista_variaveis_numericas = conjunto_dados.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "#Definir o Número de Colunas:\n",
    "colunas = 4\n",
    "\n",
    "#Definir a Altura e a Largura dos Histogramas:\n",
    "altura_largura_histogramas = 8\n",
    "\n",
    "#Verificar Se Existem Variáveis Numéricas:\n",
    "if lista_variaveis_numericas:\n",
    "\n",
    "    #Calcular o Número Total de Variáveis Numéricas:\n",
    "    numero_total_variaveis_numericas = len(lista_variaveis_numericas)\n",
    "    \n",
    "    #Calcular o Número de Linhas:\n",
    "    número_linhas = (numero_total_variaveis_numericas // colunas) + (numero_total_variaveis_numericas % colunas > 0)\n",
    "\n",
    "    #Criar a Figura e a Matriz dos Histogramas:\n",
    "    figura_histogramas, matriz_histogramas = subplots(número_linhas, colunas, figsize=(colunas * altura_largura_histogramas, número_linhas * altura_largura_histogramas), squeeze=False)\n",
    "\n",
    "    #Configurações da Figura - Título Geral - Designação, Cor e Tamanho:\n",
    "    figura_histogramas.suptitle(\"Conjunto de Dados 1 - Histogramas das Variáveis Numéricas com as Distribuições Normal/Gaussiana, Exponencial e Log-Normal Ajustadas\", color='black', fontsize=20)\n",
    "\n",
    "    #Configurações da Figura - Margens Superior, Direita, Inferior e Esquerda:\n",
    "    figura_histogramas.subplots_adjust(top=0.92, right=0.95, bottom=0.35, left=0.15)\n",
    "\n",
    "    #Configurações da Figura - Espaçamentos Horizontal e Vertical:\n",
    "    figura_histogramas.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "    #Iniciar as Coordenadas X e Y para Navegação na Matriz dos Histogramas:\n",
    "    X, Y = 0, 0\n",
    "\n",
    "    #Iterar sobre o indice das Variáveis Numéricas:\n",
    "    for indice_variavel_numerica in range(numero_total_variaveis_numericas):\n",
    "\n",
    "        #Obter os Dados da variavel Numérica Atual:\n",
    "        dados_variavel_numerica_atual = conjunto_dados[lista_variaveis_numericas[indice_variavel_numerica]].dropna().values\n",
    "\n",
    "        #Criar os Histogramas para as Variáveis Numéricas - Configurações das Barras - Cores e Número de Intervalos:\n",
    "        matriz_histogramas[X, Y].hist(dados_variavel_numerica_atual, color='#2ca02c', edgecolor='#2ca02c', bins='auto', density=True)\n",
    "\n",
    "        #Configurações dos Histogramas - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_title(f\"Histograma para a variavel Numérica {lista_variaveis_numericas[indice_variavel_numerica]}\", color='black', fontsize=15)\n",
    "\n",
    "        #Configurações do Eixo Atual - Definir Exibição dos Elementos Abaixo do Eixo Atual:\n",
    "        matriz_histogramas[X, Y].set_axisbelow(True)\n",
    "\n",
    "        #Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_xlabel(f\"variavel Numérica {lista_variaveis_numericas[indice_variavel_numerica]}\", color='black', fontsize=15)\n",
    "\n",
    "        #Configurações do Eixo X - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].tick_params(axis='x', colors='black', labelsize=15)\n",
    "\n",
    "        #Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].set_ylabel(\"Densidade de Probabilidade\", color='black', fontsize=15)\n",
    "\n",
    "        #Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "        matriz_histogramas[X, Y].tick_params(axis='y', colors='black', labelsize=15)\n",
    "\n",
    "        #Configurações do Eixo Y - Valores dos Rótulos - Formatação:\n",
    "        matriz_histogramas[X, Y].yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.3f}'.replace(\".\", \",\")))\n",
    "\n",
    "        #Configurações do Eixo Y - Linhas de Grelha - Cor, Estilo de Linha e Transparência:\n",
    "        matriz_histogramas[X, Y].grid(True, axis='y', color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "        #Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "        for margem in matriz_histogramas[X, Y].spines.values():\n",
    "            margem.set_color('black')\n",
    "            margem.set_linewidth(2.5)\n",
    "        \n",
    "        #Ocultar as Margens Superior e Direita:\n",
    "        matriz_histogramas[X, Y].spines['top'].set_visible(False)\n",
    "        matriz_histogramas[X, Y].spines['right'].set_visible(False)\n",
    "\n",
    "        #Gerar Pontos para Ajustar as Distribuições aos Histogramas:\n",
    "        pontos_ajustar_distribuicoes = np.linspace(pd.Series(dados_variavel_numerica_atual).quantile(0.001), pd.Series(dados_variavel_numerica_atual).quantile(0.999), 100)\n",
    "\n",
    "        #Calcular a media e o Desvio Padrão para Ajustar a Distribuição Normal/Gaussiana aos Dados dos Histogramas:\n",
    "        media, desvio_padrao = norm.fit(dados_variavel_numerica_atual)\n",
    "\n",
    "        #Ajustar a Distribuição Normal/Gaussiana aos Dados dos Histogramas - Configurações da Distribuição Normal/Gaussiana - Designação e Cor:\n",
    "        matriz_histogramas[X, Y].plot(pontos_ajustar_distribuicoes, norm.pdf(pontos_ajustar_distribuicoes, media, desvio_padrao), label=\"Distribuição Normal/Gaussiana\", color='#ff7f0e')\n",
    "\n",
    "        #Calcular a Localização e a Escala para Ajustar a Distribuição Exponencial aos Dados dos Histogramas:\n",
    "        localizacao, escala = expon.fit(dados_variavel_numerica_atual)\n",
    "\n",
    "        #Ajustar a Distribuição Exponencial aos Dados dos Histogramas - Configurações da Distribuição Exponencial - Designação e Cor:\n",
    "        matriz_histogramas[X, Y].plot(pontos_ajustar_distribuicoes, expon.pdf(pontos_ajustar_distribuicoes, localizacao, escala), label=\"Distribuição Exponencial\", color='#87CEEB')\n",
    "\n",
    "        #Filtrar os Dados Positivos da variavel Numérica Atual:\n",
    "        dados_positivos_variavel_numerica_atual = dados_variavel_numerica_atual[dados_variavel_numerica_atual > 0]\n",
    "        \n",
    "        #Verificar Se a variavel Numérica Atual Apresenta Dados Positivos:\n",
    "        if len(dados_positivos_variavel_numerica_atual) > 0:\n",
    "            \n",
    "            #Calcular a Forma, a Localização e a Escala para Ajustar a Distribuição Log-Normal aos Dados dos Histogramas:\n",
    "            forma, localizacao, escala = lognorm.fit(dados_positivos_variavel_numerica_atual, floc=0)\n",
    "            \n",
    "            #Ajustar a Distribuição Log-Normal aos Dados dos Histogramas - Configurações da Distribuição Log-Normal - Designação e Cor:\n",
    "            matriz_histogramas[X, Y].plot(pontos_ajustar_distribuicoes, lognorm.pdf(pontos_ajustar_distribuicoes, forma, localizacao, escala), label=\"Distribuição Log-Normal\", color='#9467bd')\n",
    "    \n",
    "        #Senão: Não Existem Dados para Ajustar a Distribuição Log-Normal aos Dados dos Histogramas:\n",
    "        else:\n",
    "            matriz_histogramas[X, Y].text(0.5, 0.5, 'Não Existem Dados para Ajustar a Distribuição Log-Normal', horizontalalignment='center', verticalalignment='center',\n",
    "                                          transform=matriz_histogramas[X, Y].transAxes, fontsize=10, color='red')\n",
    "\n",
    "        #Configurações da Legenda de Cores - Texto - Tamanho, Cores e Espessura:\n",
    "        legenda_cores = matriz_histogramas[X, Y].legend(fontsize=12, frameon=True)\n",
    "        if legenda_cores is not None:\n",
    "            legenda_cores.get_title().set_color('black')\n",
    "            for texto in legenda_cores.get_texts():\n",
    "                texto.set_color('black')\n",
    "            caixa = legenda_cores.get_frame()\n",
    "            caixa.set_edgecolor('grey')\n",
    "            caixa.set_linewidth(1.0)\n",
    "            caixa.set_facecolor('none')\n",
    "\n",
    "        #Se a variavel Numérica Atual Estiver Na Última Coluna da Matriz de Histogramas:\n",
    "        if (indice_variavel_numerica + 1) % colunas == 0:\n",
    "            \n",
    "            #Avançar para a Próxima Linha e Reiniciar a Coluna na Matriz de Histogramas\n",
    "            X, Y = X + 1, 0\n",
    "        \n",
    "        #Senão: Avançar para a Próxima Coluna na Matriz de Histogramas:\n",
    "        else:\n",
    "            Y += 1\n",
    "\n",
    "    #Ocultar os Subgráficos Vazios na Matriz dos Histogramas:\n",
    "    for subgraficos in matriz_histogramas.flat[numero_total_variaveis_numericas:]:\n",
    "        subgraficos.set_visible(False)\n",
    "    \n",
    "    #Resultados - Mostrar os Histogramas para as Variáveis Numéricas:\n",
    "    show()\n",
    "\n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Senão: Não Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423eea91",
   "metadata": {},
   "source": [
    "<H5>1.4.2.3. Gráficos de Barras para as Variáveis Temporal, Simbólicas e Binárias:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#A partir do Módulo Funções do DSLabs, Importar a Função para Definir os Títulos nos Gráficos:\n",
    "from dslabs_functions import set_chart_labels\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Identificar as Variáveis Categóricas do Conjunto de Dados:\n",
    "variaveis_categoricas = [variavel for variavel in conjunto_dados.columns if conjunto_dados[variavel].dtype == 'object']\n",
    "\n",
    "#Identificar as Variáveis Binárias do Conjunto de Dados:\n",
    "variaveis_binarias = [variavel for variavel in conjunto_dados.columns if conjunto_dados[variavel].nunique() == 2]\n",
    "\n",
    "#Definir Função para Obter o Tipo de variavel Categórica:\n",
    "def funcao_obter_tipo_variavel_categorica(variavel_categorica):\n",
    "\n",
    "    #Verificar se a variavel se chama Data:\n",
    "    if variavel_categorica == \"Data\":\n",
    "        \n",
    "        #Devolver Temporal para a variavel Data:\n",
    "        return \"Temporal\"\n",
    "    \n",
    "    #Senão: Verificar Se a variavel é Binária:\n",
    "    elif variavel_categorica in variaveis_binarias:\n",
    "        \n",
    "        #Devolver Binária para as Variáveis Binárias:\n",
    "        return \"Binária\"\n",
    "    \n",
    "    #Senão: Devolver Simbólica para as Variáveis Simbólicas:\n",
    "    else:\n",
    "        return \"Simbólica\"\n",
    "\n",
    "#Filtrar as Variáveis Categóricas com Dados Não Nulos:\n",
    "variaveis_categoricas = [variavel for variavel in variaveis_categoricas if conjunto_dados[variavel].notna().sum() > 0]\n",
    "\n",
    "#Se Existirem Variáveis Categóricas:\n",
    "if variaveis_categoricas:\n",
    "    \n",
    "    #Definir o Número de Colunas:\n",
    "    numero_colunas = 4\n",
    "    \n",
    "    #Calcular o Número de Gráficos de Barras a serem Criados com base no Número de Variáveis Categóricas:\n",
    "    numero_graficos_barras = len(variaveis_categoricas)\n",
    "    \n",
    "    #Calcular o Número de Linhas para os Gráficos de Barras: \n",
    "    numero_linhas = (numero_graficos_barras // numero_colunas) + (numero_graficos_barras % numero_colunas > 0)\n",
    "\n",
    "    #Criar o Gráfico de Barras e os Subgráficos:\n",
    "    grafico_barras, subgraficos = plt.subplots(numero_linhas, numero_colunas, figsize=(numero_colunas * 5, (numero_linhas + 1) * 4), squeeze=False)\n",
    "    \n",
    "    #Configurações dos Gráficos de Barras - Título Geral - Designação, Cor e Tamanho:\n",
    "    grafico_barras.suptitle(\"Conjunto de Dados 1 - Gráficos de Barras para as Variáveis Temporal, Simbólicas e Binárias\", color='black', fontsize=16)\n",
    "\n",
    "    #Configurações dos Gráficos de Barras - Margem Superior e Espaçamento Horizontal:\n",
    "    grafico_barras.subplots_adjust(top=0.9, wspace=0.6)\n",
    "\n",
    "    #Iniciar as Coordenadas X e Y para Navegação na Matriz de Subgráficos:\n",
    "    X, Y = 0, 0\n",
    "\n",
    "    #Definir Função para Formatar os Valores do Eixo Y:\n",
    "    def função_formatar_valores_eixo_Y(Y, posição=None):\n",
    "        \n",
    "        #Formatar os Valores do Eixo Y:\n",
    "        return f'{Y:,.0f}'.replace(',', '.')\n",
    "\n",
    "    #Iterar sobre os indices das Variáveis Categóricas:\n",
    "    for indice_variavel_categorica in range(numero_graficos_barras):\n",
    "\n",
    "        #Obter a variavel Categórica Atual com Base no indice:\n",
    "        variavel_categorica_atual = variaveis_categoricas[indice_variavel_categorica]\n",
    "\n",
    "        #Obter o Tipo da variavel Categórica Atual:\n",
    "        tipo_variavel_categorica_atual = funcao_obter_tipo_variavel_categorica(variavel_categorica_atual)\n",
    "        \n",
    "        #Verificar se a variavel Categórica Atual se chama Data:\n",
    "        if variavel_categorica_atual == \"Data\":\n",
    "            \n",
    "            #Configurações do Gráfico de Barras para a variavel Temporal Data - Título:\n",
    "            título = \"Gráfico de Barras - variavel Temporal Data\"\n",
    "        \n",
    "        #Senão: Definir o Título para o Gráfico de Barras da variavel Categórica com Base no Seu Tipo e Nome:\n",
    "        else:\n",
    "            título = f\"Gráfico de Barras - variavel {tipo_variavel_categorica_atual} {variavel_categorica_atual}\"\n",
    "    \n",
    "        #Contar as Ocorrências de Cada Categoria da variavel Categórica Atual:\n",
    "        contagem_ocorrencias_categoria_variavel_categorica_atual = conjunto_dados[variavel_categorica_atual].dropna().value_counts()\n",
    "\n",
    "        #Configurações dos Gráficos de Barras\n",
    "        set_chart_labels(subgraficos[X, Y], title=título, xlabel=f\"variavel {variavel_categorica_atual}\", ylabel=\"Número de Registos\")\n",
    "        \n",
    "        #Configurações dos Gráficos de Barras - Título - Cor e Tamanho:\n",
    "        subgraficos[X, Y].set_title(título, color='black', fontsize=10)\n",
    "\n",
    "        #Configurações das Barras - Cores:\n",
    "        subgraficos[X, Y].bar(contagem_ocorrencias_categoria_variavel_categorica_atual.index.astype(str), contagem_ocorrencias_categoria_variavel_categorica_atual.values, color='#2ca02c', edgecolor='#2ca02c')\n",
    "    \n",
    "        #Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "        subgraficos[X, Y].set_xlabel(f\"variavel {variavel_categorica_atual}\", color='black', fontsize=10)\n",
    "\n",
    "        #Configurações do Eixo X - Valores - Cor e Tamanho:\n",
    "        subgraficos[X, Y].tick_params(axis='x', colors='black', labelsize=10)\n",
    "\n",
    "        #Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "        subgraficos[X, Y].set_ylabel(\"Número de Registos\", color='black', fontsize=10)\n",
    "\n",
    "        #Configurações do Eixo Y - Valores - Cor e Tamanho:\n",
    "        subgraficos[X, Y].tick_params(axis='y', colors='black', labelsize=10)\n",
    "\n",
    "        #Configurações do Eixo Y - Valores - Formatação:\n",
    "        subgraficos[X, Y].yaxis.set_major_formatter(FuncFormatter(função_formatar_valores_eixo_Y))\n",
    "\n",
    "        #Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "        for margem in subgraficos[X, Y].spines.values():\n",
    "            margem.set_color('black')\n",
    "            margem.set_linewidth(2.5)\n",
    "\n",
    "        #Verificar Se a variavel Categórica Se Encontra na Última Coluna de uma Linha:\n",
    "        if (indice_variavel_categorica + 1) % numero_colunas == 0:\n",
    "            \n",
    "            #Avançar para a Próxima Linha e Começar na 1.ª Coluna:\n",
    "            X, Y = X + 1, 0\n",
    "        \n",
    "        #Senão: Avançar para a Próxima Coluna na Mesma Linha:\n",
    "        else:\n",
    "            Y += 1\n",
    "\n",
    "    #Remover os Subgráficos Vazios:\n",
    "    for eixo in subgraficos.flat[numero_graficos_barras:]:\n",
    "        eixo.set_visible(False)\n",
    "    \n",
    "    #Resultados - Mostrar os Gráficos de Barras:\n",
    "    plt.show()\n",
    "\n",
    "#Senão: Não Existem Variáveis Simbólicas com Dados.\n",
    "else:\n",
    "    print(\"Não Existem Variáveis Simbólicas com Dados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db3744",
   "metadata": {},
   "source": [
    "<H5>1.4.3. Estudo dos Valores Atípicos:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f781ef9",
   "metadata": {},
   "source": [
    "<H5>1.4.3.1. Estudo dos Valores Atípicos - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar a Biblioteca Numpy:\n",
    "import numpy as np\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Definir o Fator do Intervalo Interquartil:\n",
    "fator_intervalo_interquartil = 1.5\n",
    "\n",
    "#Definir o Fator do Desvio Padrao:\n",
    "fator_desvio_padrao = 3\n",
    "\n",
    "#Verificar Se Existem Variaveis Numéricas no Conjunto de Dados:\n",
    "variaveis_numericas = conjunto_dados.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "#Se Existirem Variáveis Numéricas no Conjunto de Dados:\n",
    "if len(variaveis_numericas) > 0:\n",
    "\n",
    "    #Criar um Dicionário para Armazenar os Valores Atípicos:\n",
    "    dicionario_valores_atipicos = {'Intervalo Interquartil': [], 'Desvio Padrão': []}\n",
    "\n",
    "    #Iniciar o Contador do Numero Total de Valores Atípicos - Intervalo Interquartil:\n",
    "    contador_numero_total_valores_atipicos_intervalo_interquartil = 0\n",
    "   \n",
    "    #Iniciar o Contador do Numero Total de Valores Atípicos - Desvio Padrao:\n",
    "    contador_numero_total_valores_atipicos_desvio_padrao = 0\n",
    "\n",
    "    #Iterar sobre as Variáveis Numéricas do Conjunto de Dados:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "    \n",
    "        #Calcular o 1.º Quartil:\n",
    "        Q1 = conjunto_dados[variavel_numerica].quantile(0.25)\n",
    "        \n",
    "        #Calcular o 3.º Quartil:\n",
    "        Q3 = conjunto_dados[variavel_numerica].quantile(0.75)\n",
    "        \n",
    "        #Calcular o Intervalo Interquartil:\n",
    "        intervalo_interquartil = Q3 - Q1\n",
    "        \n",
    "        #Calcular o Limite Inferior - Intervalo Interquartil:\n",
    "        limite_inferior_intervalo_interquartil = Q1 - fator_intervalo_interquartil * intervalo_interquartil\n",
    "\n",
    "        #Calcular o Limite Superior - Intervalo Interquartil:\n",
    "        limite_superior_intervalo_interquartil = Q3 + fator_intervalo_interquartil * intervalo_interquartil\n",
    "    \n",
    "        #Contar o Numero de Valores Atípicos para cada variavel Numérica - Intervalo Interquartil:\n",
    "        valores_atipicos_intervalo_interquartil = ((conjunto_dados[variavel_numerica] < limite_inferior_intervalo_interquartil) | \n",
    "                                                          (conjunto_dados[variavel_numerica] > limite_superior_intervalo_interquartil)).sum()\n",
    "    \n",
    "        #Adicionar os Resultados ao Dicionário de Valores Atípicos - Intervalo Interquartil:\n",
    "        dicionario_valores_atipicos['Intervalo Interquartil'].append(valores_atipicos_intervalo_interquartil)\n",
    "\n",
    "        #Atualizar o Contador do Número Total de Valores Atípicos - Intervalo Interquartil:\n",
    "        contador_numero_total_valores_atipicos_intervalo_interquartil += valores_atipicos_intervalo_interquartil\n",
    "\n",
    "        #Calcular a media:\n",
    "        media = conjunto_dados[variavel_numerica].mean()\n",
    "        \n",
    "        #Calcular o Desvio Padrão:\n",
    "        desvio_padrao = conjunto_dados[variavel_numerica].std()\n",
    "    \n",
    "        #Calcular o Limite Inferior - Desvio Padrão:\n",
    "        limite_inferior_desvio_padrao = media - fator_desvio_padrao * desvio_padrao\n",
    "\n",
    "        #Calcular o Limite Superior - Desvio Padrão:\n",
    "        limite_superior_desvio_padrao = media + fator_desvio_padrao * desvio_padrao\n",
    "    \n",
    "        #Contar o Numero de Valores Atípicos para cada variavel Numérica - Desvio Padrão:\n",
    "        valores_atipicos_desvio_padrao = ((conjunto_dados[variavel_numerica] < limite_inferior_desvio_padrao) |\n",
    "                                          (conjunto_dados[variavel_numerica] > limite_superior_desvio_padrao)).sum()\n",
    "    \n",
    "        #Adicionar os Resultados ao Dicionário de Valores Atípicos - Desvio Padrão:\n",
    "        dicionario_valores_atipicos['Desvio Padrão'].append(valores_atipicos_desvio_padrao)\n",
    "\n",
    "        #Atualizar o Contador do Número Total de Valores Atipicos - Desvio Padrão:\n",
    "        contador_numero_total_valores_atipicos_desvio_padrao += valores_atipicos_desvio_padrao\n",
    "\n",
    "    #Resultados - Título Geral:\n",
    "    print(\"Número de Valores Atípicos por variavel Numérica - Intervalo Interquartil e Desvio Padrão:\\n\")\n",
    "    \n",
    "    #Resultados - Títulos:\n",
    "    print(f\"{'variavel Numérica:':<30}{'Número de Valores Atípicos - Intervalo Interquartil:':<70}{'Número de Valores Atípicos - Desvio Padrão:\\n':<70}\")\n",
    "    \n",
    "    #Iterar Sobre os indices e Valores das Variáveis Numéricas:\n",
    "    for indice_variavel_numerica, valor_variavel_numerica in enumerate(variaveis_numericas):\n",
    "        \n",
    "        #Atribuir o Valor do Intervalo Interquartil à variavel Numérica Correspondente:\n",
    "        valor_intervalo_interquartil = dicionario_valores_atipicos['Intervalo Interquartil'][indice_variavel_numerica]\n",
    "\n",
    "        #Atribuir o Valor do Desvio Padrão à variavel Numérica Correspondente:\n",
    "        valor_desvio_padrao = dicionario_valores_atipicos['Desvio Padrão'][indice_variavel_numerica]\n",
    "\n",
    "        #Resultados - variavel Numérica ; Número de Valores Atípicos - Intervalo Interquartil ; Numero de Valores Atípicos - Desvio Padrão:\n",
    "        print(f\"{valor_variavel_numerica:<30}{valor_intervalo_interquartil:<70,.0f}\".replace(',', '.') + f\"{valor_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "\n",
    "    #Resultados - Número Total de Valores Atípicos - Intervalo Interquartil e Desvio Padrão:\n",
    "    print(\"=\" * 130)\n",
    "    print(f\"{'Total de Valores Atípicos:':<30}{contador_numero_total_valores_atipicos_intervalo_interquartil:<70,.0f}\".replace(',', '.') + \n",
    "          f\"{contador_numero_total_valores_atipicos_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "    \n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Nao Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb85f6",
   "metadata": {},
   "source": [
    "<H5>1.4.3.2. Estudo dos Valores Atípicos - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Importar a Biblioteca Numpy:\n",
    "import numpy as np\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Variáveis Numéricas:\n",
    "variaveis_numericas = [\"Temperatura_Minima\", \"Temperatura_Maxima\", \"Precipitacao\", \"Evaporacao\", \"Sol\", \"Velocidade_Rajada_Vento\", \"Velocidade_Vento_09h\", \"Velocidade_Vento_15h\", \"Humidade_09h\", \"Humidade_15h\", \"Pressao_Atmosferica_09h\", \"Pressao_Atmosferica_15h\", \"Nuvens_09h\", \"Nuvens_15h\", \"Temperatura_09h\", \"Temperatura_15h\"]\n",
    "\n",
    "#Valores Atípicos - Intervalo Interquartil:\n",
    "valores_atipicos_intervalo_interquartil = [54, 489, 25578, 1995, 0, 3092, 1817, 2523, 1425, 0, 1191, 919, 0, 0, 262, 764]\n",
    "\n",
    "#Valores Atípicos - Desvio Padrão:\n",
    "valores_atipicos_desvio_padrao = [19, 331, 2456, 870, 0, 1368, 1362, 958, 472, 0, 503, 426, 0, 0, 149, 397]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Figura - Tamanho:\n",
    "grafico_barras, eixo = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "#Configurações do Gráfico de Barras - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "eixo.set_title(\"Conjunto de Dados 1 - Número de Valores Atípicos por variavel Numérica\", color='black', fontsize=16, pad=20)\n",
    "\n",
    "#Configurações das Barras - Títulos:\n",
    "titulos_barras = ['Valores Atípicos - Intervalo Interquartil', 'Valores Atípicos - Desvio Padrão']\n",
    "\n",
    "#Configurações das Barras - Cores:\n",
    "cores_barras = ['#2ca02c', '#ff7f0e']\n",
    "\n",
    "#Configurações das Barras - Largura:\n",
    "largura_barras = 0.5\n",
    "\n",
    "#Agrupar os Valores Atípicos por Métodos de Cálculo - Intervalo Interquartil e Desvio Padrão:\n",
    "valores_atipicos = [valores_atipicos_intervalo_interquartil, valores_atipicos_desvio_padrao]\n",
    "\n",
    "#Calcular as Posições das Variáveis Numéricas:\n",
    "posicoes_variaveis_numericas = np.arange(len(variaveis_numericas)) * 1.5\n",
    "\n",
    "#Iterar sobre os Valores, Cores e Títulos das Barras:\n",
    "for contador, (valores_barras, cores_barras, títulos_barras) in enumerate(zip(valores_atipicos, cores_barras, titulos_barras)):\n",
    "    \n",
    "    #Configurações do Gráfico de Barras - Sobreposição:\n",
    "    grafico_barras = eixo.bar(posicoes_variaveis_numericas + contador * largura_barras, valores_barras, largura_barras, color=cores_barras, edgecolor=cores_barras, label=títulos_barras, zorder=3)\n",
    "\n",
    "    #Iterar sobre cada Barra do Gráfico:\n",
    "    for barra in grafico_barras:\n",
    "        \n",
    "        #Calcular a Altura da Barra:\n",
    "        altura_barra = barra.get_height()\n",
    "        \n",
    "        #Formatar a Altura da Barra:\n",
    "        altura_barra_formatada = f'{altura_barra:,}'.replace(',', '.')\n",
    "        \n",
    "        #Configurações das Barras - Valores - Posição, Cor e Tamanho:\n",
    "        eixo.text(barra.get_x() + barra.get_width()/2, altura_barra + 50, altura_barra_formatada, ha='center', va='bottom', color='black', fontsize=9)\n",
    "\n",
    "#Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "eixo.set_xlabel(\"Variáveis Numéricas\", color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Posições dos Marcadores:\n",
    "eixo.set_xticks(posicoes_variaveis_numericas + largura_barras / 2)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor, Tamanho, Posição e Rotação:\n",
    "eixo.set_xticklabels(variaveis_numericas, color='black', fontsize=14, ha='right', rotation=45)\n",
    "\n",
    "#Configurações do Eixo X - Parâmetros dos Marcadores - Cor:\n",
    "eixo.tick_params(axis='x', colors='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "eixo.set_ylabel(\"Número de Valores Atípicos\", color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "eixo.tick_params(axis='y', colors='black', labelsize=14)\n",
    "\n",
    "#Definir Função para Formatar os Valores do Eixo Y:\n",
    "def funcao_formatar_valores_eixo_Y(valores_Y, posição=None):\n",
    "\n",
    "    #Formatar os Valores do Eixo Y:\n",
    "    return f'{int(valores_Y):,}'.replace(',', '.')\n",
    "\n",
    "#Configurações do Eixo Y - Aplicar a Formatação aos Rótulos:\n",
    "eixo.yaxis.set_major_formatter(FuncFormatter(funcao_formatar_valores_eixo_Y))\n",
    "\n",
    "#Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "eixo.set_ylim(0, 30000)\n",
    "\n",
    "#Configurações do Eixo Y - Linhas de Grelha - Cor, Estilo de Linha, Espessura e Sobreposição:\n",
    "eixo.yaxis.grid(True, color='gray', linestyle='-', linewidth=0.5, zorder=2)\n",
    "\n",
    "#Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixo.spines[margem].set_color('black')\n",
    "    eixo.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "#Ocultar as Margens Superior e Direita:\n",
    "for margem in ['top', 'right']:\n",
    "    eixo.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição e Tamanho:\n",
    "legenda_cores = eixo.legend(loc=\"upper right\", frameon=True, fontsize=12)\n",
    "\n",
    "#Iterar sobre os Títulos da Legenda de Cores:\n",
    "for titulos_legenda_cores in legenda_cores.get_texts():\n",
    "\n",
    "    #Configurações da Legenda de Cores - Títulos - Cor:\n",
    "    titulos_legenda_cores.set_color('black')\n",
    "\n",
    "#Configurações da Legenda de Cores - Caixa da Legenda - Posição, Cor da Borda e Fundo Transparente:\n",
    "legenda_cores.set_bbox_to_anchor((1.00, 0.81))\n",
    "legenda_cores.get_frame().set_edgecolor('black')\n",
    "legenda_cores.get_frame().set_facecolor('none')\n",
    "\n",
    "#Resultados - Mostrar o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d3fcb",
   "metadata": {},
   "source": [
    "<H5>1.4.4. Distribuição das Classes da variavel Alvo:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Calcular o Número de Vezes que cada Valor Único aparece na variavel Alvo:\n",
    "numero_vezes_valor_unico_variavel_alvo = conjunto_dados[variavel_alvo].value_counts()\n",
    "\n",
    "#Configurações do Gráfico de Barras - Figura - Tamanho:\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "#Configurações do Gráfico de Barras - Título Geral - Designação, Cor, Tamanho e Espaçamento:\n",
    "plt.title(f\"Conjunto de Dados - Distribuição das Classes da variavel Alvo ({variavel_alvo})\", color='black', fontsize=16, pad=30)\n",
    "\n",
    "#Configurações das Barras - Cores:\n",
    "cores_barras = ['#2ca02c' if valor == 'Nao' else '#ff7f0e' for valor in numero_vezes_valor_unico_variavel_alvo.index]\n",
    "\n",
    "#Criar o Gráfico de Barras - Configurações do Gráfico de Barras - Sobreposição:\n",
    "grafico_barras = plt.bar(numero_vezes_valor_unico_variavel_alvo.index, numero_vezes_valor_unico_variavel_alvo, color=cores_barras, edgecolor=cores_barras, zorder=3)\n",
    "\n",
    "#Iterar sobre cada Barra do Gráfico:\n",
    "for barra in grafico_barras:\n",
    "    \n",
    "    #Obter a Altura da Barra:\n",
    "    altura_barra = barra.get_height()\n",
    "    \n",
    "    #Configurações das Barras - Valores - Posição, Cor e Tamanho:\n",
    "    plt.text(barra.get_x() + barra.get_width()/2, altura_barra, f'{altura_barra:,.0f}'.replace(',', '.'), ha='center', va='bottom', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "plt.xlabel(\"Classes da Variável Alvo (Chuva_Amanha)\", color='black', fontsize=14, labelpad=15)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "plt.xticks(color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "plt.ylabel(\"Número de Registos\", color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Cor e Tamanho:\n",
    "plt.yticks(color='black', fontsize=14)\n",
    "\n",
    "#Definir Função para Formatar os Valores do Eixo Y:\n",
    "def funcao_formatar_valores_eixo_Y(valores_Y, posição=None):\n",
    "  \n",
    "    #Formatar os Valores do Eixo Y:\n",
    "    return f\"{int(valores_Y):,}\".replace(\",\", \".\")\n",
    "\n",
    "#Configurações do Eixo Y - Linhas de Grelha - Cor, Estilo de Linha, Espessura e Sobreposição:\n",
    "plt.grid(axis='y', color='grey', linestyle='-', linewidth=0.7, zorder=2)\n",
    "\n",
    "#Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "plt.ylim(0, 120000)\n",
    "\n",
    "#Configurações do Eixo Y - Aplicar a Formatação aos Rótulos:\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(funcao_formatar_valores_eixo_Y))\n",
    "\n",
    "#Obter o Eixo Atual:\n",
    "eixo_atual = plt.gca()\n",
    "\n",
    "#Configurações das Margens dos Eixos X e Y - Cor e Espessura:\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixo_atual.spines[margem].set_color('black')\n",
    "    eixo_atual.spines[margem].set_linewidth(2.5)\n",
    "\n",
    "#Ocultar as Margens Superior e Direita:\n",
    "eixo_atual.spines['top'].set_visible(False)\n",
    "eixo_atual.spines['right'].set_visible(False)\n",
    "\n",
    "#Resultados - Mostrar o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4977229",
   "metadata": {},
   "source": [
    "<H5>1.5. Granularidade - Estudo da Granularidade para a Variável Temporal Data:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas: \n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Ticker da Biblioteca Matplotlib, Importar a Função Formatador de Função:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#A partir do Submódulo Figure da Biblioteca Matplotlib, Importar a Classe Figura:\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "#Importar a Biblioteca Numpy:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Módulo Funções do DSLabs, Importar as Funções Obter Tipos de Variáveis e Altura:\n",
    "from dslabs_functions import get_variable_types, HEIGHT\n",
    "\n",
    "#Ler e Carregar o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Definir Função para Derivar os Componentes Temporais a partir da variavel Temporal Data:\n",
    "def funcao_derivar_componentes_temporais(dados: pd.DataFrame, variaveis_temporais: list[str]) -> pd.DataFrame:\n",
    "\n",
    "    #Iterar sobre as Variáveis Temporais:\n",
    "    for variavel_temporal in variaveis_temporais:\n",
    "        \n",
    "        #Derivar os Componentes Temporais (Ano, Mes e Dia) a partir da variavel Temporal Data:\n",
    "        dados[variavel_temporal + \"_Ano\"] = dados[variavel_temporal].dt.year\n",
    "        dados[variavel_temporal + \"_Mês\"] = dados[variavel_temporal].dt.month\n",
    "        dados[variavel_temporal + \"_Dia\"] = dados[variavel_temporal].dt.day\n",
    "\n",
    "    #Devolver os Dados com os Componentes Temporais Derivados:\n",
    "    return dados\n",
    "\n",
    "#Definir Função para Criar os Gráficos de Barras e Analisar a Granularidade Temporal:\n",
    "def funcao_criar_graficos_barras_analisar_granularidade_temporal(dados: pd.DataFrame, variavel: str, niveis: list[str]) -> np.ndarray:\n",
    "    \n",
    "    #Calcular o Número de Colunas:\n",
    "    numero_colunas: int = len(niveis)\n",
    "    \n",
    "    #Armazenar a Figura e os Eixos do Gráfico de Barras numa variavel:\n",
    "    figura: Figure\n",
    "    eixos: np.ndarray\n",
    "    \n",
    "    #Criar a Figura e os Eixos para os Subgráficos:\n",
    "    figura, eixos = plt.subplots(1, numero_colunas, figsize=(numero_colunas * HEIGHT, HEIGHT), squeeze=False)\n",
    "    \n",
    "    #Configurações dos Gráficos de Barras - Título Geral - Designação, Cor e Tamanho:\n",
    "    figura.suptitle(f\"Conjunto de Dados 1 - Estudo da Granularidade para a variavel Temporal {variavel}\", color='black', fontsize=16)\n",
    "\n",
    "    #Configurações dos Gráficos de Barras - Margem e Espaçamento Horizontal:\n",
    "    figura.subplots_adjust(top=0.80, hspace=0.5)\n",
    "\n",
    "    #Definir os Níveis de Detalhe Temporais (Ano, Mês e Dia):\n",
    "    niveis_detalhe = [\"Ano\", \"Mês\", \"Dia\"]\n",
    "\n",
    "    #Iterar sobre os indices das Variáveis Temporais:\n",
    "    for indice_variavel_temporal in range(numero_colunas):\n",
    "\n",
    "        #Obter e Ordenar as Contagens de cada Valor Único das Variáveis Temporais:\n",
    "        contagens_valores_unicos_variaveis_temporais: pd.Series[int] = dados[variavel + \"_\" + niveis_detalhe[indice_variavel_temporal]].value_counts().sort_index()\n",
    "\n",
    "        #Verificar Se o Nível de Detalhe da variavel Temporal é Mês:\n",
    "        if niveis_detalhe[indice_variavel_temporal] == \"Mês\":\n",
    "\n",
    "            #Criar Lista de Rótulos de Texto para os Valores Únicos das Variáveis Temporais:\n",
    "            rotulos_variaveis_temporais = [f'{valor_unico_variavel_temporal}' for valor_unico_variavel_temporal in contagens_valores_unicos_variaveis_temporais.index]\n",
    "\n",
    "        #Senão: Verificar Se o Nível de Detalhe da variavel Temporal é Ano:\n",
    "        elif niveis_detalhe[indice_variavel_temporal] == \"Ano\":\n",
    "\n",
    "            #Converter os indices das Contagens em Rótulos de Texto para as Variáveis Temporais:\n",
    "            rotulos_variaveis_temporais = contagens_valores_unicos_variaveis_temporais.index.astype(str).to_list()\n",
    "\n",
    "        #Senão: Converter os indices das Contagens em Rótulos para as Variáveis Temporais:\n",
    "        else:\n",
    "            rotulos_variaveis_temporais = contagens_valores_unicos_variaveis_temporais.index.to_list()\n",
    "\n",
    "        #Verificar Se o Nível de Detalhe da variavel Temporal é Ano:\n",
    "        if niveis_detalhe[indice_variavel_temporal] == \"Ano\":\n",
    "            \n",
    "            #Definir o Título como Granularidade Anual:\n",
    "            titulo = \"Granularidade Anual\"\n",
    "\n",
    "        #Senão: Verificar Se o Nível de Detalhe da variavel Temporal é Mes:\n",
    "        elif niveis_detalhe[indice_variavel_temporal] == \"Mês\":\n",
    "            \n",
    "            #Definir o Título como Granularidade Mensal:\n",
    "            titulo = \"Granularidade Mensal\"\n",
    "        \n",
    "        #Senão: Definir o Título como Granularidade Diária:\n",
    "        else:\n",
    "            titulo = \"Granularidade Diária\"\n",
    "\n",
    "        #Configurações dos Gráficos de Barras - Títulos - Cor e Tamanho:\n",
    "        eixos[0, indice_variavel_temporal].set_title(titulo, color='black', fontsize=12)\n",
    "        \n",
    "        #Configurações das Barras - Cores, Altura, Posição e Tamanho:\n",
    "        barras = eixos[0, indice_variavel_temporal].bar(rotulos_variaveis_temporais, contagens_valores_unicos_variaveis_temporais.values, color='#2ca02c', edgecolor='#2ca02c')\n",
    "        for barra in barras:\n",
    "            altura = barra.get_height()\n",
    "            eixos[0, indice_variavel_temporal].text(barra.get_x() + barra.get_width()/2, altura + 0.5, f'{altura:,.0f}'.replace(',', '.'),\n",
    "                                                    ha='center', va='bottom', color='black', fontsize=6)\n",
    "\n",
    "        #Configurações do Eixo X - Título - Cor e Tamanho:\n",
    "        eixos[0, indice_variavel_temporal].set_xlabel(niveis_detalhe[indice_variavel_temporal], color='black', fontsize=10)\n",
    "        \n",
    "        #Configurações do Eixo X - Valores - Cor:\n",
    "        eixos[0, indice_variavel_temporal].set_xticklabels(rotulos_variaveis_temporais, color='black')\n",
    "        eixos[0, indice_variavel_temporal].set_xticks(range(len(rotulos_variaveis_temporais)))\n",
    "        eixos[0, indice_variavel_temporal].tick_params(axis='x', colors='black')\n",
    "\n",
    "        #Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "        eixos[0, indice_variavel_temporal].set_ylabel(\"Número de Registos\", color='black', fontsize=10)\n",
    "\n",
    "\n",
    "        #Configurações do Eixo Y - Valores - Cor:\n",
    "        eixos[0, indice_variavel_temporal].tick_params(axis='y', colors='black')\n",
    "\n",
    "        #Configurações do Eixo Y - Limites Mínimo e Máximo:\n",
    "        if niveis_detalhe[indice_variavel_temporal] == \"Ano\":\n",
    "            eixos[0, indice_variavel_temporal].set_ylim(0, 20000)\n",
    "\n",
    "        #Configurações do Eixo Y - Formatações:\n",
    "        eixos[0, indice_variavel_temporal].yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'.replace(\",\", \".\")))\n",
    "\n",
    "        #Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "        for margem in ['top', 'right', 'bottom', 'left']:\n",
    "            eixos[0, indice_variavel_temporal].spines[margem].set_color('black')\n",
    "            eixos[0, indice_variavel_temporal].spines[margem].set_linewidth(2.5)\n",
    "\n",
    "    #Resultados - Mostrar os Gráficos de Barras:\n",
    "    plt.show()\n",
    "\n",
    "#Obter os Tipos de Variáveis:\n",
    "tipos_variaveis: dict[str, list] = get_variable_types(conjunto_dados)\n",
    "\n",
    "#Derivar os Componentes Temporais a partir da variavel Temporal Date:\n",
    "componentes_temporais: pd.DataFrame = funcao_derivar_componentes_temporais(conjunto_dados, tipos_variaveis[\"date\"])\n",
    "\n",
    "#Iterar sobre as Variáveis Temporais para Análise:\n",
    "for variavel_temporal in tipos_variaveis[\"date\"]:\n",
    "\n",
    "    #Chamar Função para Criar Gráficos de Barras e Analisar a Granularidade Temporal:\n",
    "    funcao_criar_graficos_barras_analisar_granularidade_temporal(componentes_temporais, variavel_temporal, [\"Ano\", \"Mês\", \"Dia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8220739",
   "metadata": {},
   "source": [
    "<H5>1.6. Esparsidade:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525a50d",
   "metadata": {},
   "source": [
    "<H5>1.6.1. Gráficos de Dispersão entre as Variáveis - 1 Classe:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Pyplot da Biblioteca Matplotlib, Importar as Funções Mostrar e Subgráficos:\n",
    "from matplotlib.pyplot import show, subplots\n",
    "\n",
    "#A partir do Submódulo Figure da Biblioteca Matplotlib, Importar a Classe Figura:\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "#Importar a Biblioteca Numpy:\n",
    "import numpy as np\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Remover os Registos com Valores Omissos:\n",
    "conjunto_dados = conjunto_dados.dropna()\n",
    "\n",
    "#Converter os Nomes das Variáveis numa Lista:\n",
    "lista_variaveis: list = conjunto_dados.columns.to_list()\n",
    "\n",
    "#Verificar Se Existem Variáveis na Lista:\n",
    "if lista_variaveis:\n",
    "    \n",
    "    #Calcular o Número de Variáveis da Lista:\n",
    "    numero_variaveis: int = len(lista_variaveis)\n",
    "    \n",
    "    #Definir o Objeto para a Figura:\n",
    "    figura: Figure\n",
    "    \n",
    "    #Definir a Estrutura para os Eixos dos Gráficos de Dispersão:\n",
    "    eixos_graficos_dispersao: np.ndarray\n",
    "    \n",
    "    #Definir a Altura dos Gráficos de Dispersão:\n",
    "    altura_graficos_dispersao = 5\n",
    "\n",
    "    #Criar os Gráficos de Dispersão com Dimensões Ajustadas ao Número de Variáveis e à Altura:\n",
    "    figura, eixos_graficos_dispersao = subplots(numero_variaveis, numero_variaveis, figsize=(numero_variaveis * altura_graficos_dispersao, numero_variaveis * altura_graficos_dispersao), squeeze=False)\n",
    "\n",
    "    #Configurações da Figura - Título Geral - Designação, Cor e Tamanho:\n",
    "    figura.suptitle(\"\\nConjunto de Dados 1 - Gráficos de Dispersão entre as Variáveis - 1 Classe\", color='black', fontsize=170)\n",
    "\n",
    "    #Iterar sobre os indices das Variáveis da Lista para o Eixo X:\n",
    "    for indice_eixo_X in range(len(lista_variaveis)):\n",
    "        \n",
    "        #Selecionar a variavel do Eixo X com base no indice:\n",
    "        variavel_eixo_X: str = lista_variaveis[indice_eixo_X]\n",
    "        \n",
    "        #Iterar sobre os indices das Variáveis da Lista para o Eixo Y:\n",
    "        for indice_eixo_Y in range(len(lista_variaveis)):\n",
    "           \n",
    "            #Se a Posição For Acima da Diagonal Principal da Matriz de Gráficos de Dispersão:\n",
    "            if indice_eixo_Y > indice_eixo_X:\n",
    "                \n",
    "                #Selecionar a variavel do Eixo Y com base no indice:\n",
    "                variavel_eixo_Y: str = lista_variaveis[indice_eixo_Y]\n",
    "\n",
    "                #Verificar Se o Conjunto de Dados Não Está Vazio Após Remover os Valores Omissos das Variáveis dos Eixos X e Y:\n",
    "                if not conjunto_dados[[variavel_eixo_X, variavel_eixo_Y]].dropna().empty:\n",
    "                    \n",
    "                    #Verificar Se as Variáveis dos Eixos X e Y Têm Mais de 1 Valor Único:\n",
    "                    if conjunto_dados[variavel_eixo_X].nunique() > 1 and conjunto_dados[variavel_eixo_Y].nunique() > 1:\n",
    "\n",
    "                        #Criar os Gráficos de Dispersão - Configurações dos Gráficos de Dispersão - Cor e Transparência:\n",
    "                        eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].scatter(conjunto_dados[variavel_eixo_X], conjunto_dados[variavel_eixo_Y], color='#2ca02c', alpha=0.5)\n",
    "\n",
    "                        #Configurações dos Gráficos de Dispersão - Título - Designação e Cor:\n",
    "                        eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].set_title(f'{variavel_eixo_X} vs {variavel_eixo_Y}', color='black')\n",
    "\n",
    "                        #Configurações do Eixo X - Título - Cor:\n",
    "                        eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].set_xlabel(variavel_eixo_X, color='black')\n",
    "\n",
    "                        #Configurações do Eixo Y - Título - Cor:\n",
    "                        eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].set_ylabel(variavel_eixo_Y, color='black')\n",
    "\n",
    "                    #Senão: Desativar a Exibição dos Gráficos de Dispersão Quando Não Existir Variação Suficiente nas Variáveis:\n",
    "                    else:\n",
    "                        eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].axis('off')\n",
    "                        \n",
    "                        #Variável do Eixo X E/Ou variavel do Eixo Y Não Tem/Têm Variação Suficiente Para Criar um Gráfico de Dispersão:\n",
    "                        print(f\"variavel {variavel_eixo_X} E/Ou variavel {variavel_eixo_Y} Não Tem/Têm Variação Suficiente Para Criar um Gráfico de Dispersão.\")\n",
    "\n",
    "                #Senão: Não Existem Dados Suficientes para o Par de Variáveis X e Y:\n",
    "                else:\n",
    "                    eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].axis('off')\n",
    "                    \n",
    "                    #Variável do Eixo X E/Ou variavel do Eixo Y Não Tem/Têm Variação Suficiente Para Criar um Gráfico de Dispersão:\n",
    "                    print(f\"variavel {variavel_eixo_X} E/Ou variavel {variavel_eixo_Y} Não Tem/Têm Variação Suficiente Para Criar um Gráfico de Dispersão.\")\n",
    "\n",
    "            #Senão: Desativar a Exibição dos Gráficos de Dispersão Abaixo da Diagonal Principal:\n",
    "            else:\n",
    "                eixos_graficos_dispersao[indice_eixo_X, indice_eixo_Y].axis('off')\n",
    "\n",
    "    #Resultados - Mostrar os Gráficos de Dispersão:\n",
    "    show()\n",
    "\n",
    "#Senão: Não Existem Variáveis com Variação Suficiente ou com Dados Suficientes para Criar um Gráfico de Dispersão.\n",
    "else:\n",
    "    print(\"Nao Existem Variáveis com Variação Suficiente ou com Dados Suficientes para Criar um Gráfico de Dispersão.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae793c82",
   "metadata": {},
   "source": [
    "<H5>1.6.2. Gráficos de Dispersão entre as Variáveis - Registos por Classe (variavel Alvo):</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add347ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Submódulo Pyplot da Biblioteca Matplotlib, Importar as Funções Mostrar, Subgráficos e Obter a Figura Atual:\n",
    "from matplotlib.pyplot import show, subplots, gcf\n",
    "\n",
    "#A partir do Submódulo Types da Interface de Programação de Aplicações (API) da Biblioteca Pandas, Importar a Função Verificar Se a variavel É Numérica:\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Configurações dos Gráficos de Dispersão - Cor de Preenchimento:\n",
    "cor_preenchimento = 'gray'\n",
    "\n",
    "#Configurações dos Gráficos de Dispersão - Cores da variavel de Agrupamento:\n",
    "cores_variavel_agrupamento = ['#2ca02c', '#ff7f0e']\n",
    "\n",
    "#Definir Função para Criar o Gráfico de Dispersão entre as Variáveis:\n",
    "def funcao_criar_grafico_dispersao_variaveis(dados: pd.DataFrame, variavel_eixo_X: str, variavel_eixo_Y: str, variavel_agrupamento: str = \"\", eixo=None) -> None:\n",
    "\n",
    "    #Configurações dos Gráficos de Dispersão - Título - Designação:\n",
    "    titulo_grafico_dispersao: str = f\"{variavel_eixo_X} x {variavel_eixo_Y}\"\n",
    "\n",
    "    #Verificar Se Existe uma variavel de Agrupamento:\n",
    "    if variavel_agrupamento:\n",
    "\n",
    "        #Adicionar a variavel de Agrupamento ao Título do Gráfico de Dispersão:\n",
    "        titulo_grafico_dispersao += f\" por {variavel_agrupamento}\"\n",
    "\n",
    "        #Verificar Se a variavel de Agrupamento é Numérica:\n",
    "        if is_numeric_dtype(dados[variavel_agrupamento]):\n",
    "\n",
    "            #Criar o Gráfico de Dispersão:\n",
    "            grafico_dispersao = eixo.scatter(dados[variavel_eixo_X], dados[variavel_eixo_Y], c=dados[variavel_agrupamento])\n",
    "\n",
    "            #Adicionar a Barra de Cores ao Gráfico de Dispersão:\n",
    "            barra_cores = gcf().colorbar(grafico_dispersao)\n",
    "            \n",
    "            #Ocultar o Contorno da Barra de Cores:\n",
    "            barra_cores.outline.set_visible(False)\n",
    "\n",
    "            #Adicionar o Rótulo à Barra de Cores:\n",
    "            barra_cores.set_label(variavel_agrupamento, loc=\"top\")\n",
    "\n",
    "        #Senão: Obter os Valores Únicos da variavel de Agrupamento e Ordená-los:\n",
    "        else:\n",
    "            valores_unicos_variavel_agrupamento = sorted(dados[variavel_agrupamento].unique())\n",
    "            \n",
    "            #Iterar sobre os indices e Valores da variavel de Agrupamento:\n",
    "            for indice_variavel_agrupamento, valor_variavel_agrupamento in enumerate(valores_unicos_variavel_agrupamento):\n",
    "                \n",
    "                #Filtrar os Dados com Base no Valor da variavel de Agrupamento:\n",
    "                subconjunto_dados = dados[dados[variavel_agrupamento] == valor_variavel_agrupamento]\n",
    "\n",
    "                #Criar o Gráfico de Dispersão para o Subconjunto de Dados:\n",
    "                eixo.scatter(subconjunto_dados[variavel_eixo_X], subconjunto_dados[variavel_eixo_Y], color=cores_variavel_agrupamento[indice_variavel_agrupamento], label=valor_variavel_agrupamento)\n",
    "\n",
    "            #Configurações da Legenda de Cores - Tamanho:\n",
    "            eixo.legend(fontsize=\"xx-small\")\n",
    "\n",
    "    #Senão: Criar o Gráfico de Dispersão Sem a variavel de Agrupamento:\n",
    "    else:\n",
    "        eixo.scatter(dados[variavel_eixo_X], dados[variavel_eixo_Y], color=cor_preenchimento)\n",
    "    \n",
    "    #Configurações dos Gráficos de Dispersão - Título:\n",
    "    eixo.set_title(titulo_grafico_dispersao)\n",
    "    \n",
    "    #Configurações do Eixo X - Rótulo:\n",
    "    eixo.set_xlabel(variavel_eixo_X)\n",
    "    \n",
    "    #Configurações do Eixo Y - Rótulo:\n",
    "    eixo.set_ylabel(variavel_eixo_Y)\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Remover os Registos com Valores em Falta:\n",
    "conjunto_dados = conjunto_dados.dropna()\n",
    "\n",
    "#Converter os Nomes das Variáveis numa Lista:\n",
    "lista_variaveis = conjunto_dados.columns.to_list()\n",
    "\n",
    "#Verificar Se Existem Variáveis na Lista:\n",
    "if len(lista_variaveis) > 0:\n",
    "\n",
    "    #Criar os Subgráficos com Dimensões Ajustadas ao Número de Variáveis:\n",
    "    figura, eixos_subgraficos = subplots(len(lista_variaveis), len(lista_variaveis), figsize=(10 * len(lista_variaveis), 10 * len(lista_variaveis)), squeeze=False)\n",
    "    \n",
    "    #Configurações dos Gráficos de Dispersão - Título Geral - Designação, Cor e Tamanho:\n",
    "    figura.suptitle(\"\\nConjunto de Dados 1 - Gráficos de Dispersão entre as Variáveis - Registos por Classe (variavel Alvo: Chuva_Amanha)\", color='black', fontsize=200)\n",
    "    \n",
    "    #Definir a Variável Alvo (Chuva_Amanha):\n",
    "    variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "    #Iterar sobre os indices e Nomes das Variáveis para o Eixo X:\n",
    "    for indice_variavel_eixo_X, nome_variavel_eixo_X in enumerate(lista_variaveis):\n",
    "\n",
    "        #Iterar sobre os indices e Nomes das Variáveis para o Eixo Y:\n",
    "        for indice_variavel_eixo_Y, nome_variavel_eixo_Y in enumerate(lista_variaveis):\n",
    "\n",
    "            #Se a Posição For Acima da Diagonal Principal na Matriz de Subgráficos:\n",
    "            if indice_variavel_eixo_Y > indice_variavel_eixo_X:\n",
    "                \n",
    "                #Criar o Gráfico de Dispersão entre as Variáveis:\n",
    "                funcao_criar_grafico_dispersao_variaveis(conjunto_dados, nome_variavel_eixo_X, nome_variavel_eixo_Y, variavel_alvo, eixo=eixos_subgraficos[indice_variavel_eixo_X, indice_variavel_eixo_Y])\n",
    "\n",
    "            #Senão: Desativar a Exibição dos Subgráficos Abaixo da Diagonal Principal na Matriz de Subgráficos:\n",
    "            else:\n",
    "                eixos_subgraficos[indice_variavel_eixo_X, indice_variavel_eixo_Y].axis('off')\n",
    "\n",
    "    #Resultados - Mostrar os Gráficos de Dispersão:\n",
    "    show()\n",
    "\n",
    "#Senão: Não Existem Variáveis com Variação Suficiente ou com Dados Suficientes para Criar um Gráfico de Dispersão.\n",
    "else:\n",
    "    print(\"Não Existem Variáveis com Variação Suficiente ou com Dados Suficientes para Criar um Gráfico de Dispersão.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b66ca2",
   "metadata": {},
   "source": [
    "<H5>1.6.3. Mapa de Calor de Correlação entre as Variáveis (Pós-Codificação):</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar o Submódulo Pyplot da Biblioteca Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importar a Biblioteca Seaborn:\n",
    "import seaborn\n",
    "\n",
    "#Definir o Tipo de Letra dos Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pd.read_csv('conjunto_dados_codificado_final.csv')\n",
    "\n",
    "#Filtrar as Variáveis Numéricas:\n",
    "variaveis_numericas = conjunto_dados.select_dtypes(include='number')\n",
    "\n",
    "#Calcular a Matriz de Correlação:\n",
    "matriz_correlacao = variaveis_numericas.corr()\n",
    "\n",
    "#Configurações do Mapa de Calor de Correlação entre as Variáveis - Figura - Tamanho:\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "#Criar o Mapa de Calor de Correlação entre as Variáveis - Configurações do Mapa de Calor - Cores, Valores Mínimo e Máximo, Largura das Linhas, Formato dos Valores e Tamanho das Anotações:\n",
    "seaborn.heatmap(matriz_correlacao, annot=True, cmap='BrBG', vmin=-1, vmax=1, linecolor='gray', linewidths=0.5, fmt=\".2f\", annot_kws={\"size\": 8})\n",
    "\n",
    "#Configurações do Mapa de Calor - Título Geral - Designação, Cor e Tamanho:\n",
    "plt.title('Conjunto de Dados 1 - Mapa de Calor de Correlação entre as Variáveis (Pós-Codificação)\\n', color='black', fontsize=16)\n",
    "\n",
    "#Configurações do Eixo X - Título - Designação, Cor e Tamanho:\n",
    "plt.xlabel('Variáveis Numéricas', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Rótulos dos Marcadores - Cor, Tamanho e Rotação:\n",
    "plt.xticks(color='black', fontsize=12, rotation=90)\n",
    "\n",
    "#Configurações do Eixo Y - Título - Designação, Cor e Tamanho:\n",
    "plt.ylabel('Variáveis Numéricas', color='black', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulos dos Marcadores - Cor, Tamanho e Rotação:\n",
    "plt.yticks(color='black', fontsize=12, rotation=0)\n",
    "\n",
    "#Resultados - Mostrar o Mapa de Calor:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f9e14",
   "metadata": {},
   "source": [
    "<H4>2. Parte 2 - Preparação dos Dados:</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed20d8",
   "metadata": {},
   "source": [
    "<H5>2.1. Codificação:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e3ff1",
   "metadata": {},
   "source": [
    "<H5>2.1.1. Codificação - Variáveis Categóricas Simbólicas Nominais Binárias (Chuva_Hoje e Chuva_Amanha) - Técnica de Codificação Binária:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f747f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_meteorologia_austrália.csv')\n",
    "\n",
    "#Aplicar a Técnica de Codificação Binária às Variáveis Categóricas Simbólicas Nominais Binárias (Chuva_Hoje e Chuva_Amanha):\n",
    "conjunto_dados['Chuva_Hoje'] = conjunto_dados['Chuva_Hoje'].map({'Nao': 0, 'Sim': 1})\n",
    "conjunto_dados['Chuva_Amanha'] = conjunto_dados['Chuva_Amanha'].map({'Nao': 0, 'Sim': 1})\n",
    "\n",
    "#Guardar o Conjunto de Dados Codificado por Codificação Binária:\n",
    "conjunto_dados.to_csv('conjunto_dados_codificado_binária.csv', index=False)\n",
    "print(\"O Conjunto de Dados Codificado por Codificação Binária Foi Guardado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f4186",
   "metadata": {},
   "source": [
    "<H5>2.1.2. Codificação - variavel Ordinal Temporal (Data) - Técnica de Codificação Extração de Componentes Temporais:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_codificado_binária.csv')\n",
    "\n",
    "#Conversão da variavel Ordinal Temporal Data para o Formato DateTime:\n",
    "conjunto_dados['Data'] = pandas.to_datetime(conjunto_dados['Data'])\n",
    "\n",
    "#Extrair os Componentes Temporais (Ano, Mes e Dia) a partir da variavel Data:\n",
    "conjunto_dados['Ano'] = conjunto_dados['Data'].dt.year\n",
    "conjunto_dados['Mes'] = conjunto_dados['Data'].dt.month\n",
    "conjunto_dados['Dia'] = conjunto_dados['Data'].dt.day\n",
    "\n",
    "#Remover a variavel Original Data:\n",
    "conjunto_dados.drop(columns=['Data'], inplace=True)\n",
    "\n",
    "#Reorganizar as Variáveis para que as Variáveis Ano, Mes e Dia Fiquem no Início:\n",
    "conjunto_dados = conjunto_dados[['Ano', 'Mes', 'Dia'] + [variavel for variavel in conjunto_dados.columns if variavel not in ['Ano', 'Mes', 'Dia']]]\n",
    "\n",
    "#Guardar o Conjunto de Dados Codificado por Extração de Componentes Temporais:\n",
    "conjunto_dados.to_csv('conjunto_dados_codificado_temporal.csv', index=False)\n",
    "print(\"O Conjunto de Dados Codificado por Extração de Componentes Temporais Foi Guardado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568eb04d",
   "metadata": {},
   "source": [
    "<H5>2.1.3. variavel Categórica Simbólica Nominal (Localizacao) - Técnica de Codificação Geoespacial:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_codificado_temporal.csv')\n",
    "\n",
    "#Dicionário das Localizações (Localização: Latitude, Longitude, Altitude):\n",
    "dicionario_localizacoes = {\"Adelaide\": (-34.9285, 138.6007, 48),\n",
    "                           \"Albany\": (-35.0270, 117.8820, 69),\n",
    "                           \"Albury\": (-36.0734, 146.9135, 150),\n",
    "                           \"AliceSprings\": (-23.6980, 133.8807, 545),\n",
    "                           \"BadgerysCreek\": (-33.8833, 150.7333, 60),\n",
    "                           \"Ballarat\": (-37.5640, 143.8500, 450),\n",
    "                           \"Bendigo\": (-36.7590, 144.2807, 300),\n",
    "                           \"Brisbane\": (-27.4698, 153.0251, 20),\n",
    "                           \"Cairns\": (-16.9186, 145.7781, 10),\n",
    "                           \"Canberra\": (-35.2835, 149.1281, 600),\n",
    "                           \"Cobar\": (-31.4980, 145.8389, 260),\n",
    "                           \"CoffsHarbour\": (-30.2975, 153.1130, 25),\n",
    "                           \"Dartmoor\": (-37.9484, 141.5285, 100),\n",
    "                           \"Darwin\": (-12.4628, 130.8418, 10),\n",
    "                           \"GoldCoast\": (-28.0167, 153.4000, 5),\n",
    "                           \"Hobart\": (-42.8821, 147.3272, 100),\n",
    "                           \"Katherine\": (-14.4650, 132.2630, 108),\n",
    "                           \"Launceston\": (-41.4412, 147.1392, 100),\n",
    "                           \"Melbourne\": (-37.8136, 144.9631, 30),\n",
    "                           \"MelbourneAirport\": (-37.6699, 144.8421, 20),\n",
    "                           \"Mildura\": (-34.1850, 142.1480, 50),\n",
    "                           \"Moree\": (-29.4695, 149.8422, 200),\n",
    "                           \"MountGambier\": (-37.8292, 140.7823, 65),\n",
    "                           \"MountGinini\": (-35.5294, 148.7721, 1760),\n",
    "                           \"Newcastle\": (-32.9282, 151.7817, 5),\n",
    "                           \"Nhil\": (-36.4220, 140.9850, 100),\n",
    "                           \"NorahHead\": (-33.3000, 151.5800, 20),\n",
    "                           \"NorfolkIsland\": (-29.0400, 167.9540, 30),\n",
    "                           \"Nuriootpa\": (-34.4664, 138.9260, 100),\n",
    "                           \"PearceRAAF\": (-31.6676, 116.0157, 49),\n",
    "                           \"Penrith\": (-33.7535, 150.6833, 50),\n",
    "                           \"Perth\": (-31.9505, 115.8605, 50),\n",
    "                           \"PerthAirport\": (-31.9352, 115.9672, 20),\n",
    "                           \"Portland\": (-38.3480, 141.5880, 10),\n",
    "                           \"Richmond\": (-33.6000, 150.7400, 40),\n",
    "                           \"Sale\": (-38.1033, 147.0687, 15),\n",
    "                           \"SalmonGums\": (-32.9810, 121.6356, 200),\n",
    "                           \"Sydney\": (-33.8688, 151.2093, 20),\n",
    "                           \"SydneyAirport\": (-33.9399, 151.1753, 10),\n",
    "                           \"Townsville\": (-19.2519, 146.8183, 20),\n",
    "                           \"Tuggeranong\": (-35.4333, 149.0667, 500),\n",
    "                           \"Uluru\": (-25.3444, 131.0369, 600),\n",
    "                           \"WaggaWagga\": (-35.0974, 147.3615, 200),\n",
    "                           \"Walpole\": (-34.9965, 115.7475, 40),\n",
    "                           \"Watsonia\": (-37.6994, 145.1111, 100),\n",
    "                           \"Williamtown\": (-32.7956, 151.8344, 9),\n",
    "                           \"Witchcliffe\": (-34.0771, 115.0518, 30),\n",
    "                           \"Wollongong\": (-34.4278, 150.8931, 5),\n",
    "                           \"Woomera\": (-31.1456, 136.7982, 300)}\n",
    "\n",
    "#Substituir a variavel Categórica Simbólica Nominal Localizacao pelas Variáveis Local_Lat, Local_Long e Local_Alt:\n",
    "conjunto_dados[['Local_Lat', 'Local_Long', 'Local_Alt']] = conjunto_dados['Localizacao'].map(dicionario_localizacoes).apply(pandas.Series)\n",
    "\n",
    "#Remover a variavel Original Localizacao:\n",
    "conjunto_dados.drop('Localizacao', axis=1, inplace=True)\n",
    "\n",
    "#Lista das Variáveis:\n",
    "lista_variaveis = list(conjunto_dados.columns)\n",
    "\n",
    "#Reordenar as Variáveis do Conjunto de Dados:\n",
    "variaveis_temporais = ['Ano', 'Mes', 'Dia']\n",
    "variaveis_geoespaciais = ['Local_Lat', 'Local_Long', 'Local_Alt']\n",
    "lista_variaveis = (variaveis_temporais + variaveis_geoespaciais + [variavel for variavel in lista_variaveis if variavel not in variaveis_temporais + variaveis_geoespaciais])\n",
    "\n",
    "#Reordenar o Conjunto de Dados:\n",
    "conjunto_dados = conjunto_dados[lista_variaveis]\n",
    "\n",
    "#Guardar o Conjunto de Dados Codificado por Codificação Geoespacial:\n",
    "conjunto_dados.to_csv('conjunto_dados_codificado_geoespacial.csv', index=False)\n",
    "print(\"O Conjunto de Dados Codificado por Codificação Geoespacial Foi Guardado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d0a28",
   "metadata": {},
   "source": [
    "<H5>2.1.4. Codificação - Variáveis Categóricas Simbólicas Nominais Circulares (Direcao_Rajada_Vento, Direcao_Vento_09h e Direcao_Vento_15h) - Técnica de Codificação Cíclica:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd21b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_codificado_geoespacial.csv')\n",
    "\n",
    "#Definir Função para Converter as Direções do Vento em Graus:\n",
    "def funcao_converter_direcoes_vento_graus(direcao_vento):\n",
    "    \n",
    "    #Converter as Direções Cardeais do Vento em Graus:\n",
    "    direções_vento = {'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5, 'E': 90, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5, 'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5, 'W': 270,\n",
    "                      'WNW': 292.5, 'NW': 315, 'NNW': 337.5}\n",
    "    \n",
    "    #Devolver as Direções do Vento em Graus:\n",
    "    return direções_vento.get(direcao_vento, numpy.nan)\n",
    "\n",
    "#Converter as Direções do Vento em Graus para as Variáveis Categóricas Simbólicas Nominais Circulares (Direcao_Rajada_Vento, Direcao_Vento_09h e Direcao_Vento_15h):\n",
    "for variavel in ['Direcao_Rajada_Vento', 'Direcao_Vento_09h', 'Direcao_Vento_15h']:\n",
    "    conjunto_dados[variavel] = conjunto_dados[variavel].apply(funcao_converter_direcoes_vento_graus)\n",
    "\n",
    "#Converter as Direções do Vento em Graus para Radianos, utilizando o Seno e o Cosseno, para as Variáveis Circulares:\n",
    "for variavel in ['Direcao_Rajada_Vento', 'Direcao_Vento_09h', 'Direcao_Vento_15h']:\n",
    "    conjunto_dados[f'{variavel}_Sin'] = numpy.sin(numpy.radians(conjunto_dados[variavel]))\n",
    "    conjunto_dados[f'{variavel}_Cos'] = numpy.cos(numpy.radians(conjunto_dados[variavel]))\n",
    "\n",
    "#Remover as Variáveis Circulares Originais:\n",
    "conjunto_dados = conjunto_dados.drop(columns=['Direcao_Rajada_Vento', 'Direcao_Vento_09h', 'Direcao_Vento_15h'])\n",
    "\n",
    "#Reordenar as Novas Variáveis Circulares Para Que Se Posicionem Após a variavel Velocidade_Vento_15h:\n",
    "lista_variaveis = [variavel for variavel in conjunto_dados.columns if variavel != 'Velocidade_Vento_15h']\n",
    "conjunto_dados = conjunto_dados[['Velocidade_Vento_15h'] + [variavel for variavel in lista_variaveis]]\n",
    "\n",
    "#Remover as Variáveis em Duplicado:\n",
    "conjunto_dados = conjunto_dados.loc[:, ~conjunto_dados.columns.duplicated()]\n",
    "\n",
    "#Guardar o Conjunto de Dados Codificado por Codificação Cíclica:\n",
    "conjunto_dados.to_csv('conjunto_dados_codificado_cíclica.csv', index=False)\n",
    "print(\"O Conjunto de Dados Codificado por Codificação Cíclica Foi Guardado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8237a7c",
   "metadata": {},
   "source": [
    "<H5>2.1.5. Codificação - Reorganizar as Variáveis:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717aa76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_codificado_cíclica.csv')\n",
    "\n",
    "#Obter as Variáveis do Conjunto de Dados:\n",
    "variaveis = conjunto_dados.columns\n",
    "\n",
    "#Definir a Ordem Final das Variáveis:\n",
    "ordem_final_variaveis = ['Ano', 'Mes', 'Dia', 'Local_Lat', 'Local_Long', 'Local_Alt', 'Temperatura_Minima', 'Temperatura_Maxima',\n",
    "                         'Precipitacao', 'Evaporacao', 'Sol', 'Velocidade_Rajada_Vento', 'Velocidade_Vento_09h', 'Velocidade_Vento_15h', 'Direcao_Rajada_Vento_Sin',\n",
    "                         'Direcao_Rajada_Vento_Cos', 'Direcao_Vento_09h_Sin', 'Direcao_Vento_09h_Cos', 'Direcao_Vento_15h_Sin', 'Direcao_Vento_15h_Cos', 'Humidade_09h',\n",
    "                         'Humidade_15h', 'Pressao_Atmosferica_09h', 'Pressao_Atmosferica_15h', 'Nuvens_09h','Nuvens_15h', 'Temperatura_09h', 'Temperatura_15h',\n",
    "                         'Chuva_Hoje', 'Chuva_Amanha']\n",
    "\n",
    "#Reorganizar as Variáveis no Conjunto de Dados:\n",
    "variaveis_reordenadas = [variavel for variavel in ordem_final_variaveis if variavel in variaveis]\n",
    "conjunto_dados = conjunto_dados[variaveis_reordenadas]\n",
    "\n",
    "#Guardar o Conjunto de Dados Codificado:\n",
    "conjunto_dados.to_csv('conjunto_dados_codificado_final.csv', index=False)\n",
    "print(\"O Conjunto de Dados Codificado Foi Guardado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23659aab",
   "metadata": {},
   "source": [
    "<H5>2.2. Divisão do Conjunto de Dados Total em Conjunto de Treino (70%) e Conjunto de Teste (30%) - Técnica de Divisão Hold-Out:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Model_Selection, Importar Função Dividir Conjunto de Dados em Conjunto de Treino e Conjunto de Teste:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Ler o Conjunto de Dados:\n",
    "conjunto_dados = pandas.read_csv('conjunto_dados_codificado_final.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Preencher os Valores em Falta da variavel Alvo com o Valor da Sua Moda:\n",
    "variavel_alvo_moda = conjunto_dados[variavel_alvo].mode()[0]\n",
    "conjunto_dados[variavel_alvo] = conjunto_dados[variavel_alvo].fillna(variavel_alvo_moda)\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Dados Total:\n",
    "X = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "Y = conjunto_dados[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Dados Total em Conjunto de Treino e Conjunto de Teste:\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "#Calcular o Número de Registos do Conjunto de Dados Total:\n",
    "conjunto_dados_numero_registos = conjunto_dados.shape[0]\n",
    "\n",
    "#Calcular e Mostrar o Número de Registos do Conjunto de Treino:\n",
    "conjunto_treino_numero_registos = X_treino.shape[0]\n",
    "print(f\"Número de Registos do Conjunto de Treino: {conjunto_treino_numero_registos:,}\".replace(\",\", \".\"))\n",
    "\n",
    "#Calcular e Mostrar a Percentagem de Registos do Conjunto de Treino:\n",
    "conjunto_treino_percentagem = (conjunto_treino_numero_registos / conjunto_dados_numero_registos) * 100\n",
    "print(f\"Percentagem de Registos do Conjunto de Treino: {conjunto_treino_percentagem:.0f}%\")\n",
    "\n",
    "#Combinar as Variáveis Preditoras e a variavel Alvo no Conjunto de Treino:\n",
    "conjunto_treino = pandas.concat([X_treino, Y_treino], axis=1)\n",
    "\n",
    "#Calcular e Mostrar o Número de Registos do Conjunto de Teste:\n",
    "conjunto_teste_registos = X_teste.shape[0]\n",
    "print(f\"\\nNúmero de Registos do Conjunto de Teste: {conjunto_teste_registos:,}\".replace(\",\", \".\"))\n",
    "\n",
    "#Calcular e Mostrar a Percentagem de Registos do Conjunto de Teste:\n",
    "conjunto_teste_percentagem = (conjunto_teste_registos / conjunto_dados_numero_registos) * 100\n",
    "print(f\"Percentagem de Registos do Conjunto de Teste: {conjunto_teste_percentagem:.0f}%\")\n",
    "\n",
    "#Combinar as Variáveis Preditoras e a variavel Alvo no Conjunto de Teste:\n",
    "conjunto_teste = pandas.concat([X_teste, Y_teste], axis=1)\n",
    "\n",
    "#Guardar os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino.to_csv('conjunto_treino.csv', index=False)\n",
    "conjunto_teste.to_csv('conjunto_teste.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Foram Guardados com Sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367799e9",
   "metadata": {},
   "source": [
    "<H5>2.3. Tratamento dos Valores em Falta:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d41a7f",
   "metadata": {},
   "source": [
    "<H5>2.3.1. Tratamento dos Valores em Falta - Verificar o Número de Valores em Falta:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Calcular o Número Total de Registos do Conjunto de Treino:\n",
    "conjunto_treino_total_registos = conjunto_treino.shape[0]\n",
    "\n",
    "#Calcular o Número Total de Registos com Valores em Falta do Conjunto de Treino:\n",
    "conjunto_treino_total_registos_valores_falta = conjunto_treino.isnull().any(axis=1).sum()\n",
    "\n",
    "#Calcular a Percentagem de Registos com Valores em Falta do Conjunto de Treino:\n",
    "conjunto_treino_percentagem_valores_falta = (conjunto_treino_total_registos_valores_falta / conjunto_treino_total_registos) * 100\n",
    "\n",
    "#Resultados - Número Total de Registos, Número Total de Registos com Valores em Falta e Percentagem de Registos com Valores em Falta do Conjunto de Treino:\n",
    "print(f\"Número Total de Registos do Conjunto de Treino: {conjunto_treino_total_registos:,.0f}\".replace(\",\", \".\"))\n",
    "print(f\"Número Total de Registos com Valores em Falta do Conjunto de Treino: {conjunto_treino_total_registos_valores_falta:,.0f}\".replace(\",\", \".\"))\n",
    "print(f\"Percentagem de Registos com Valores em Falta do Conjunto de Treino: {conjunto_treino_percentagem_valores_falta:.0f}%\")\n",
    "\n",
    "#Calcular o Número Total de Registos do Conjunto de Teste:\n",
    "conjunto_teste_total_registos = conjunto_teste.shape[0] \n",
    "\n",
    "#Calcular o Número Total de Registos com Valores em Falta do Conjunto de Teste:\n",
    "conjunto_teste_total_registos_valores_falta = conjunto_teste.isnull().any(axis=1).sum()\n",
    "\n",
    "#Calcular a Percentagem de Registos com Valores em Falta do Conjunto de Teste:\n",
    "conjunto_teste_percentagem_valores_falta = (conjunto_teste_total_registos_valores_falta / conjunto_teste_total_registos) * 100\n",
    "\n",
    "#Resultados - Número Total de Registos, Número Total de Registos com Valores em Falta e Percentagem de Registos com Valores em Falta do Conjunto de Teste:\n",
    "print(f\"\\nNúmero Total de Registos do Conjunto de Teste: {conjunto_teste_total_registos:,.0f}\".replace(\",\", \".\"))\n",
    "print(f\"Número Total de Registos com Valores em Falta do Conjunto de Teste: {conjunto_teste_total_registos_valores_falta:,.0f}\".replace(\",\", \".\"))\n",
    "print(f\"Percentagem de Registos com Valores em Falta do Conjunto de Teste: {conjunto_teste_percentagem_valores_falta:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3e422",
   "metadata": {},
   "source": [
    "<H5>2.3.2. Tratamento dos Valores em Falta - Abordagem de Remoção de Valores em Falta - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0640c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes, Importar o Modelo Classificador de Naïves Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Remover Todos os Registos com Valores em Falta:\n",
    "def funcao_remover_registos_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    conjunto_dados_sem_valores_falta = variaveis_preditoras.notnull().all(axis=1) & variavel_alvo.notnull()\n",
    "    variaveis_preditoras = variaveis_preditoras[conjunto_dados_sem_valores_falta]\n",
    "    variavel_alvo = variavel_alvo[conjunto_dados_sem_valores_falta]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Verificar Se Ainda Existem Valores em Falta nas Variáveis Preditoras e na variavel Alvo:\n",
    "def funcao_verificar_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    if variaveis_preditoras.isnull().sum().sum() > 0 or variavel_alvo.isnull().sum() > 0:\n",
    "        return \"Ainda Existem Valores em Falta.\"\n",
    "    else:\n",
    "        return \"Todos os Valores em Falta Foram Removidos com Sucesso.\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino, variavel_alvo_treino = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Remover Todos os Registos com Valores em Falta do Conjunto de Treino:\n",
    "variaveis_preditoras_treino_remocao, variavel_alvo_treino_remocao = funcao_remover_registos_valores_falta(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Treino:\n",
    "print(\"Conjunto de Treino:\", funcao_verificar_valores_falta(variaveis_preditoras_treino_remocao, variavel_alvo_treino_remocao))\n",
    "\n",
    "#Dividir os Dados em Variaveis Preditoras e Variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Remover Todos os Registos com Valores em Falta do Conjunto de Teste:\n",
    "variaveis_preditoras_teste_remocao, variavel_alvo_teste_remocao = funcao_remover_registos_valores_falta(variaveis_preditoras_teste, variavel_alvo_teste)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Teste:\n",
    "print(\"\\nConjunto de Teste:\", funcao_verificar_valores_falta(variaveis_preditoras_teste_remocao, variavel_alvo_teste_remocao))\n",
    "\n",
    "#Guardar os Conjuntos de Treino e de Teste Sem Valores em Falta:\n",
    "conjunto_treino_sem_valores_falta_remocao = pandas.concat([variaveis_preditoras_treino_remocao, variavel_alvo_treino_remocao], axis=1).to_csv('conjunto_treino_sem_valores_falta_remocao.csv', index=False)\n",
    "conjunto_teste_sem_valores_falta_remocao = pandas.concat([variaveis_preditoras_teste_remocao, variavel_alvo_teste_remocao], axis=1).to_csv('conjunto_dados_sem_valores_falta_remocao.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Sem Valores em Falta Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_remocao, variavel_alvo_treino_remocao)\n",
    "\n",
    "#Fazer Previsoes no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_prevista_teste_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste_remocao)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste_remocao)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_teste_remocao, variavel_alvo_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_remocao, variavel_alvo_treino_remocao)\n",
    "\n",
    "#Fazer Previsoes no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_prevista_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(variaveis_preditoras_teste_remocao)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_probabilidades_previstas_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste_remocao)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste_remocao, variavel_alvo_probabilidades_previstas_teste_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(variavel_alvo_teste_remocao, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32d535",
   "metadata": {},
   "source": [
    "<H5>2.3.3. Tratamento dos Valores em Falta - Abordagem de Imputação dos Valores em Falta utilizando a media - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Preencher os Valores em Falta:\n",
    "def funcao_preencher_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    \n",
    "    #Preencher os Valores em Falta da variavel Preditora Binária (Chuva_Hoje) com o Valor da Moda:\n",
    "    for variavel in ['Chuva_Hoje']:\n",
    "        if variavel in variaveis_preditoras.columns:\n",
    "            moda = variaveis_preditoras[variavel].mode()[0]\n",
    "            variaveis_preditoras[variavel] = variaveis_preditoras[variavel].fillna(moda)\n",
    "    \n",
    "    #Preencher os Valores em Falta das Restantes Variáveis Preditoras com o Valor da media:\n",
    "    for variavel in variaveis_preditoras.columns:\n",
    "        if variavel not in ['Chuva_Hoje', 'Chuva_Amanha']:\n",
    "            media = variaveis_preditoras[variavel].mean()\n",
    "            variaveis_preditoras[variavel] = variaveis_preditoras[variavel].fillna(media)\n",
    "    \n",
    "    #Preencher os Valores em Falta da Variável Alvo (Chuva_Amanha) com o Valor da Moda:\n",
    "    moda = variavel_alvo.mode()[0]\n",
    "    variavel_alvo = variavel_alvo.fillna(moda)\n",
    "        \n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Verificar Se Ainda Existem Valores em Falta:\n",
    "def funcao_verificar_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    if variaveis_preditoras.isnull().sum().sum() > 0 or variavel_alvo.isnull().sum() > 0:\n",
    "        return \"Ainda Existem Valores em Falta.\"\n",
    "    else:\n",
    "        return \"Todos os Valores em Falta Foram Preenchidos com Sucesso através da Imputação pela Média.\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino, variavel_alvo_treino = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Preencher os Valores em Falta no Conjunto de Treino:\n",
    "variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Treino:\n",
    "print(\"Conjunto de Treino:\", funcao_verificar_valores_falta(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida))\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Preencher os Valores em Falta no Conjunto de Teste:\n",
    "variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_teste, variavel_alvo_teste)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Teste:\n",
    "print(\"\\nConjunto de Teste:\", funcao_verificar_valores_falta(variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida))\n",
    "\n",
    "#Guardar os Conjuntos de Treino e de Teste Sem Valores em Falta:\n",
    "pandas.concat([variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida], axis=1).to_csv('conjunto_treino_sem_valores_falta_media.csv', index=False)\n",
    "pandas.concat([variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida], axis=1).to_csv('conjunto_teste_sem_valores_falta_media.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Sem Valores em Falta Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN:\n",
    "modelo_knn.fit(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de KNN:\n",
    "variavel_prevista_knn = modelo_knn.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_knn = modelo_knn.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de KNN:\n",
    "exatidao_knn = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "sensibilidade_knn = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "precisao_knn = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "auc_knn = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_knn)\n",
    "f1_knn = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_knn:.2f}\")\n",
    "print(f\"AUC: {auc_knn:.2f}\")\n",
    "print(f\"F1: {f1_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de Naïve Bayes Bernoulli:\n",
    "variavel_prevista_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de Naïve Bayes Bernoulli:\n",
    "exatidao_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_naive_bayes_bernoulli = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "precisao_naive_bayes_bernoulli = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "auc_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_naive_bayes_bernoulli)\n",
    "f1_naive_bayes_bernoulli = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39473ef",
   "metadata": {},
   "source": [
    "<H5>2.3.4. Tratamento dos Valores em Falta - Abordagem de Imputação dos Valores em Falta utilizando a Mediana - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Preencher os Valores em Falta:\n",
    "def funcao_preencher_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    \n",
    "    #Preencher os Valores em Falta da variavel Preditora Binária (Chuva_Hoje) com o Valor da Moda:\n",
    "    for variavel in ['Chuva_Hoje']:\n",
    "        if variavel in variaveis_preditoras.columns:\n",
    "            moda = variaveis_preditoras[variavel].mode()[0]\n",
    "            variaveis_preditoras[variavel] = variaveis_preditoras[variavel].fillna(moda)\n",
    "    \n",
    "    #Preencher os Valores em Falta das Restantes Variáveis Preditoras com o Valor da Mediana:\n",
    "    for variavel in variaveis_preditoras.columns:\n",
    "        if variavel not in ['Chuva_Hoje', 'Chuva_Amanha']:\n",
    "            mediana = variaveis_preditoras[variavel].median()\n",
    "            variaveis_preditoras[variavel] = variaveis_preditoras[variavel].fillna(mediana)\n",
    "    \n",
    "    #Preencher os Valores em Falta da Variável Alvo (Chuva_Amanha) com o Valor da Moda:\n",
    "    moda = variavel_alvo.mode()[0]\n",
    "    variavel_alvo = variavel_alvo.fillna(moda)\n",
    "        \n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Verificar Se Ainda Existem Valores em Falta:\n",
    "def funcao_verificar_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    if variaveis_preditoras.isnull().sum().sum() > 0 or variavel_alvo.isnull().sum() > 0:\n",
    "        return \"Ainda Existem Valores em Falta.\"\n",
    "    else:\n",
    "        return \"Todos os Valores em Falta Foram Preenchidos com Sucesso através da Imputação pela Mediana.\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino, variavel_alvo_treino = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Preencher os Valores em Falta no Conjunto de Treino:\n",
    "variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Treino:\n",
    "print(\"Conjunto de Treino:\", funcao_verificar_valores_falta(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida))\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Preencher os Valores em Falta no Conjunto de Teste:\n",
    "variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_teste, variavel_alvo_teste)\n",
    "\n",
    "#Verificar Se Ainda Existem Valores em Falta no Conjunto de Teste:\n",
    "print(\"\\nConjunto de Teste:\", funcao_verificar_valores_falta(variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida))\n",
    "\n",
    "#Guardar os Conjuntos de Treino e de Teste Sem Valores em Falta:\n",
    "pandas.concat([variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida], axis=1).to_csv('conjunto_treino_sem_valores_falta_mediana.csv', index=False)\n",
    "pandas.concat([variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida], axis=1).to_csv('conjunto_teste_sem_valores_falta_mediana.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Sem Valores em Falta Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN:\n",
    "modelo_knn.fit(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o KNN:\n",
    "variavel_prevista_knn = modelo_knn.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_knn = modelo_knn.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o KNN:\n",
    "exatidao_knn = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "sensibilidade_knn = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "precisao_knn = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "auc_knn = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_knn)\n",
    "f1_knn = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_knn:.2f}\")\n",
    "print(f\"AUC: {auc_knn:.2f}\")\n",
    "print(f\"F1: {f1_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Naïve Bayes Bernoulli:\n",
    "variavel_prevista_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Naïve Bayes Bernoulli:\n",
    "exatidao_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_naive_bayes_bernoulli = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "precisao_naive_bayes_bernoulli = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "auc_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_naive_bayes_bernoulli)\n",
    "f1_naive_bayes_bernoulli = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248081a7",
   "metadata": {},
   "source": [
    "<H5>2.3.5. Tratamento dos Valores em Falta - Abordagem de Imputação dos Valores em Falta utilizando a Moda - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58aa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do Submódulo Neighbors da Biblioteca Scikit-Learn, Importar o Modelo Classificador de K-Nearest Neighbors (KNN):\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do Submódulo Naïve_Bayes da Biblioteca Scikit-Learn, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do Submódulo Metrics da Biblioteca Scikit-Learn, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Preencher os Valores em Falta do Conjunto de Treino com o Valor da Moda:\n",
    "conjunto_treino_preenchido_moda = conjunto_treino.fillna(conjunto_treino.mode().iloc[0])\n",
    "\n",
    "#Preencher os Valores em Falta do Conjunto de Teste com o Valor da Moda:\n",
    "conjunto_teste_preenchido_moda = conjunto_teste.fillna(conjunto_teste.mode().iloc[0])\n",
    "\n",
    "#Definir Função para Verificar Se Ainda Existem Valores em Falta:\n",
    "def funcao_verificar_valores_falta(conjunto):\n",
    "    total_valores_falta = conjunto.isnull().sum().sum()\n",
    "    if total_valores_falta == 0:\n",
    "        return \"Já Não Existem Valores em Falta Após a Imputação pela Moda.\"\n",
    "    else:\n",
    "        return f\"Ainda Existem {total_valores_falta} Valores em Falta Após a Imputação pela Moda.\"\n",
    "\n",
    "#Verificar Valores em Falta no Conjunto de Treino:\n",
    "print(\"Conjunto de Treino:\", funcao_verificar_valores_falta(conjunto_treino_preenchido_moda))\n",
    "\n",
    "#Verificar Valores em Falta no Conjunto de Teste:\n",
    "print(\"\\nConjunto de Teste:\", funcao_verificar_valores_falta(conjunto_teste_preenchido_moda))\n",
    "\n",
    "#Guardar os Conjuntos Sem Valores em Falta:\n",
    "conjunto_treino_preenchido_moda.to_csv('conjunto_treino_sem_valores_em_falta_imputação_moda.csv', index=False)\n",
    "conjunto_teste_preenchido_moda.to_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Sem Valores em Falta Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir o Conjunto de Treino Sem Valores em Falta em Variáveis Preditoras e variavel Alvo:\n",
    "variaveis_preditoras_treino = conjunto_treino_preenchido_moda.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_treino = conjunto_treino_preenchido_moda[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Teste Sem Valores em Falta em Variáveis Preditoras e variavel Alvo:\n",
    "variaveis_preditoras_teste = conjunto_teste_preenchido_moda.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_teste = conjunto_teste_preenchido_moda[variavel_alvo]\n",
    "\n",
    "#Definir o Modelo Classificador de KNN com k=5:\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN:\n",
    "modelo_knn.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de KNN:\n",
    "variavel_prevista_knn = modelo_knn.predict(variaveis_preditoras_teste)\n",
    "variavel_probabilidade_knn = modelo_knn.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de KNN - Conjunto de Teste:\n",
    "exatidao_knn = accuracy_score(variavel_alvo_teste, variavel_prevista_knn)\n",
    "sensibilidade_knn = recall_score(variavel_alvo_teste, variavel_prevista_knn)\n",
    "precisao_knn = precision_score(variavel_alvo_teste, variavel_prevista_knn)\n",
    "auc_knn = roc_auc_score(variavel_alvo_teste, variavel_probabilidade_knn)\n",
    "f1_knn = f1_score(variavel_alvo_teste, variavel_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_knn:.2f}\")\n",
    "print(f\"AUC: {auc_knn:.2f}\")\n",
    "print(f\"F1: {f1_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes:\n",
    "modelo_naive_bayes.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de Naïve Bayes Bernoulli:\n",
    "variavel_prevista_Naïve_bayes = modelo_naive_bayes.predict(variaveis_preditoras_teste)\n",
    "variavel_probabilidade_Naïve_bayes = modelo_naive_bayes.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_Naïve_bayes = accuracy_score(variavel_alvo_teste, variavel_prevista_Naïve_bayes)\n",
    "sensibilidade_Naïve_bayes = recall_score(variavel_alvo_teste, variavel_prevista_Naïve_bayes)\n",
    "precisao_Naïve_bayes = precision_score(variavel_alvo_teste, variavel_prevista_Naïve_bayes)\n",
    "auc_Naïve_bayes = roc_auc_score(variavel_alvo_teste, variavel_probabilidade_Naïve_bayes)\n",
    "f1_Naïve_bayes = f1_score(variavel_alvo_teste, variavel_prevista_Naïve_bayes)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_Naïve_bayes:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_Naïve_bayes:.2f}\")\n",
    "print(f\"precisao: {precisao_Naïve_bayes:.2f}\")\n",
    "print(f\"AUC: {auc_Naïve_bayes:.2f}\")\n",
    "print(f\"F1: {f1_Naïve_bayes:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d339461",
   "metadata": {},
   "source": [
    "<H5>2.3.6. Tratamento dos Valores em Falta - Abordagem de Imputação dos Valores em Falta utilizando o Imputador KNN - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas: \n",
    "import pandas\n",
    "\n",
    "#A partir do Submódulo Neighbors da Biblioteca Scikit-Learn, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do Submódulo Impute da Biblioteca Scikit-Learn, Importar o Imputador KNN:\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#A partir do Submódulo Naïve_Bayes da Biblioteca Scikit-Learn, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do Submódulo Metrics da Biblioteca Scikit-Learn, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_dividir_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Preencher os Valores em Falta:\n",
    "def funcao_preencher_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    \n",
    "    #Preencher os Valores em Falta da variavel Preditora Binária (Chuva_Hoje) com o Valor da Moda:\n",
    "    if 'Chuva_Hoje' in variaveis_preditoras.columns:\n",
    "        moda = variaveis_preditoras['Chuva_Hoje'].mode()[0]\n",
    "        variaveis_preditoras['Chuva_Hoje'] = variaveis_preditoras['Chuva_Hoje'].fillna(moda)\n",
    "    \n",
    "    #Preencher os Valores em Falta das Restantes Variáveis Preditoras com o Imputador KNN:\n",
    "    imputador_knn = KNNImputer()\n",
    "    variaveis_preditoras = pandas.DataFrame(imputador_knn.fit_transform(variaveis_preditoras), columns=variaveis_preditoras.columns)\n",
    "    \n",
    "    #Preencher os Valores em Falta da variavel Alvo com o Valor da Moda:\n",
    "    moda = variavel_alvo.mode()[0]\n",
    "    variavel_alvo = variavel_alvo.fillna(moda)\n",
    "    \n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Definir Função para Verificar Se Ainda Existem Valores em Falta:\n",
    "def funcao_verificar_valores_falta(variaveis_preditoras, variavel_alvo):\n",
    "    if variaveis_preditoras.isnull().sum().sum() > 0 or variavel_alvo.isnull().sum() > 0:\n",
    "        return \"Ainda Existem Valores em Falta.\"\n",
    "    else:\n",
    "        return \"Todos os Valores em Falta Foram Preenchidos com Sucesso.\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Conjuntos em Variáveis Preditoras e variavel Alvo:\n",
    "variaveis_preditoras_treino, variavel_alvo_treino = funcao_dividir_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_dividir_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Preencher os Valores em Falta nos Conjuntos:\n",
    "variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida = funcao_preencher_valores_falta(variaveis_preditoras_teste, variavel_alvo_teste)\n",
    "\n",
    "#Verificar Valores em Falta:\n",
    "print(\"Conjunto de Treino:\", funcao_verificar_valores_falta(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida))\n",
    "print(\"Conjunto de Teste:\", funcao_verificar_valores_falta(variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida))\n",
    "\n",
    "#Guardar os Conjuntos Sem Valores em Falta:\n",
    "pandas.concat([variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida], axis=1).to_csv('conjunto_treino_sem_valores_falta_imputador_knn.csv', index=False)\n",
    "pandas.concat([variaveis_preditoras_teste_preenchidas, variavel_alvo_teste_preenchida], axis=1).to_csv('conjunto_teste_sem_valores_falta_imputador_knn.csv', index=False)\n",
    "print(\"\\nOs Conjuntos de Treino e de Teste Sem Valores em Falta Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Definir o Modelo Classificador de KNN com k=5:\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN:\n",
    "modelo_knn.fit(variaveis_preditoras_treino_preenchidas, variavel_alvo_treino_preenchida)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de KNN:\n",
    "variavel_prevista_knn = modelo_knn.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_knn = modelo_knn.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de KNN - Conjunto de Teste:\n",
    "exatidao_knn = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "sensibilidade_knn = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "precisao_knn = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "auc_knn = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_knn)\n",
    "f1_knn = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_knn:.2f}\")\n",
    "print(f\"AUC: {auc_knn:.2f}\")\n",
    "print(f\"F1: {f1_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_naive_bayes_bernoulli.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer Previsões e Calcular Probabilidades no Conjunto de Teste para o Modelo de Naïve Bayes Bernoulli:\n",
    "variavel_prevista_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict(variaveis_preditoras_teste_preenchidas)\n",
    "variavel_probabilidade_naive_bayes_bernoulli = modelo_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste_preenchidas)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_naive_bayes_bernoulli = recall_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "precisao_naive_bayes_bernoulli = precision_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "auc_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste_preenchida, variavel_probabilidade_naive_bayes_bernoulli)\n",
    "f1_naive_bayes_bernoulli = f1_score(variavel_alvo_teste_preenchida, variavel_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292b3d1",
   "metadata": {},
   "source": [
    "<H5>2.3.7. Tratamento dos Valores em Falta - Abordagens de Remoção e Imputação dos Valores em Falta - Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ed51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Submódulo Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Abordagens de Remoção/Imputação dos Valores em Falta:\n",
    "modelos_abordagens_remocao_imputacao_valores_falta = ['KNN - Remoção dos Valores em Falta', 'KNN - Imputação pela media', 'KNN - Imputação pela Mediana',\n",
    "                                                      'KNN - Imputação pela Moda', 'KNN - Imputação pelo Imputador KNN', 'Naïve Bayes Bernoulli - Remoção dos Valores em Falta', \n",
    "                                                      'Naïve Bayes Bernoulli - Imputação pela media', 'Naïve Bayes Bernoulli - Imputação pela Mediana',\n",
    "                                                      'Naïve Bayes Bernoulli - Imputação pela Moda','Naïve Bayes Bernoulli - Imputação pelo Imputador KNN']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.85, 0.84, 0.84, 0.84, 0.84, 0.77, 0.77, 0.77, 0.77, 0.77]\n",
    "sensibilidade = [0.51, 0.49, 0.49, 0.50, 0.49, 0.44, 0.41, 0.42, 0.44, 0.41]\n",
    "precisao = [0.70, 0.69, 0.69, 0.68, 0.68, 0.48, 0.47, 0.47, 0.46, 0.47]\n",
    "auc = [0.84, 0.82, 0.82, 0.82, 0.82, 0.73, 0.73, 0.73, 0.72, 0.73]\n",
    "f1 = [0.59, 0.57, 0.57, 0.58, 0.57, 0.46, 0.44, 0.44, 0.45, 0.44]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título Geral, Espaçamento, Cor, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(16, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação dos Modelos Classificadores de KNN e Naïve Bayes Bernoulli para Abordagens de Remoção/Imputação dos Valores em Falta', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Dicionário, Cores, Largura e indice:\n",
    "dicionario_barras = {\"Exatidão\": exatidao, \"Sensibilidade\": sensibilidade, \"Precisão\": precisao, \"AUC\": auc, \"F1\": f1}\n",
    "cores_barras = [\"#ff7f0e\", \"#ffdd57\", \"#2ca02c\", \"#87CEEB\", \"#9467bd\"]\n",
    "largura_barras = 0.15\n",
    "indice_barras = numpy.arange(len(modelos_abordagens_remocao_imputacao_valores_falta))\n",
    "\n",
    "#Definir os Offsets X para cada Métrica de Avaliação:\n",
    "offset_X = {\"Exatidão\": 0, \"Sensibilidade\": -0.05, \"Precisão\": -0.05, \"AUC\": 0, \"F1\": 0.07}\n",
    "\n",
    "#Definir os Offsets Y para cada Métrica de Avaliação:\n",
    "offset_Y = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": 0.01, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Iterar sobre as Métricas de Avaliação e seus Respetivos Valores no Dicionário de Barras:\n",
    "for posicao_X, (metrica_avaliacao, valores) in enumerate(dicionario_barras.items()):\n",
    "    \n",
    "    #Criar Barras:\n",
    "    barras = matplotlib.pyplot.bar(indice_barras + posicao_X * largura_barras, valores, largura_barras, label=metrica_avaliacao, color=cores_barras[posicao_X])\n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras:\n",
    "        \n",
    "        #Definir Altura de cada Barra:\n",
    "        altura_y = barra.get_height()\n",
    "        \n",
    "        #Adicionar Valores Acima das Barras - Largura, Altura, Posição, Cor e Tamanho:\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2 + offset_X[metrica_avaliacao], altura_y + offset_Y[metrica_avaliacao], f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Posição e Rotação:\n",
    "matplotlib.pyplot.xlabel('Modelos de KNN e Naïve Bayes Bernoulli - Abordagens de Remoção/Imputação dos Valores em Falta', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, modelos_abordagens_remocao_imputacao_valores_falta, fontsize=14, rotation=45, ha='right', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Intervalo e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=12)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos.spines[margem].set_color('black')\n",
    "    eixos.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda_cores = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda_cores.get_frame().set_edgecolor('grey')\n",
    "legenda_cores.get_frame().set_facecolor('none')\n",
    "legenda_cores.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff837c",
   "metadata": {},
   "source": [
    "<H5>2.4. Tratamento dos Valores Atípicos:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37db50",
   "metadata": {},
   "source": [
    "<H5>2.4.1. Tratamento dos Valores Atípicos - Contabilização dos Valores Atípicos:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b92662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Ler o Conjunto de Treino:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir o Fator do Intervalo Interquartil:\n",
    "fator_intervalo_interquartil = 1.5\n",
    "\n",
    "#Definir o Fator do Desvio Padrão:\n",
    "fator_desvio_padrao = 3\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Treino:\n",
    "variaveis_numericas = conjunto_treino.select_dtypes(include=[numpy.number]).columns\n",
    "\n",
    "#Se Existirem Variáveis Numéricas:\n",
    "if len(variaveis_numericas) > 0:\n",
    "\n",
    "    #Dicionário para Armazenar os Valores Atípicos:\n",
    "    dicionario_valores_atipicos = {'Intervalo Interquartil': [], 'Desvio Padrão': []}\n",
    "\n",
    "    #Iniciar o Número Total de Valores Atípicos - Intervalo Interquartil:\n",
    "    valores_atipicos_total_intervalo_interquartil = 0\n",
    "   \n",
    "    #Iniciar o Número Total de Valores Atípicos - Desvio Padrão:\n",
    "    valores_atipicos_total_desvio_padrao = 0\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "    \n",
    "        #Calcular o 1.º Quartil:\n",
    "        Q1 = conjunto_treino[variavel_numerica].quantile(0.25)\n",
    "        \n",
    "        #Calcular o 3.º Quartil:\n",
    "        Q3 = conjunto_treino[variavel_numerica].quantile(0.75)\n",
    "        \n",
    "        #Calcular o Intervalo Interquartil:\n",
    "        intervalo_interquartil = Q3 - Q1\n",
    "        \n",
    "        #Calcular o Limite Inferior - Intervalo Interquartil:\n",
    "        limite_inferior_intervalo_interquartil = Q1 - fator_intervalo_interquartil * intervalo_interquartil\n",
    "        \n",
    "        #Calcular o Limite Superior - Intervalo Interquartil:\n",
    "        limite_superior_intervalo_interquartil = Q3 + fator_intervalo_interquartil * intervalo_interquartil\n",
    "    \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino - Intervalo Interquartil:\n",
    "        valores_atípicos_intervalo_interquartil = ((conjunto_treino[variavel_numerica] < limite_inferior_intervalo_interquartil) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior_intervalo_interquartil)).sum()\n",
    "    \n",
    "        #Armazenar os Resultados no Dicionário dos Valores Atípicos - Intervalo Interquartil:\n",
    "        dicionario_valores_atipicos['Intervalo Interquartil'].append(valores_atípicos_intervalo_interquartil)\n",
    "\n",
    "        #Acumular o Número Total de Valores Atípicos - Intervalo Interquartil:\n",
    "        valores_atipicos_total_intervalo_interquartil += valores_atípicos_intervalo_interquartil\n",
    "\n",
    "        #Calcular a media:\n",
    "        media = conjunto_treino[variavel_numerica].mean()\n",
    "        \n",
    "        #Calcular o Desvio Padrão:\n",
    "        desvio_padrao = conjunto_treino[variavel_numerica].std()\n",
    "    \n",
    "        #Calcular o Limite Inferior - Desvio Padrão:\n",
    "        limite_inferior_desvio_padrao = media - fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Calcular o Limite Superior - Desvio Padrão:\n",
    "        limite_superior_desvio_padrao = media + fator_desvio_padrao * desvio_padrao\n",
    "    \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        valores_atipicos_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior_desvio_padrao) | \n",
    "                                                  (conjunto_treino[variavel_numerica] > limite_superior_desvio_padrao)).sum()\n",
    "        \n",
    "        #Armazenar os Resultados no Dicionário dos Valores Atípicos - Desvio Padrão:\n",
    "        dicionario_valores_atipicos['Desvio Padrão'].append(valores_atipicos_desvio_padrao)\n",
    "\n",
    "        #Acumular o Número Total de Valores Atípicos - Desvio Padrão:\n",
    "        valores_atipicos_total_desvio_padrao += valores_atipicos_desvio_padrao\n",
    "\n",
    "    #Resultados - Número de Valores Atípicos do Conjunto de Treino por Variável Numérica - Intervalo Interquartil e Desvio Padrão:\n",
    "    print(\"Número de Valores Atípicos do Conjunto de Treino por Variável Numérica - Intervalo Interquartil e Desvio Padrão:\\n\")\n",
    "    print(f\"{'Variável Numérica':<30}{'Número de Valores Atípicos - Intervalo Interquartil':<70}{'Número de Valores Atípicos - Desvio Padrão':<70}\")\n",
    "    print(\"=\" * 130)\n",
    "\n",
    "    #Iterar sobre as Variáveis Numéricas:\n",
    "    for indice, variavel_numerica in enumerate(variaveis_numericas):\n",
    "\n",
    "        #Obter os Valores Atípicos pelo Intervalo Interquartil:\n",
    "        intervalo_interquartil = dicionario_valores_atipicos['Intervalo Interquartil'][indice]\n",
    "        \n",
    "        #Obter os Valores Atípicos pelo Desvio Padrão:\n",
    "        desvio_padrao = dicionario_valores_atipicos['Desvio Padrão'][indice]\n",
    "        \n",
    "        #Imprimir os Valores Formatados:\n",
    "        print(f\"{variavel_numerica:<30}{intervalo_interquartil:<70,.0f}\".replace(',', '.') +\n",
    "              f\"{desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "\n",
    "    #Resultados - Número Total de Valores Atípicos do Conjunto de Treino - Intervalo Interquartil e Desvio Padrão - Imprimir os Valores Formatados:\n",
    "    print(\"=\" * 130)\n",
    "    print(f\"{'\\nTotal':<30}{valores_atipicos_total_intervalo_interquartil:<70,.0f}\".replace(',', '.') + \n",
    "          f\"{valores_atipicos_total_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "    \n",
    "\n",
    "#Senão: Não Existem Variáveis Numéricas.\n",
    "else:\n",
    "    print(\"Não Existem Variáveis Numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531149b7",
   "metadata": {},
   "source": [
    "<H5>2.4.2. Tratamento dos Valores Atípicos - Abordagem de Remoção dos Valores Atípicos - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_sem_valores_em_falta_imputação_moda.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Definir o Fator do Desvio Padrão:\n",
    "fator_desvio_padrao = 3\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Treino:\n",
    "variaveis_numericas = conjunto_treino.select_dtypes(include=[numpy.number]).columns\n",
    "\n",
    "#Se Existirem Variáveis Numéricas no Conjunto de Treino:\n",
    "if len(variaveis_numericas) > 0:\n",
    "    \n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    numero_total_valores_atipicos_conjunto_treino_desvio_padrao = 0\n",
    "\n",
    "    #Criar um Dicionário para Armazenar os Limites Inferior e Superior:\n",
    "    dicionario_limites_inferior_superior = {}\n",
    "    \n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "        \n",
    "        #Calcular a media:\n",
    "        media = conjunto_treino[variavel_numerica].mean()\n",
    "        \n",
    "        #Calcular o Desvio Padrão:\n",
    "        desvio_padrao = conjunto_treino[variavel_numerica].std()\n",
    "        \n",
    "        #Calcular o Limite Inferior:\n",
    "        limite_inferior = media - fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Calcular o Limite Superior:\n",
    "        limite_superior = media + fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Armazenar no Dicionário os Limites Inferior e Superior:\n",
    "        dicionario_limites_inferior_superior[variavel_numerica] = (limite_inferior, limite_superior)\n",
    "        \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "    \n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_total_valores_atipicos_conjunto_treino_desvio_padrao += numero_valores_atipicos_conjunto_treino_desvio_padrao\n",
    "\n",
    "    #Resultados - Número Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Remover os Valores Atípicos do Conjunto de Treino:\n",
    "        conjunto_treino = conjunto_treino[(conjunto_treino[variavel_numerica] >= limite_inferior) &\n",
    "                                                      (conjunto_treino[variavel_numerica] <= limite_superior)]\n",
    "\n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino Após a Remoção:\n",
    "    numero_total_valores_atipicos_conjunto_treino_desvio_padrao = 0\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino Após a Remoção - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "\n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino Após a Remoção:\n",
    "        numero_total_valores_atipicos_conjunto_treino_desvio_padrao += numero_valores_atipicos_conjunto_treino_desvio_padrao\n",
    "\n",
    "    #Resultados - Número Total de Valores Atípicos do Conjunto de Treino Após a Remoção - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total de Valores Atípicos do Conjunto de Treino Após a Remoção - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_desvio_padrao:.0f}\".replace(',', '.'))\n",
    "\n",
    "#Guardar o Conjunto de Treino Sem Valores Atípicos Após a Remoção:\n",
    "conjunto_treino.to_csv('conjunto_treino_sem_valores_atípicos_remoção_desvio_padrão.csv', index=False)\n",
    "print(\"\\nO Conjunto de Treino Sem Valores Atípicos Após a Remoção pelo Desvio Padrão Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_prevista_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_probabilidades_previstas_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_prevista_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76989234",
   "metadata": {},
   "source": [
    "<H5>2.4.3. Tratamento dos Valores Atípicos - Abordagem de Imputação pela Mediana - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69187a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#A partir do SKLearn.Neighbors Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_sem_valores_em_falta_imputação_moda.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Definir o Fator do Desvio Padrão:\n",
    "fator_desvio_padrao = 3\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Treino:\n",
    "variaveis_numericas = conjunto_treino.select_dtypes(include=[numpy.number]).columns\n",
    "\n",
    "#Se Existirem Variáveis Numéricas no Conjunto de Treino:\n",
    "if len(variaveis_numericas) > 0:\n",
    "    \n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    numero_total_valores_atipicos_conjunto_treino_desvio_padrao = 0\n",
    "\n",
    "    #Criar um Dicionário para Armazenar os Limites Inferior e Superior:\n",
    "    dicionario_limites_inferior_superior = {}\n",
    "    \n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "        \n",
    "        #Calcular a media:\n",
    "        media = conjunto_treino[variavel_numerica].mean()\n",
    "        \n",
    "        #Calcular o Desvio Padrão:\n",
    "        desvio_padrao = conjunto_treino[variavel_numerica].std()\n",
    "        \n",
    "        #Calcular o Limite Inferior - Desvio Padrão:\n",
    "        limite_inferior = media - fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Calcular o Limite Superior - Desvio Padrão:\n",
    "        limite_superior = media + fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Armazenar no Dicionário os Limites Inferior e Superior:\n",
    "        dicionario_limites_inferior_superior[variavel_numerica] = (limite_inferior, limite_superior)\n",
    "        \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "    \n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_total_valores_atipicos_conjunto_treino_desvio_padrao += numero_valores_atipicos_conjunto_treino_desvio_padrao\n",
    "\n",
    "    #Resultados - Número Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Calcular a Mediana de cada variavel Numérica do Conjunto de Treino:\n",
    "        mediana = conjunto_treino[variavel_numerica].median()\n",
    "        \n",
    "        #Imputar os Valores Atípicos de cada variavel Numérica do Conjunto de Treino pelo respetivo Valor da Mediana:\n",
    "        conjunto_treino[variavel_numerica] = numpy.where((conjunto_treino[variavel_numerica] < limite_inferior) | (conjunto_treino[variavel_numerica] > limite_superior),\n",
    "                                                             mediana, conjunto_treino[variavel_numerica])\n",
    "\n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino Após a Imputação pela Mediana:\n",
    "    numero_total_valores_atipicos_conjunto_treino_imputacao_mediana = 0\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino Após a Imputação pela Mediana - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_imputacao_mediana = ((conjunto_treino[variavel_numerica] < limite_inferior) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "\n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino Após a Imputação pela Mediana:\n",
    "        numero_total_valores_atipicos_conjunto_treino_imputacao_mediana += numero_valores_atipicos_conjunto_treino_imputacao_mediana\n",
    "\n",
    "    #Resultados - Número Total de Valores Atípicos do Conjunto de Treino Após a Imputação pela Mediana - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total de Valores Atípicos do Conjunto de Treino Após a Imputação pela Mediana - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_imputacao_mediana:.0f}\".replace(',', '.'))\n",
    "\n",
    "#Guardar o Conjunto de Treino Sem Valores Atípicos Após a Imputação pela Mediana - Desvio Padrão:\n",
    "conjunto_treino.to_csv('conjunto_treino_sem_valores_atípicos_imputação_mediana_desvio_padrão.csv', index=False)\n",
    "print(\"\\nO Conjunto de Treino Sem Valores Atípicos Após a Imputação pela Mediana - Desvio Padrão Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_prevista_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_probabilidades_previstas_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_prevista_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7b38e",
   "metadata": {},
   "source": [
    "<H5>2.4.4. Tratamento dos Valores Atípicos - Abordagem de Truncamento aos Valores Mínimo e Máximo - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919163be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#A partir do SKLearn.Neighbors Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_sem_valores_em_falta_imputação_moda.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Definir o Fator do Desvio Padrão:\n",
    "fator_desvio_padrao = 3\n",
    "\n",
    "#Obter as Variáveis Numéricas do Conjunto de Treino:\n",
    "variaveis_numericas = conjunto_treino.select_dtypes(include=[numpy.number]).columns\n",
    "\n",
    "#Se Existirem Variáveis Numéricas no Conjunto de Treino:\n",
    "if len(variaveis_numericas) > 0:\n",
    "    \n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    numero_total_valores_atipicos_conjunto_treino_desvio_padrao = 0\n",
    "\n",
    "    #Criar um Dicionário para Armazenar os Limites Inferior e Superior:\n",
    "    dicionario_limites_inferior_superior = {}\n",
    "    \n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "        \n",
    "        #Calcular a media:\n",
    "        media = conjunto_treino[variavel_numerica].mean()\n",
    "        \n",
    "        #Calcular o Desvio Padrão:\n",
    "        desvio_padrao = conjunto_treino[variavel_numerica].std()\n",
    "        \n",
    "        #Calcular o Limite Inferior:\n",
    "        limite_inferior = media - fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Calcular o Limite Superior:\n",
    "        limite_superior = media + fator_desvio_padrao * desvio_padrao\n",
    "        \n",
    "        #Armazenar no Dicionário os Limites Inferior e Superior:\n",
    "        dicionario_limites_inferior_superior[variavel_numerica] = (limite_inferior, limite_superior)\n",
    "        \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior) | \n",
    "                                                          (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "    \n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "        numero_total_valores_atipicos_conjunto_treino_desvio_padrao += numero_valores_atipicos_conjunto_treino_desvio_padrao\n",
    "\n",
    "    #Resultados - Número Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total Inicial de Valores Atípicos do Conjunto de Treino - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_desvio_padrao:<70,.0f}\".replace(',', '.'))\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Truncar os Valores do Conjunto de Treino aos Limites Inferior e Superior:\n",
    "        conjunto_treino[variavel_numerica] = numpy.clip(conjunto_treino[variavel_numerica], limite_inferior, limite_superior)\n",
    "\n",
    "    #Iniciar o Número Total de Valores Atípicos do Conjunto de Treino Após a Truncagem:\n",
    "    numero_total_valores_atipicos_conjunto_treino_desvio_padrao = 0\n",
    "\n",
    "    #Iterar sobre cada variavel Numérica do Conjunto de Treino:\n",
    "    for variavel_numerica in variaveis_numericas:\n",
    "\n",
    "        #Obter os Limites Inferior e Superior - Desvio Padrão:\n",
    "        limite_inferior, limite_superior = dicionario_limites_inferior_superior[variavel_numerica]\n",
    "    \n",
    "        #Contar o Número de Valores Atípicos do Conjunto de Treino Após a Truncagem - Desvio Padrão:\n",
    "        numero_valores_atipicos_conjunto_treino_desvio_padrao = ((conjunto_treino[variavel_numerica] < limite_inferior) |\n",
    "                                                                 (conjunto_treino[variavel_numerica] > limite_superior)).sum()\n",
    "\n",
    "        #Acumular o Número Total de Valores Atípicos do Conjunto de Treino Após a Truncagem:\n",
    "        numero_total_valores_atipicos_conjunto_treino_desvio_padrao += numero_valores_atipicos_conjunto_treino_desvio_padrao\n",
    "\n",
    "    #Resultados - Número Total de Valores Atípicos do Conjunto de Treino Após a Truncagem - Desvio Padrão:\n",
    "    print(f\"\\nNúmero Total de Valores Atípicos do Conjunto de Treino Após a Truncagem - Desvio Padrão: {numero_total_valores_atipicos_conjunto_treino_desvio_padrao:.0f}\".replace(',', '.'))\n",
    "\n",
    "#Guardar o Conjunto de Treino Sem Valores Atípicos Após a Truncagem:\n",
    "conjunto_treino.to_csv('conjunto_treino_sem_valores_atípicos_truncagem_desvio_padrão.csv', index=False)\n",
    "print(\"\\nO Conjunto de Treino Sem Valores Atípicos Após a Truncagem pelo Desvio Padrão Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Definir Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_dados, variavel_alvo):\n",
    "    variaveis_preditoras = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    variavel_alvo = conjunto_dados[variavel_alvo]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_funcao_dividir_dados_variaveis_preditoras_variavel_alvo(conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_prevista_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "variavel_alvo_teste_probabilidades_previstas_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(variaveis_preditoras_treino_sem_valores_atipicos, variavel_alvo_treino_sem_valores_atipicos)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_prevista_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_teste, variavel_alvo_teste_probabilidades_previstas_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(variavel_alvo_teste, variavel_alvo_teste_prevista_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e086eb",
   "metadata": {},
   "source": [
    "<H5>2.4.5. Tratamento dos Valores Atípicos - Abordagens de Tratamento - Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Abordagens de Remoção/Imputação dos Valores em Falta:\n",
    "modelos_abordagens_remocao_imputacao_valores_falta = ['KNN - Remoção dos Valores Atípicos', 'KNN - Imputação pela Mediana', 'KNN - Truncar Valores ao Mínimo/Máximo',\n",
    "                                                      'Naïve Bayes - Remoção dos Valores Atípicos', 'Naïve Bayes - Imputação pela Mediana',\n",
    "                                                      'Naïve Bayes - Truncar Valores ao Mínimo/Máximo']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.84, 0.84, 0.84, 0.77, 0.77, 0.77]\n",
    "sensibilidade = [0.50, 0.50, 0.50, 0.39, 0.40, 0.44]\n",
    "precisao = [0.67, 0.67, 0.69, 0.46, 0.46, 0.46]\n",
    "auc = [0.81, 0.82, 0.82, 0.72, 0.72, 0.72]\n",
    "f1 = [0.57, 0.57, 0.58, 0.42, 0.43, 0.45]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título Geral, Espaçamento, Cor, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(16, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação dos Modelos de KNN e Naïve Bayes Bernoulli para Abordagens de Remoção/Imputação dos Valores Atípicos',\n",
    "    fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Dicionário, Cores, Largura e indice:\n",
    "dicionario_barras = {\"Exatidão\": exatidao, \"Sensibilidade\": sensibilidade, \"Precisão\": precisao, \"AUC\": auc, \"F1\": f1}\n",
    "cores_barras = [\"#ff7f0e\", \"#ffdd57\", \"#2ca02c\", \"#87CEEB\", \"#9467bd\"]\n",
    "largura_barras = 0.15\n",
    "indice_barras = numpy.arange(len(modelos_abordagens_remocao_imputacao_valores_falta))\n",
    "\n",
    "#Definir os Offsets X para cada Métrica de Avaliação:\n",
    "offset_X = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": -0.05, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Definir os Offsets Y para cada Métrica de Avaliação:\n",
    "offset_Y = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": 0.01, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Iterar sobre as Métricas de Avaliação e seus Respetivos Valores no Dicionário de Barras:\n",
    "for posicao_X, (metrica_avaliacao, valores) in enumerate(dicionario_barras.items()):\n",
    "    \n",
    "    #Criar Barras:\n",
    "    barras = matplotlib.pyplot.bar(indice_barras + posicao_X * largura_barras, valores, largura_barras, label=metrica_avaliacao, color=cores_barras[posicao_X])\n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras:\n",
    "        \n",
    "        #Definir Altura de cada Barra:\n",
    "        altura_y = barra.get_height()\n",
    "        \n",
    "        #Adicionar Valores Acima das Barras - Largura, Altura, Posição, Cor e Tamanho:\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2 + offset_X[metrica_avaliacao], altura_y + offset_Y[metrica_avaliacao], f'{altura_y:.2f}',\n",
    "            ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Posição e Rotação:\n",
    "matplotlib.pyplot.xlabel('Modelos de KNN e Naïve Bayes Bernoulli - Abordagens de Remoção/Imputação dos Valores Atípicos',\n",
    "    fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, modelos_abordagens_remocao_imputacao_valores_falta, fontsize=14, rotation=45, ha='right', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=12)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos.spines[margem].set_color('black')\n",
    "    eixos.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda_cores = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda_cores.get_frame().set_edgecolor('grey')\n",
    "legenda_cores.get_frame().set_facecolor('none')\n",
    "legenda_cores.get_title().set_color('black')\n",
    "for texto in legenda_cores.get_texts():\n",
    "    texto.set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149b587",
   "metadata": {},
   "source": [
    "<H5>2.5. Normalização de Escala:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7356ab9",
   "metadata": {},
   "source": [
    "<H5>2.5.1. Normalização de Escala - Técnica de Normalização de Escala Z-Score - Modelo Classificador de KNN:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:  \n",
    "import pandas as pd\n",
    "\n",
    "#A partir do Submódulo de Pré-Processamento da Biblioteca Scikit-Learn, Importar a Técnica de Normalização de Escala Z-Score:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#A partir do Submódulo Neighbors da Biblioteca Scikit-Learn, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do Submódulo Metrics da Biblioteca Scikit-Learn, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler e Carregar os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_sem_valores_atípicos_truncagem_desvio_padrão.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir o Conjunto de Treino em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_treino = conjunto_treino.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_treino = conjunto_treino[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_teste = conjunto_teste.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Identificar Variáveis Contínuas, excluindo a Variável Binária Chuva_Hoje - Conjunto de Treino:\n",
    "variaveis_continuas_treino = variaveis_preditoras_conjunto_treino.drop(columns=['Chuva_Hoje'])\n",
    "variaveis_binarias_treino = variaveis_preditoras_conjunto_treino[['Chuva_Hoje']]\n",
    "\n",
    "#Identificar Variáveis Contínuas, excluindo a Variável Binária Chuva_Hoje - Conjunto de Teste:\n",
    "variaveis_continuas_teste = variaveis_preditoras_conjunto_teste.drop(columns=['Chuva_Hoje'])\n",
    "variaveis_binarias_teste = variaveis_preditoras_conjunto_teste[['Chuva_Hoje']]\n",
    "\n",
    "#Definir a Técnica de Normalização de Escala Z-Score:\n",
    "tecnica_normalizacao_escala_zscore = StandardScaler()\n",
    "\n",
    "#Aplicar a Normalização Apenas Às Variáveis Contínuas:\n",
    "variaveis_continuas_treino_normalizadas = tecnica_normalizacao_escala_zscore.fit_transform(variaveis_continuas_treino)\n",
    "variaveis_continuas_teste_normalizadas = tecnica_normalizacao_escala_zscore.transform(variaveis_continuas_teste)\n",
    "\n",
    "#Reconstruir os Conjuntos de Treino e de Teste com Variáveis Contínuas Normalizadas e Variáveis Binárias Intactas - Conjunto de Treino:\n",
    "variaveis_preditoras_treino_normalizadas_zscore = pd.DataFrame(variaveis_continuas_treino_normalizadas, columns=variaveis_continuas_treino.columns)\n",
    "variaveis_preditoras_treino_normalizadas_zscore['Chuva_Hoje'] = variaveis_binarias_treino.reset_index(drop=True)\n",
    "\n",
    "#Reconstruir os Conjuntos de Treino e de Teste com Variáveis Contínuas Normalizadas e Variáveis Binárias Intactas - Conjunto de Teste:\n",
    "variaveis_preditoras_teste_normalizadas_zscore = pd.DataFrame(variaveis_continuas_teste_normalizadas, columns=variaveis_continuas_teste.columns)\n",
    "variaveis_preditoras_teste_normalizadas_zscore['Chuva_Hoje'] = variaveis_binarias_teste.reset_index(drop=True)\n",
    "\n",
    "#Adicionar a Variável Alvo aos Conjuntos Normalizados - Conjunto de Treino:\n",
    "conjunto_treino_normalizado_zscore = variaveis_preditoras_treino_normalizadas_zscore.copy()\n",
    "conjunto_treino_normalizado_zscore[variavel_alvo] = variavel_alvo_conjunto_treino.reset_index(drop=True)\n",
    "\n",
    "#Adicionar a Variável Alvo aos Conjuntos Normalizados - Conjunto de Teste:\n",
    "conjunto_teste_normalizado_zscore = variaveis_preditoras_teste_normalizadas_zscore.copy()\n",
    "conjunto_teste_normalizado_zscore[variavel_alvo] = variavel_alvo_conjunto_teste.reset_index(drop=True)\n",
    "\n",
    "#Guardar os Conjuntos Normalizados:\n",
    "conjunto_treino_normalizado_zscore.to_csv('conjunto_treino_normalizado_z-score.csv', index=False)\n",
    "conjunto_teste_normalizado_zscore.to_csv('conjunto_teste_normalizado_z-score.csv', index=False)\n",
    "\n",
    "#Resultados - Os Conjuntos de Treino e de Teste Normalizados através da Técnica de Normalização de Escala Z-Score Foram Guardados com Sucesso!:\n",
    "print(\"Os Conjuntos de Treino e de Teste Normalizados através da Técnica de Normalização de Escala Z-Score Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Definir o Modelo Classificador de KNN com k=5:\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_normalizadas_zscore, variavel_alvo_conjunto_treino)\n",
    "\n",
    "#Fazer Previsões da Variável Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_prevista_teste_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste_normalizadas_zscore)\n",
    "\n",
    "#Calcular as Probabilidades Previstas da variável Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste_normalizadas_zscore)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_conjunto_teste, variavel_alvo_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "print(\"\\n5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e429859",
   "metadata": {},
   "source": [
    "<H5>2.5.2. Normalização de Escala - Técnica de Normalização de Escala MinMax - Modelo Classificador de KNN:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:  \n",
    "import pandas as pd\n",
    "\n",
    "#A partir do Submódulo de Pré-Processamento da Biblioteca Scikit-Learn, Importar a Técnica de Normalização de Escala MinMax:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#A partir do Submódulo Neighbors da Biblioteca Scikit-Learn, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do Submódulo Metrics da Biblioteca Scikit-Learn, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler e Carregar os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_sem_valores_atípicos_truncagem_desvio_padrão.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_sem_valores_em_falta_imputação_moda.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir o Conjunto de Treino em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_treino = conjunto_treino.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_treino = conjunto_treino[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_teste = conjunto_teste.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Identificar Variáveis Contínuas, excluindo a Variável Binária Chuva_Hoje - Conjunto de Treino:\n",
    "variaveis_continuas_treino = variaveis_preditoras_conjunto_treino.drop(columns=['Chuva_Hoje'])\n",
    "variaveis_binarias_treino = variaveis_preditoras_conjunto_treino[['Chuva_Hoje']]\n",
    "\n",
    "#Identificar Variáveis Contínuas, excluindo a Variável Binária Chuva_Hoje - Conjunto de Teste:\n",
    "variaveis_continuas_teste = variaveis_preditoras_conjunto_teste.drop(columns=['Chuva_Hoje'])\n",
    "variaveis_binarias_teste = variaveis_preditoras_conjunto_teste[['Chuva_Hoje']]\n",
    "\n",
    "#Definir a Técnica de Normalização de Escala MinMax:\n",
    "tecnica_normalizacao_escala_minmax = MinMaxScaler()\n",
    "\n",
    "#Aplicar a Normalização Apenas Às Variáveis Contínuas:\n",
    "variaveis_continuas_treino_normalizadas = tecnica_normalizacao_escala_minmax.fit_transform(variaveis_continuas_treino)\n",
    "variaveis_continuas_teste_normalizadas = tecnica_normalizacao_escala_minmax.transform(variaveis_continuas_teste)\n",
    "\n",
    "#Reconstruir os Conjuntos de Treino e de Teste com Variáveis Contínuas Normalizadas e Variáveis Binárias Intactas - Conjunto de Treino:\n",
    "variaveis_preditoras_treino_normalizadas_minmax = pd.DataFrame(variaveis_continuas_treino_normalizadas, columns=variaveis_continuas_treino.columns)\n",
    "variaveis_preditoras_treino_normalizadas_minmax['Chuva_Hoje'] = variaveis_binarias_treino.reset_index(drop=True)\n",
    "\n",
    "#Reconstruir os Conjuntos de Treino e de Teste com Variáveis Contínuas Normalizadas e Variáveis Binárias Intactas - Conjunto de Teste:\n",
    "variaveis_preditoras_teste_normalizadas_minmax = pd.DataFrame(variaveis_continuas_teste_normalizadas, columns=variaveis_continuas_teste.columns)\n",
    "variaveis_preditoras_teste_normalizadas_minmax['Chuva_Hoje'] = variaveis_binarias_teste.reset_index(drop=True)\n",
    "\n",
    "#Adicionar a Variável Alvo aos Conjuntos Normalizados - Conjunto de Treino:\n",
    "conjunto_treino_normalizado_minmax = variaveis_preditoras_treino_normalizadas_minmax.copy()\n",
    "conjunto_treino_normalizado_minmax[variavel_alvo] = variavel_alvo_conjunto_treino.reset_index(drop=True)\n",
    "\n",
    "#Adicionar a Variável Alvo aos Conjuntos Normalizados - Conjunto de Teste:\n",
    "conjunto_teste_normalizado_minmax = variaveis_preditoras_teste_normalizadas_minmax.copy()\n",
    "conjunto_teste_normalizado_minmax[variavel_alvo] = variavel_alvo_conjunto_teste.reset_index(drop=True)\n",
    "\n",
    "#Guardar os Conjuntos Normalizados:\n",
    "conjunto_treino_normalizado_minmax.to_csv('conjunto_treino_normalizado_minmax.csv', index=False)\n",
    "conjunto_teste_normalizado_minmax.to_csv('conjunto_teste_normalizado_minmax.csv', index=False)\n",
    "\n",
    "#Resultados - Os Conjuntos de Treino e de Teste Normalizados através da Técnica de Normalização de Escala MinMax Foram Guardados com Sucesso!:\n",
    "print(\"Os Conjuntos de Treino e de Teste Normalizados através da Técnica de Normalização de Escala MinMax Foram Guardados com Sucesso!\")\n",
    "\n",
    "#Definir o Modelo Classificador de KNN com k=5:\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_treino_normalizadas_minmax, variavel_alvo_conjunto_treino)\n",
    "\n",
    "#Fazer Previsões da Variável Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_prevista_teste_knn = modelo_classificador_knn.predict(variaveis_preditoras_teste_normalizadas_minmax)\n",
    "\n",
    "#Calcular as Probabilidades Previstas da variável Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_teste_normalizadas_minmax)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_conjunto_teste, variavel_alvo_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "print(\"\\n5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5aad9",
   "metadata": {},
   "source": [
    "<H5>2.5.3. Normalização de Escala - Técnicas de Normalização de Escala Z-Score e MinMax - Modelo Classificador de KNN - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf608248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Modelo Classificador de KNN - Técnicas de Normalização de Escala Z-Score e MinMax:\n",
    "modelo_knn_tecnicas_normalizacao_escala = ['Modelo KNN - Técnica de Normalização de Escala Z-Score', 'Modelo KNN - Técnica de Normalização de Escala MinMax']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.84, 0.83]\n",
    "sensibilidade = [0.48, 0.46]\n",
    "precisao = [0.69, 0.67]\n",
    "auc = [0.83, 0.81]\n",
    "f1 = [0.57, 0.54]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título, Espaçamento, Cores, Legenda, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(16, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação do Modelo Classificador de KNN para as Técnicas de Normalização de Escala Z-Score e MinMax', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Dicionário, Cores, Largura e Índice:\n",
    "dicionario_barras = {\"Exatidão\": exatidao, \"Sensibilidade\": sensibilidade, \"Precisão\": precisao, \"AUC\": auc, \"F1\": f1}\n",
    "cores_barras = [\"#ff7f0e\", \"#ffdd57\", \"#2ca02c\", \"#87CEEB\", \"#9467bd\"]\n",
    "largura_barras = 0.15\n",
    "indice_barras = numpy.arange(len(modelo_knn_tecnicas_normalizacao_escala))\n",
    "\n",
    "#Definir os Offsets Horizontais para cada Métrica de Avaliação:\n",
    "offset_X = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": 0, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Definir os Offsets Verticais para cada Métrica de Avaliação:\n",
    "offset_Y = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": 0, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Iterar sobre as Métricas de Avaliação e seus Respetivos Valores no Dicionário de Barras:\n",
    "for posicao_X, (metrica_avaliacao, valores) in enumerate(dicionario_barras.items()):\n",
    "    \n",
    "    #Criar Barras:\n",
    "    barras = matplotlib.pyplot.bar(indice_barras + posicao_X * largura_barras, valores, largura_barras, label=metrica_avaliacao, color=cores_barras[posicao_X])\n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras:\n",
    "        \n",
    "        #Definir Altura de cada Barra:\n",
    "        altura_y = barra.get_height()\n",
    "        \n",
    "        #Adicionar Valores Acima das Barras - Posição, Cor e Tamanho:\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2 + offset_X[metrica_avaliacao], altura_y + offset_Y[metrica_avaliacao], f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Rotação e Posição:\n",
    "matplotlib.pyplot.xlabel('Modelo KNN - Técnicas de Normalização de Escala Z-Score e MinMax', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_barras + 2.5 * largura_barras, modelo_knn_tecnicas_normalizacao_escala, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Intervalo e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=12)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos.spines[margem].set_color('black')\n",
    "    eixos.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda_cores = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda_cores.get_frame().set_edgecolor('grey')\n",
    "legenda_cores.get_frame().set_facecolor('none')\n",
    "legenda_cores.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535dc5d9",
   "metadata": {},
   "source": [
    "<H5>2.6. Balanceamento:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab23b7",
   "metadata": {},
   "source": [
    "<H5>2.6.1. Balanceamento - Técnica de Sobreamostragem por Replicação - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ccf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Função para Dividir os Dados em Variáveis Preditoras e variavel Alvo:\n",
    "def funcao_funcao_dividir_dados(conjunto_dados, variavel_alvo):\n",
    "    X = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    Y = conjunto_dados[variavel_alvo]\n",
    "    return X, Y\n",
    "\n",
    "#Função para Aplicar a Técnica de Sobreamostragem por Replicação ao Conjunto de Dados:\n",
    "def funcao_tecnica_sobreamostragem_replicacao(conjunto_dados, variavel_alvo):\n",
    "\n",
    "    #Identificar a Classe Maioritária e a Classe Minoritária:\n",
    "    contagem_classes = conjunto_dados[variavel_alvo].value_counts()\n",
    "    classe_maioritaria = contagem_classes.idxmax()\n",
    "    classe_minoritaria = contagem_classes.idxmin()\n",
    "\n",
    "    #Separar as Classes Maioritária e Minoritária:\n",
    "    classe_maioritaria = conjunto_dados[conjunto_dados[variavel_alvo] == classe_maioritaria]\n",
    "    classe_minoritaria = conjunto_dados[conjunto_dados[variavel_alvo] == classe_minoritaria]\n",
    "\n",
    "    #Sobreamostrar a Classe Minoritária:\n",
    "    classe_minoritaria_sobreamostrada = classe_minoritaria.sample(len(classe_maioritaria), replace=True, random_state=42)\n",
    "\n",
    "    #Concatenar a Classe Maioritária com a Classe Minoritária Sobreamostrada:\n",
    "    conjunto_dados_balanceado = pandas.concat([classe_maioritaria, classe_minoritaria_sobreamostrada])\n",
    "\n",
    "    #Misturar Aleatoriamente os Registos do Conjunto de Dados Balanceado:\n",
    "    conjunto_dados_balanceado = conjunto_dados_balanceado.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #Devolver o Conjunto de Dados Balanceado:\n",
    "    return conjunto_dados_balanceado\n",
    "\n",
    "#Ler e Carregar o Conjunto de Treino Pré-Balanceamento:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Aplicar a Técnica de Sobreamostragem por Replicação ao Conjunto de Treino:\n",
    "conjunto_balanceado = funcao_tecnica_sobreamostragem_replicacao(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Verificar a Distribuição das Classes da Variável Alvo (Chuva_Amanha) Pós-Balanceamento por Sobreamostragem por Replicação:\n",
    "distribuicao_classes_variavel_alvo_pos_balanceamento_sobreamostragem_replicacao = conjunto_balanceado[variavel_alvo].value_counts().sort_index().apply(lambda x: f'{x:,.0f}'.replace(',', '.'))\n",
    "print(f\"Conjunto de Treino - Distribuição das Classes da Variável Alvo ({variavel_alvo}) Pós-Balanceamento por Sobreamostragem por Replicação:\")\n",
    "for classe, valor in distribuicao_classes_variavel_alvo_pos_balanceamento_sobreamostragem_replicacao.items():\n",
    "    print(f\"{classe}    {valor}\")\n",
    "print()\n",
    "\n",
    "#Guardar o Conjunto de Treino Balanceado por Sobreamostragem por Replicação:\n",
    "conjunto_balanceado.to_csv('conjunto_treino_balanceado_sobreamostragem_replicação.csv', index=False)\n",
    "print(\"O Conjunto de Treino Balanceado por Sobreamostragem por Replicação Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Dividir os Dados Balanceados em Variáveis Preditoras e variavel Alvo:\n",
    "X_balanceado, Y_balanceado = funcao_funcao_dividir_dados(conjunto_balanceado, variavel_alvo)\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_knn.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_previsto_teste_knn = modelo_classificador_knn.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN: - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "precisao_teste_knn = precision_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "print()\n",
    "\n",
    "#Iniciar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_previsto_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_probabilidades_previstas_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc6711a",
   "metadata": {},
   "source": [
    "<H5>2.6.2. Balanceamento - Técnica de Sobreamostragem por SMOTE - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#A partir do IMBLearn.Over_Sampling Importar a Técnica de Sobreamostragem por SMOTE:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Função para Dividir os Dados em Variáveis Preditoras e Variável Alvo:\n",
    "def funcao_funcao_dividir_dados(conjunto_dados, variavel_alvo):\n",
    "    X = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    Y = conjunto_dados[variavel_alvo]\n",
    "    return X, Y\n",
    "\n",
    "#Função para Aplicar a Técnica de Sobreamostragem por SMOTE ao Conjunto de Treino:\n",
    "def funcao_tecnica_sobreamostragem_smote(X, Y):\n",
    "    tecnica_sobreamostragem_smote = SMOTE(sampling_strategy=1.0, random_state=42)\n",
    "    X_sobreamostrado, Y_sobreamostrado = tecnica_sobreamostragem_smote.fit_resample(X, Y)\n",
    "    return X_sobreamostrado, Y_sobreamostrado\n",
    "\n",
    "#Ler e Carregar o Conjunto de Treino Pré-Balanceamento:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo:\n",
    "X, Y = funcao_funcao_dividir_dados(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Aplicar a Técnica de Sobreamostragem por SMOTE:\n",
    "X_balanceado, Y_balanceado = funcao_tecnica_sobreamostragem_smote(X, Y)\n",
    "\n",
    "# Verificar a Distribuição das Classes da Variável Alvo (Chuva_Amanha) Pós-Balanceamento por Sobreamostragem por SMOTE:\n",
    "distribuicao_classes_variavel_alvo_pos_balanceamento_sobreamostragem_smote = pandas.Series(Y_balanceado).value_counts().sort_index().apply(lambda x: f'{x:,.0f}'.replace(',', '.'))\n",
    "print(f\"Conjunto de Treino - Distribuição das Classes da Variável Alvo ({variavel_alvo}) Pós-Balanceamento por Sobreamostragem por SMOTE:\")\n",
    "for classe, valor in distribuicao_classes_variavel_alvo_pos_balanceamento_sobreamostragem_smote.items():\n",
    "    print(f\"{classe}    {valor}\")\n",
    "print()\n",
    "\n",
    "#Guardar o Conjunto de Treino Balanceado por Sobreamostragem por SMOTE:\n",
    "conjunto_balanceado = pandas.concat([pandas.DataFrame(X_balanceado), pandas.Series(Y_balanceado, name=variavel_alvo)], axis=1)\n",
    "conjunto_balanceado.to_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv', index=False)\n",
    "print(\"O Conjunto de Treino Balanceado por Sobreamostragem por SMOTE Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_knn.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_previsto_teste_knn = modelo_classificador_knn.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "precisao_teste_knn = precision_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "print()\n",
    "\n",
    "#Iniciar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_previsto_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_probabilidades_previstas_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14925eb",
   "metadata": {},
   "source": [
    "<H5>2.6.3. Balanceamento - Técnica de Subamostragem - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:  \n",
    "import pandas\n",
    "\n",
    "#A partir do Submódulo Neighbors da Biblioteca Scikit-Learn, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do Submódulo Naïve_Bayes da Biblioteca Scikit-Learn, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do Submódulo Metrics da Biblioteca Scikit-Learn, Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Ler o Conjunto de Treino:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Contar o Número de Classes da Variável Alvo do Conjunto de Treino:\n",
    "numero_classes_variavel_alvo_conjunto_treino = conjunto_treino[variavel_alvo].value_counts()\n",
    "\n",
    "#Identificar as Classes Maioritária e Minoritária da Variável Alvo do Conjunto de Treino:\n",
    "classe_maioritaria_variavel_alvo_conjunto_treino = numero_classes_variavel_alvo_conjunto_treino.idxmax()\n",
    "classe_minoritaria_variavel_alvo_conjunto_treino = numero_classes_variavel_alvo_conjunto_treino.idxmin()\n",
    "\n",
    "#Separar as Classes Maioritária e Minoritária da Variável Alvo do Conjunto de Treino:\n",
    "classe_maioritaria_variavel_alvo_conjunto_treino = conjunto_treino[conjunto_treino[variavel_alvo] == classe_maioritaria_variavel_alvo_conjunto_treino]\n",
    "classe_minoritaria_variavel_alvo_conjunto_treino = conjunto_treino[conjunto_treino[variavel_alvo] == classe_minoritaria_variavel_alvo_conjunto_treino]\n",
    "\n",
    "#Subamostrar a Classe Maioritária da Variável Alvo do Conjunto de Treino:\n",
    "classe_maioritaria_variavel_alvo_conjunto_treino_subamostrada = classe_maioritaria_variavel_alvo_conjunto_treino.sample(len(classe_minoritaria_variavel_alvo_conjunto_treino), random_state=42)\n",
    "\n",
    "#Concatenar a Classe Maioritária da Variável Alvo do Conjunto de Treino Subamostrada com a Classe Minoritária da Variável Alvo do Conjunto de Treino:\n",
    "conjunto_treino_balanceado_subamostragem = pandas.concat([classe_maioritaria_variavel_alvo_conjunto_treino_subamostrada, classe_minoritaria_variavel_alvo_conjunto_treino])\n",
    "\n",
    "#Misturar Aleatoriamente os Registos do Conjunto de Treino Balanceado por Subamostragem:\n",
    "conjunto_treino_balanceado_subamostragem = conjunto_treino_balanceado_subamostragem.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#Guardar o Conjunto de Treino Balanceado por Subamostragem:\n",
    "conjunto_treino_balanceado_subamostragem.to_csv('conjunto_treino_balanceado_subamostragem.csv', index=False)\n",
    "print(\"O Conjunto de Treino Balanceado por Subamostragem Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Verificar a Distribuição das Classes da Variável Alvo do Conjunto de Treino Pós-Balanceamento por Subamostragem:\n",
    "distribuicao_classes_variavel_alvo_conjunto_treino_pos_balanceamento_subamostragem = conjunto_treino_balanceado_subamostragem[variavel_alvo].value_counts().sort_index().apply(lambda x: f'{x:,.0f}'.replace(',', '.'))\n",
    "print(f\"Conjunto de Treino - Distribuição das Classes da Variável Alvo ({variavel_alvo}) Pós-Balanceamento por Subamostragem:\")\n",
    "for classe, valor in distribuicao_classes_variavel_alvo_conjunto_treino_pos_balanceamento_subamostragem.items():\n",
    "    print(f\"{classe}    {valor}\")\n",
    "\n",
    "#Dividir o Conjunto de Treino Balanceado por Subamostragem em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_treino_balanceado_subamostragem = conjunto_treino_balanceado_subamostragem.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_treino_balanceado_subamostragem = conjunto_treino_balanceado_subamostragem[variavel_alvo]\n",
    "\n",
    "#Definir o Modelo Classificador de KNN com k=5:\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_knn.fit(variaveis_preditoras_conjunto_treino_balanceado_subamostragem, variavel_alvo_conjunto_treino_balanceado_subamostragem)\n",
    "\n",
    "#Ler o Conjunto de Teste:\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir o Conjunto de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_conjunto_teste = conjunto_teste.drop(columns=[variavel_alvo])\n",
    "variavel_alvo_conjunto_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Fazer Previsões da Variável Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_prevista_teste_knn = modelo_classificador_knn.predict(variaveis_preditoras_conjunto_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas da variavel Alvo no Conjunto de Teste com o Modelo Classificador de KNN:\n",
    "variavel_alvo_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(variaveis_preditoras_conjunto_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "exatidao_teste_knn = accuracy_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "precisao_teste_knn = precision_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(variavel_alvo_conjunto_teste, variavel_alvo_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "print(\"\\n5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de KNN:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "\n",
    "#Definir o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino Balanceado por Subamostragem:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(variaveis_preditoras_conjunto_treino_balanceado_subamostragem, variavel_alvo_conjunto_treino_balanceado_subamostragem)\n",
    "\n",
    "#Fazer Previsões da variavel Alvo no Conjunto de Teste com o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_prevista_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(variaveis_preditoras_conjunto_teste)\n",
    "\n",
    "#Calcular as Probabilidades Previstas da Variável Alvo no Conjunto de Teste com o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "variavel_alvo_probabilidades_previstas_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(variaveis_preditoras_conjunto_teste)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(variavel_alvo_conjunto_teste, variavel_alvo_probabilidades_previstas_teste_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(variavel_alvo_conjunto_teste, variavel_alvo_prevista_teste_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "print(\"\\n5 Métricas de Avaliação no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dded0",
   "metadata": {},
   "source": [
    "<H5>2.6.4. Balanceamento - Técnica de Balanceamento Híbrido (Sobreamostragem SMOTE + Subamostragem) - Modelos Classificadores de KNN e Naïve Bayes Bernoulli:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics Importar as 5 Métricas de Avaliação (exatidao, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#A partir do IMBLearn.Over_Sampling Importar a Técnica de Sobreamostragem por SMOTE:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#A partir do IMBLearn.Under_Sampling Importar a Técnica de Subamostragem:\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Função para Dividir os Dados em Variáveis Preditoras e Variável Alvo:\n",
    "def funcao_funcao_dividir_dados(conjunto_dados, variavel_alvo):\n",
    "    X = conjunto_dados.drop(columns=[variavel_alvo])\n",
    "    Y = conjunto_dados[variavel_alvo]\n",
    "    return X, Y\n",
    "\n",
    "#Função para Aplicar a Técnica de Balanceamento Híbrido ao Conjunto de Treino:\n",
    "def funcao_tecnica_balanceamento_hibrido(X, Y):\n",
    "\n",
    "    #Aplicar a Técnica de Balanceamento de Sobreamostragem por SMOTE:\n",
    "    sobreamostragem_smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "    X_sobreamostrado, Y_sobreamostrado = sobreamostragem_smote.fit_resample(X, Y)\n",
    "    \n",
    "    #Aplicar a Técnica de Balanceamento de Subamostragem:\n",
    "    subamostragem = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "    X_balanceado, Y_balanceado = subamostragem.fit_resample(X_sobreamostrado, Y_sobreamostrado)\n",
    "    \n",
    "    return X_balanceado, Y_balanceado\n",
    "\n",
    "#Ler e Carregar o Conjunto de Treino Pré-Balanceamento:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo:\n",
    "X, Y = funcao_funcao_dividir_dados(conjunto_treino, variavel_alvo)\n",
    "\n",
    "#Aplicar a Técnica de Balanceamento Híbrido:\n",
    "X_balanceado, Y_balanceado = funcao_tecnica_balanceamento_hibrido(X, Y)\n",
    "\n",
    "#Verificar a Distribuição das Classes da Variável Alvo (Chuva_Amanha) Pós-Balanceamento Híbrido:\n",
    "distribuição_classes_variavel_alvo_pos_balanceamento_híbrido = pandas.Series(Y_balanceado).value_counts().sort_index().apply(lambda x: f'{x:,.0f}'.replace(',', '.'))\n",
    "print(f\"Conjunto de Treino - Distribuição das Classes da Variável Alvo ({variavel_alvo}) Pós-Balanceamento Híbrido:\")\n",
    "for classe, valor in distribuição_classes_variavel_alvo_pos_balanceamento_híbrido.items():\n",
    "    print(f\"{classe}    {valor}\")\n",
    "print()\n",
    "\n",
    "#Guardar o Conjunto de Treino Balanceado por Balanceamento Híbrido:\n",
    "conjunto_balanceado = pandas.concat([pandas.DataFrame(X_balanceado), pandas.Series(Y_balanceado, name=variavel_alvo)], axis=1)\n",
    "conjunto_balanceado.to_csv('conjunto_treino_balanceado_híbrido_smote_subamostragem.csv', index=False)\n",
    "print(\"O Conjunto de Treino Balanceado por Balanceamento Híbrido Foi Guardado com Sucesso!\")\n",
    "\n",
    "#Iniciar o Modelo Classificador de KNN (k=5):\n",
    "modelo_classificador_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Treinar o Modelo Classificador de KNN no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_knn.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_previsto_teste_knn = modelo_classificador_knn.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de KNN:\n",
    "Y_probabilidades_previstas_teste_knn = modelo_classificador_knn.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "exatidao_teste_knn = accuracy_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "sensibilidade_teste_knn = recall_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "precisao_teste_knn = precision_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "auc_teste_knn = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_knn)\n",
    "f1_teste_knn = f1_score(Y_balanceado, Y_previsto_teste_knn)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\n",
    "print(\"5 Métricas de Avaliação para o Modelo Classificador de KNN - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_knn:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_knn:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_knn:.2f}\")\n",
    "print(f\"AUC: {auc_teste_knn:.2f}\")\n",
    "print(f\"F1: {f1_teste_knn:.2f}\")\n",
    "print()\n",
    "\n",
    "#Iniciar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "modelo_classificador_naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar o Modelo Classificador de Naïve Bayes Bernoulli no Conjunto de Treino Balanceado:\n",
    "modelo_classificador_naive_bayes_bernoulli.fit(X_balanceado, Y_balanceado)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_previsto_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict(X_balanceado)\n",
    "\n",
    "#Calcular as Probabilidades Previstas no Conjunto de Teste para o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "Y_probabilidades_previstas_teste_naive_bayes_bernoulli = modelo_classificador_naive_bayes_bernoulli.predict_proba(X_balanceado)[:, 1]\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "exatidao_teste_naive_bayes_bernoulli = accuracy_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "sensibilidade_teste_naive_bayes_bernoulli = recall_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "precisao_teste_naive_bayes_bernoulli = precision_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "auc_teste_naive_bayes_bernoulli = roc_auc_score(Y_balanceado, Y_probabilidades_previstas_teste_naive_bayes_bernoulli)\n",
    "f1_teste_naive_bayes_bernoulli = f1_score(Y_balanceado, Y_previsto_teste_naive_bayes_bernoulli)\n",
    "\n",
    "#Resultados - Mostrar as 5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\n",
    "print(\"5 Métricas de Avaliação para o Modelo Classificador de Naïve Bayes Bernoulli - Conjunto de Teste:\")\n",
    "print(f\"exatidao: {exatidao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"precisao: {precisao_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"AUC: {auc_teste_naive_bayes_bernoulli:.2f}\")\n",
    "print(f\"F1: {f1_teste_naive_bayes_bernoulli:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2369b",
   "metadata": {},
   "source": [
    "<H5>2.6.5. Balanceamento - Técnicas de Balanceamento - Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Modelos Classificadores de KNN e Naïve Bayes Bernoulli - Técnicas de Balanceamento:\n",
    "modelos_tecnicas_balanceamento = ['KNN - Sobreamostragem por Replicação', 'KNN - Sobreamostragem por SMOTE', 'KNN - Subamostragem',\n",
    "                                  'KNN - Híbrido (Sobreamostragem SMOTE + Subamostragem)', 'Naïve Bayes Bernoulli - Sobreamostragem por Replicação',\n",
    "                                  'Naïve Bayes Bernoulli - Sobreamostragem por SMOTE', 'Naïve Bayes Bernoulli - Subamostragem',\n",
    "                                  'Naïve Bayes Bernoulli - Híbrido (Sobreamostragem SMOTE + Subamostragem)']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.91, 0.91, 0.78, 0.88, 0.73, 0.73, 0.72, 0.73]\n",
    "sensibilidade = [0.97, 0.99, 0.76, 0.94, 0.73, 0.73, 0.72, 0.72]\n",
    "precisao = [0.86, 0.85, 0.49, 0.84, 0.73, 0.73, 0.42, 0.73]\n",
    "auc = [0.98, 0.99, 0.84, 0.96, 0.80, 0.80, 0.79, 0.80]\n",
    "f1 = [0.91, 0.92, 0.60, 0.89, 0.73, 0.73, 0.53, 0.73]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título, Espaçamento, Cores, Legenda, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(16, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação dos Modelos Classificadores de KNN e Naïve Bayes Bernoulli para Técnicas de Balanceamento', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Dicionário, Cores, Largura e indice:\n",
    "dicionario_barras = {\"Exatidão\": exatidao, \"Sensibilidade\": sensibilidade, \"Precisão\": precisao, \"AUC\": auc, \"F1\": f1}\n",
    "cores_barras = [\"#ff7f0e\", \"#ffdd57\", \"#2ca02c\", \"#87CEEB\", \"#9467bd\"]\n",
    "largura_barras = 0.15\n",
    "indice_barras = numpy.arange(len(modelos_tecnicas_balanceamento))\n",
    "\n",
    "#Definir os Offsets Horizontais para cada Métrica de Avaliação:\n",
    "offset_X = {\"Exatidão\": 0, \"Sensibilidade\": -0.03, \"Precisão\": -0.03, \"AUC\": 0, \"F1\": 0.05}\n",
    "\n",
    "#Definir os Offsets Verticais para cada Métrica de Avaliação:\n",
    "offset_Y = {\"Exatidão\": 0, \"Sensibilidade\": 0, \"Precisão\": 0, \"AUC\": 0, \"F1\": 0}\n",
    "\n",
    "#Iterar sobre as Métricas de Avaliação e seus Respetivos Valores no Dicionário de Barras:\n",
    "for posicao_X, (metrica_avaliacao, valores) in enumerate(dicionario_barras.items()):\n",
    "    \n",
    "    #Criar Barras:\n",
    "    barras = matplotlib.pyplot.bar(indice_barras + posicao_X * largura_barras, valores, largura_barras, label=metrica_avaliacao, color=cores_barras[posicao_X])\n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras:\n",
    "        \n",
    "        #Definir Altura de cada Barra:\n",
    "        altura_Y = barra.get_height()\n",
    "        \n",
    "        #Adicionar Valores Acima das Barras - Cor e Tamanho:\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2 + offset_X[metrica_avaliacao], altura_Y + offset_Y[metrica_avaliacao], f'{altura_Y:.2f}', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Posição e Rotação:\n",
    "matplotlib.pyplot.xlabel('Modelos KNN e Naïve Bayes Bernoulli - Técnicas de Balanceamento', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, modelos_tecnicas_balanceamento, fontsize=14, rotation=45, ha='right', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Intervalo e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=12)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos.spines[margem].set_color('black')\n",
    "    eixos.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda_cores = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda_cores.get_frame().set_edgecolor('grey')\n",
    "legenda_cores.get_frame().set_facecolor('none')\n",
    "legenda_cores.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5ff10",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8983f",
   "metadata": {},
   "source": [
    "<H4>3. Parte 3. Engenharia de Variáveis:</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8921e",
   "metadata": {},
   "source": [
    "<H5>3.1. Seleção de Variáveis:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0490e",
   "metadata": {},
   "source": [
    "<H5>3.1.1. Seleção de Variáveis - Variáveis Redundantes:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd7f80",
   "metadata": {},
   "source": [
    "<H5>3.1.1.1. Seleção de Variáveis - Variáveis Redundantes - Número de Variáveis a Remover e Sensibilidades dos Modelos de KNN e Naïve Bayes Bernoulli para cada Threshold de Correlação:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76578c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do sklearn.naive_bayes, Importar o Modelo Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar o relatorio de Classificação:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Ler e Carregar os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo:\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir o Conjunto de Treino em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_treino = conjunto_treino.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_treino = conjunto_treino[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_preditoras_teste = conjunto_teste.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Definir Função para Identificar Variáveis Altamente Correlacionadas/Redundantes:\n",
    "def funcao_identificar_variaveis_altamente_correlacionadas(variaveis, threshold_correlacao):\n",
    "    matriz_correlacao = abs(variaveis.corr())\n",
    "    variaveis_a_remover = set()\n",
    "    for coluna in matriz_correlacao.columns:\n",
    "        variaveis_altamente_correlacionadas = matriz_correlacao.index[matriz_correlacao[coluna] >= threshold_correlacao].tolist()\n",
    "        if coluna in variaveis_altamente_correlacionadas:\n",
    "            variaveis_altamente_correlacionadas.remove(coluna)\n",
    "        variaveis_a_remover.update(variaveis_altamente_correlacionadas)\n",
    "    return variaveis_a_remover\n",
    "\n",
    "#Avaliar um Modelo Específico quanto à Métrica de Avaliação Sensibilidade:\n",
    "def avaliar_modelo(modelo, variaveis_preditoras_treino, variavel_alvo_treino, variaveis_preditoras_teste, variavel_alvo_teste):\n",
    "    modelo.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "    previsões = modelo.predict(variaveis_preditoras_teste)\n",
    "    return classification_report(variavel_alvo_teste, previsões, output_dict=True).get('1.0', {}).get('recall')\n",
    "\n",
    "#Avaliar os Modelos de KNN e Naïve Bayes Bernoulli mediante os Diferentes Thresholds de Correlação:\n",
    "def avaliar_modelos_knn_naive_bayes_bernoulli(variaveis_preditoras_treino, variavel_alvo_treino, variaveis_preditoras_teste, variavel_alvo_teste, thresholds_correlacao):\n",
    "    resultados = {}\n",
    "    melhor_threshold_knn = None\n",
    "    melhor_sensibilidade_knn = 0\n",
    "    melhor_threshold_naive_bayes = None\n",
    "    melhor_sensibilidade_naive_bayes = 0\n",
    "\n",
    "    #Iterar pelos Thresholds de Correlação:\n",
    "    for threshold_correlacao in thresholds_correlacao:\n",
    "\n",
    "        #Remover as Variáveis Altamente Correlacionadas/Redundantes:\n",
    "        variaveis_a_remover = funcao_identificar_variaveis_altamente_correlacionadas(variaveis_preditoras_treino, threshold_correlacao)\n",
    "        variaveis_preditoras_treino_reduzidas = variaveis_preditoras_treino.drop(variaveis_a_remover, axis=1)\n",
    "        variaveis_preditoras_teste_reduzidas = variaveis_preditoras_teste.drop(variaveis_a_remover, axis=1)\n",
    "\n",
    "        #Treinar e Avaliar o Modelo de KNN (k = 5) quanto à Métrica de Avaliação Sensibilidade:\n",
    "        sensibilidade_knn = avaliar_modelo(KNeighborsClassifier(n_neighbors=5), variaveis_preditoras_treino_reduzidas, variavel_alvo_treino, variaveis_preditoras_teste_reduzidas, variavel_alvo_teste)\n",
    "\n",
    "        #Treinar e Avaliar o Modelo de Naïve Bayes Bernoulli quanto à Métrica de Avaliação Sensibilidade:\n",
    "        sensibilidade_naive_bayes_bernoulli = avaliar_modelo(BernoulliNB(), variaveis_preditoras_treino_reduzidas, variavel_alvo_treino, variaveis_preditoras_teste_reduzidas, variavel_alvo_teste)\n",
    "\n",
    "        #Armazenar os Resultados - Número de Variáveis a Remover e Sensibilidades dos Modelos de KNN e Naïve Bayes Bernoulli:\n",
    "        resultados[threshold_correlacao] = {'Número de Variáveis a Remover': len(variaveis_a_remover), 'Sensibilidade do Modelo de KNN': sensibilidade_knn,\n",
    "                                 'Sensibilidade do Modelo de Naïve Bayes Bernoulli': sensibilidade_naive_bayes_bernoulli}\n",
    "\n",
    "        #Atualizar o Melhor Threshold de Correlação e Sensibilidade para o Modelo de KNN:\n",
    "        if sensibilidade_knn is not None and sensibilidade_knn > melhor_sensibilidade_knn:\n",
    "            melhor_sensibilidade_knn = sensibilidade_knn\n",
    "            melhor_threshold_knn = threshold_correlacao\n",
    "\n",
    "        #Atualizar o Melhor Threshold de Correlação e Sensibilidade para o Modelo Naïve Bayes Bernoulli:\n",
    "        if sensibilidade_naive_bayes_bernoulli is not None and sensibilidade_naive_bayes_bernoulli > melhor_sensibilidade_naive_bayes:\n",
    "            melhor_sensibilidade_naive_bayes = sensibilidade_naive_bayes_bernoulli\n",
    "            melhor_threshold_naive_bayes = threshold_correlacao\n",
    "\n",
    "    return resultados, melhor_threshold_knn, melhor_sensibilidade_knn, melhor_threshold_naive_bayes, melhor_sensibilidade_naive_bayes\n",
    "\n",
    "#Definir os Thresholds de Correlação:\n",
    "thresholds_correlacao = numpy.arange(0.10, 1.01, 0.05)\n",
    "\n",
    "#Para cada Threshold de Correlação, Avaliar os Modelos de KNN e Naïve Bayes Bernoulli quanto à Métrica de Avaliação Sensibilidade:\n",
    "resultados_sensibilidade, melhor_threshold_knn, melhor_sensibilidade_knn, melhor_threshold_naive_bayes, melhor_sensibilidade_naive_bayes = avaliar_modelos_knn_naive_bayes_bernoulli(\n",
    "    variaveis_preditoras_treino, variavel_alvo_treino, variaveis_preditoras_teste, variavel_alvo_teste, thresholds_correlacao)\n",
    "\n",
    "#Para cada Threshold de Correlação, Mostrar o Número de Variáveis a Remover e as Sensibilidades dos Modelos Classificadores de KNN e Naïve Bayes Bernoulli:\n",
    "for threshold_correlacao, metricas in resultados_sensibilidade.items():\n",
    "    sensibilidade_knn = f\"{metricas['Sensibilidade do Modelo de KNN']:.2f}\" if metricas['Sensibilidade do Modelo de KNN'] is not None else 'N/A'\n",
    "    sensibilidade_naive_bayes_bernoulli = f\"{metricas['Sensibilidade do Modelo de Naïve Bayes Bernoulli']:.2f}\" if metricas['Sensibilidade do Modelo de Naïve Bayes Bernoulli'] is not None else 'N/A'\n",
    "    print(f\"Threshold de Correlação: {threshold_correlacao:.2f}, Número de Variáveis a Remover: {metricas['Número de Variáveis a Remover']}, \"\n",
    "          f\"Sensibilidade do Modelo de KNN: {sensibilidade_knn}, \"\n",
    "          f\"Sensibilidade do Modelo de Naïve Bayes Bernoulli: {sensibilidade_naive_bayes_bernoulli}\")\n",
    "\n",
    "#Melhor Threshold de Correlação para os Modelos Classificadores de KNN e Naïve Bayes Bernoulli, com base nas Sensibilidades mais Altas:\n",
    "print(f\"\\nMelhor Threshold de Correlação para o Modelo de KNN: {melhor_threshold_knn:.2f} - Sensibilidade: {melhor_sensibilidade_knn:.2f} - Número de Variáveis a Remover: {resultados_sensibilidade[melhor_threshold_knn]['Número de Variáveis a Remover']}\")\n",
    "print(f\"\\nMelhor Threshold de Correlação para o Modelo de Naïve Bayes Bernoulli: {melhor_threshold_naive_bayes:.2f} - Sensibilidade: {melhor_sensibilidade_naive_bayes:.2f} - Número de Variáveis a Remover: {resultados_sensibilidade[melhor_threshold_naive_bayes]['Número de Variáveis a Remover']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fae664",
   "metadata": {},
   "source": [
    "<H5>3.1.1.2. Seleção de Variáveis - Variáveis Redundantes - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745aa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Thresholds de Correlação:\n",
    "thresholds_correlacao = [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "#Sensibilidades do Modelo Classificador de KNN para o Conjunto de Treino:\n",
    "treino_sensibilidade_knns = [0.03, 0.03, 0.11, 0.68, 0.68, 0.65, 0.65, 0.65, 0.62, 0.60, 0.64, 0.64, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.76]\n",
    "\n",
    "#Sensibilidades do Modelo Classificador de Naïve Bayes Bernoulli para o Conjunto de Treino:\n",
    "treino_sensibilidade_naive_bayess = [0.49, 0.49, 0.48, 0.48, 0.48, 0.71, 0.71, 0.71, 0.57, 0.60, 0.63, 0.72, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.71]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Cores, Espaçamento, Espessura da Linha, Legenda, Grelha e Layout:\n",
    "fig = matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Estudo da Redundância\\n\\nAnálise das Sensibilidades dos Modelos de KNN e Naïve Bayes em função do Threshold de Correlação', fontsize=16, pad=20)\n",
    "matplotlib.pyplot.plot(thresholds_correlacao, treino_sensibilidade_knns, label='Modelo Classificador de KNN', color='green', linewidth=2)\n",
    "matplotlib.pyplot.plot(thresholds_correlacao, treino_sensibilidade_naive_bayess, label='Modelo Classificador de Naïve Bayes Bernoulli', color='orange', linewidth=2)\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.grid(True)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanho, Espaçamento, Limites Mínimo e Máximo e Intervalo:\n",
    "matplotlib.pyplot.xlabel('Threshold de Correlação', fontsize=14, labelpad=15)\n",
    "matplotlib.pyplot.xticks(numpy.arange(0.25, 1.01, 0.05))\n",
    "matplotlib.pyplot.xlim(0.25, 1.00)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanho, Espaçamento, Limites Mínimo e Máximo, Intervalo e Formatações:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14, labelpad=15)\n",
    "matplotlib.pyplot.yticks(numpy.arange(0, 1.1, 0.1))\n",
    "def format_func(valor, tick_number):\n",
    "    return f'{valor:.2f}'\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Espessura e Cor:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['left', 'bottom']:\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_visible(False)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0086e",
   "metadata": {},
   "source": [
    "<H5>3.1.1.3. Seleção de Variáveis - Variáveis Redundantes - Variáveis Redundantes a Remover para o Melhor Threshold de Correlação:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Variável Alvo:\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir os Conjuntos de Treino e de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "X_treino = conjunto_treino.drop(variavel_alvo, axis=1)\n",
    "Y_treino = conjunto_treino[variavel_alvo]\n",
    "X_teste = conjunto_teste.drop(variavel_alvo, axis=1)\n",
    "Y_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Calcular a Matriz de Correlação Absoluta:\n",
    "matriz_correlacao = abs(X_treino.corr())\n",
    "\n",
    "#Identificar as Variáveis Altamente Correlacionadas/Redundantes a Remover:\n",
    "def identificar_variaveis_altamente_correlacionadas(matriz_correlacao, threshold):\n",
    "    variaveis = matriz_correlacao.columns\n",
    "    variaveis_a_remover = set()\n",
    "    for coluna in variaveis:\n",
    "        variaveis_correlacionadas = matriz_correlacao.index[matriz_correlacao[coluna] >= threshold].tolist()\n",
    "        if coluna in variaveis_correlacionadas:\n",
    "            variaveis_correlacionadas.remove(coluna)\n",
    "        variaveis_a_remover.update(variaveis_correlacionadas)\n",
    "    return variaveis_a_remover\n",
    "\n",
    "#Definir o Melhor Threshold de Correlação:\n",
    "melhor_threshold_correlacao = 1.00\n",
    "\n",
    "#Identificar as Variáveis Altamente Correlacionadas/Redundantes a Remover:\n",
    "variaveis_a_remover = identificar_variaveis_altamente_correlacionadas(matriz_correlacao, melhor_threshold_correlacao)\n",
    "\n",
    "#Melhor Threshold de Correlação e Variáveis Altamente Correlacionadas/Redundantes a Remover:\n",
    "print(f\"Melhor Threshold de Correlação: {melhor_threshold_correlacao:.2f}\")\n",
    "print(f\"Variáveis Altamente Correlacionadas/Redundantes a Remover: {sorted(variaveis_a_remover)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a467a2",
   "metadata": {},
   "source": [
    "<H5>3.1.2. Seleção de Variáveis - Variáveis de Baixa Variância:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3752b8",
   "metadata": {},
   "source": [
    "<H5>3.1.2.1. Seleção de Variáveis - Variáveis de Baixa Variância - Número de Variáveis de Baixa Variância a Remover e Sensibilidades dos Modelos de KNN e Naïve Bayes para cada Threshold de Variância - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Classificador de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do SKLearn.Naive_Bayes, Importar o Classificador de Naïve Bayes Bernoulli:\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar o Relatório de Classificação:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Dividir o Conjunto de Treino em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_treino = conjunto_treino.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_treino = conjunto_treino[variavel_alvo]\n",
    "\n",
    "#Dividir o Conjunto de Teste em Variáveis Preditoras e Variável Alvo:\n",
    "variaveis_teste = conjunto_teste.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Função para Avaliar os Modelos:\n",
    "def funcao_avaliar_modelo(modelo, X_treino, Y_treino, X_teste, Y_teste):\n",
    "    modelo.fit(X_treino, Y_treino)\n",
    "    Y_previsto = modelo.predict(X_teste)\n",
    "    relatorio = classification_report(Y_teste, Y_previsto, output_dict=True)\n",
    "    return relatorio['1.0']['recall'] if '1.0' in relatorio else None\n",
    "\n",
    "#Função para Avaliar os Modelos com Diferentes Thresholds de Variância:\n",
    "def funcao_avaliar_modelos_com_thresholds_variancia(X_treino, Y_treino, X_teste, Y_teste, thresholds_variancia):\n",
    "    resultados = {}\n",
    "    threshold_sem_variavel = None\n",
    "    \n",
    "    #Calcular a Variância das Variáveis no Conjunto de Treino:\n",
    "    variancias = X_treino.var()\n",
    "\n",
    "    #Iterar sobre os Thresholds de Variância:\n",
    "    for threshold_variancia in thresholds_variancia:\n",
    "        variaveis_a_manter = variancias[variancias >= threshold_variancia].index\n",
    "        numero_variaveis_restantes = len(variaveis_a_manter)\n",
    "\n",
    "        #Se Não Houver Variáveis Restantes:\n",
    "        if numero_variaveis_restantes == 0:\n",
    "            if threshold_sem_variavel is None:\n",
    "                threshold_sem_variavel = threshold_variancia\n",
    "\n",
    "            #Iniciar o Dicionário para o Threshold de Variância:\n",
    "            threshold_variancia_formatado = round(threshold_variancia, 2)\n",
    "            if threshold_variancia_formatado not in resultados:\n",
    "                resultados[threshold_variancia_formatado] = {'Sensibilidade do Modelo de KNN': None, 'Sensibilidade do Modelo de Naïve Bayes': None, 'Variáveis Restantes': 0}\n",
    "            continue\n",
    "\n",
    "        #Reduzir os Conjuntos de Treino e de Teste com base no Threshold de Variância:\n",
    "        X_treino_reduzido = X_treino[variaveis_a_manter]\n",
    "        X_teste_reduzido = X_teste[variaveis_a_manter]\n",
    "\n",
    "        #Treinar e Avaliar os Modelos de KNN e Naïve Bayes:\n",
    "        modelos = {'KNN': KNeighborsClassifier(n_neighbors=5), 'Naïve Bayes': BernoulliNB()}\n",
    "        for nome_modelo, modelo in modelos.items():\n",
    "            sensibilidade = funcao_avaliar_modelo(modelo, X_treino_reduzido, Y_treino, X_teste_reduzido, Y_teste)\n",
    "            threshold_variancia_formatado = round(threshold_variancia, 2)\n",
    "            if threshold_variancia_formatado not in resultados:\n",
    "                resultados[threshold_variancia_formatado] = {}\n",
    "            resultados[threshold_variancia_formatado][nome_modelo] = sensibilidade\n",
    "        \n",
    "        #Armazenar o Número de Variáveis Restantes:\n",
    "        resultados[round(threshold_variancia, 2)]['Variáveis Restantes'] = numero_variaveis_restantes\n",
    "\n",
    "    return resultados, threshold_sem_variavel\n",
    "\n",
    "#Definir os Thresholds de Variância:\n",
    "thresholds_variancia = numpy.arange(0.10, 1.85, 0.05)\n",
    "\n",
    "#Avaliar os Modelos de KNN e Naïve Bayes com Base nos Thresholds de Variância:\n",
    "sensibilidade_resultados, threshold_sem_variavel = funcao_avaliar_modelos_com_thresholds_variancia(\n",
    "    variaveis_treino, variavel_alvo_treino, variaveis_teste, variavel_alvo_teste, thresholds_variancia)\n",
    "\n",
    "#Encontrar o Melhor Threshold de Variância para os Modelos de KNN e Naïve Bayes:\n",
    "melhor_threshold_knn = None\n",
    "melhor_sensibilidade_knn = -1\n",
    "melhor_threshold_naive_bayes = None\n",
    "melhor_sensibilidade_naive_bayes = -1\n",
    "numero_variaveis_restantes_knn = None\n",
    "numero_variaveis_restantes_naive_bayes = None\n",
    "\n",
    "#Avaliação da Sensibilidade dos Modelos de KNN e Naïve Bayes para cada Threshold de Variância:\n",
    "for threshold_variancia, metricas in sensibilidade_resultados.items():\n",
    "    sensibilidade_knn = metricas.get('KNN')\n",
    "    sensibilidade_naive_bayes = metricas.get('Naïve Bayes')\n",
    "\n",
    "    #Atualizar o Melhor Threshold de Variância para o Modelo de KNN:\n",
    "    if sensibilidade_knn is not None and sensibilidade_knn > melhor_sensibilidade_knn:\n",
    "        melhor_threshold_knn = threshold_variancia\n",
    "        melhor_sensibilidade_knn = sensibilidade_knn\n",
    "        numero_variaveis_restantes_knn = metricas['Variáveis Restantes']\n",
    "\n",
    "    #Atualizar o Melhor Threshold de Variância para o Modelo de Naïve Bayes:\n",
    "    if sensibilidade_naive_bayes is not None and sensibilidade_naive_bayes > melhor_sensibilidade_naive_bayes:\n",
    "        melhor_threshold_naive_bayes = threshold_variancia\n",
    "        melhor_sensibilidade_naive_bayes = sensibilidade_naive_bayes\n",
    "        numero_variaveis_restantes_naive_bayes = metricas['Variáveis Restantes']\n",
    "\n",
    "#Mostrar os Resultados Finais, incluindo o Threshold de Variância:\n",
    "for threshold_variancia, metricas in sensibilidade_resultados.items():\n",
    "    sensibilidade_knn = metricas.get('KNN')\n",
    "    sensibilidade_naive_bayes = metricas.get('Naïve Bayes')\n",
    "    variáveis_restantes = metricas.get('Variáveis Restantes')\n",
    "\n",
    "    #Evitar a Duplicação de Resultados para os Thresholds de Variância sem Variáveis Restantes:\n",
    "    if sensibilidade_knn is not None or sensibilidade_naive_bayes is not None:\n",
    "        print(f\"Threshold de Variância: {threshold_variancia:.2f}, \"\n",
    "              f\"Sensibilidade do Modelo de KNN: {sensibilidade_knn:.2f}, \"\n",
    "              f\"Sensibilidade do Modelo de Naïve Bayes: {sensibilidade_naive_bayes:.2f}, \"\n",
    "              f\"Número de Variáveis Restantes: {variáveis_restantes}\")\n",
    "\n",
    "#Mostrar o Threshold de Variância Final (\"Nenhuma Variável Restante\"):\n",
    "if threshold_sem_variavel is not None:\n",
    "    print(f\"Nenhuma Variável Restante para o Threshold de Variância: {threshold_sem_variavel:.2f}\")\n",
    "\n",
    "#Mostrar o Melhor Threshold de Variância para os Modelos de KNN e Naïve Bayes, com base nas Sensibilidades mais Altas:\n",
    "print(f\"\\nMelhor Threshold de Variância para o Modelo de KNN = {melhor_threshold_knn:.2f} com Sensibilidade = {melhor_sensibilidade_knn:.2f} e Variáveis Restantes = {numero_variaveis_restantes_knn}\")\n",
    "print(f\"\\nMelhor Threshold de Variância para o Modelo de Naïve Bayes = {melhor_threshold_naive_bayes:.2f} com Sensibilidade = {melhor_sensibilidade_naive_bayes:.2f} e Variáveis Restantes = {numero_variaveis_restantes_naive_bayes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c231f",
   "metadata": {},
   "source": [
    "<H5>3.1.2.2. Seleção de Variáveis - Variáveis de Baixa Variância - Número de Variáveis de Baixa Variância a Remover e Sensibilidades dos Modelos KNN e Naïve Bayes para cada Threshold de Variância - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06440d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Definir os Thresholds de Variância:\n",
    "thresholds_variancia = [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30,\n",
    "                        1.35, 1.40, 1.45, 1.50]\n",
    "\n",
    "#Definir as Sensibilidades do Modelo KNN para os Thresholds de Variância Assinalados:\n",
    "sensibilidades_knn = [0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.73, 0.58, 0.22, 0.22, 0.22, 0.22, 0.22,\n",
    "                      0.22, 0.22, 0.22, 0.22]\n",
    "\n",
    "#Definir as Sensibilidades do Modelo Naïve Bayes para os Thresholds de Variância Assinalados:\n",
    "sensibilidades_naive_bayes = [0.71, 0.71, 0.71, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.72, 0.72, 0.69, 0.71, 0.62, 0.41, 0.41, 0.41, 0.41,\n",
    "                              0.41, 0.41, 0.41, 0.41, 0.41]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título, Tamanho, Espaçamento, Legenda de Cores e Grelha:\n",
    "matplotlib.pyplot.figure(figsize=(8, 5))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Estudo da Variância\\n\\nAnálise das Sensibilidades dos Modelos de KNN e Naïve Bayes em função do Threshold de Variância', fontsize=14, pad=20)\n",
    "matplotlib.pyplot.plot(thresholds_variancia, sensibilidades_knn, label='Modelo Classificador de KNN', color='green', linewidth=2)\n",
    "matplotlib.pyplot.plot(thresholds_variancia, sensibilidades_naive_bayes, label='Modelo Classificador de Naïve Bayes', color='orange', linewidth=2)\n",
    "matplotlib.pyplot.legend(fontsize=10, frameon=True, edgecolor='gray')\n",
    "matplotlib.pyplot.grid(True)\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanho, Espaçamento, Limite Máximo e Ajustes:\n",
    "matplotlib.pyplot.xlabel('Threshold de Variância', fontsize=14, labelpad=15)\n",
    "matplotlib.pyplot.xticks(numpy.arange(0.10, 1.51, 0.10))\n",
    "matplotlib.pyplot.xlim(0.10, 1.50)\n",
    "def format_x_ticks(value, tick_number):\n",
    "    return f'{value:.2f}'\n",
    "matplotlib.pyplot.gca().xaxis.set_major_formatter(FuncFormatter(format_x_ticks))\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanho, Espaçamento, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14, labelpad=15)\n",
    "matplotlib.pyplot.yticks(numpy.arange(0.00, 1.10, 0.10))\n",
    "matplotlib.pyplot.ylim(0.00, 1.00)\n",
    "def format_y_ticks(value, tick_number):\n",
    "    return f'{value:.2f}'\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FuncFormatter(format_y_ticks))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Espessura e Cor:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['left', 'bottom']:\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_visible(False)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c99fb",
   "metadata": {},
   "source": [
    "<H5>3.1.2.3. Seleção de Variáveis - Variáveis de Baixa Variância - Variâncias das Variáveis:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Remover a Variável Alvo:\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "X_treino = conjunto_treino.drop(variavel_alvo, axis=1)\n",
    "X_teste = conjunto_teste.drop(variavel_alvo, axis=1)\n",
    "\n",
    "#Calcular a Variância das Variáveis para ambos os Conjuntos de Treino e de Teste:\n",
    "variancias_treino = X_treino.var()\n",
    "variancias_teste = X_teste.var()\n",
    "\n",
    "#Variáveis e respetivas Variâncias para o Conjunto de Treino:\n",
    "print(\"Conjunto de Treino:\\n\")\n",
    "print(f\"{'Variáveis:':<30} {'Variâncias:\\n'}\")\n",
    "for variavel, variancia in zip(X_treino.columns, variancias_treino):\n",
    "    print(f\"{variavel:<30} {variancia:.2f}\")\n",
    "\n",
    "#Variáveis e respetivas Variâncias para o Conjunto de Teste:\n",
    "print(\"\\n\\nConjunto de Teste:\\n\")\n",
    "print(f\"{'Variáveis:':<30} {'Variâncias:\\n'}\")\n",
    "for variavel, variancia in zip(X_teste.columns, variancias_teste):\n",
    "    print(f\"{variavel:<30} {variancia:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262ec23",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca10c15",
   "metadata": {},
   "source": [
    "<H4>4. Parte 4. Avaliação de Modelos Classificadores:</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866704d",
   "metadata": {},
   "source": [
    "<H5>4.1 - Modelo de Naïve Bayes:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdf04c",
   "metadata": {},
   "source": [
    "<H5>4.1.1 - Modelo de Naïve Bayes - Naïve Bayes Gaussiano vs Naïve Bayes Bernoulli - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33faafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Naive_Bayes, Importar os Modelos de Naïve Bayes Gaussiano e Bernoulli:\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Função para Separar as Variáveis de Entrada e de Saída:\n",
    "def separar_variaveis(data):\n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "    return X, Y\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separação das Variáveis de Entrada e de Saída para os Conjuntos de Treino e de Teste:\n",
    "X_treino, Y_treino = separar_variaveis(conjunto_treino)\n",
    "X_teste, Y_teste = separar_variaveis(conjunto_teste)\n",
    "\n",
    "#Definir os Modelos de Naïve Bayes Gaussiano e Bernoulli:\n",
    "naive_bayes_gaussiano = GaussianNB()\n",
    "naive_bayes_bernoulli = BernoulliNB()\n",
    "\n",
    "#Treinar os Modelos de Naïve Bayes Gaussiano e Bernoulli no Conjunto de Treino:\n",
    "naive_bayes_gaussiano.fit(X_treino, Y_treino)\n",
    "naive_bayes_bernoulli.fit(X_treino, Y_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste:\n",
    "Y_previsto_gaussiano = naive_bayes_gaussiano.predict(X_teste)\n",
    "Y_previsto_bernoulli = naive_bayes_bernoulli.predict(X_teste)\n",
    "\n",
    "#Obter as Probabilidades para o Cálculo de AUC:\n",
    "Y_probabilidades_gaussiano = naive_bayes_gaussiano.predict_proba(X_teste)[:,1]\n",
    "Y_probabilidades_bernoulli = naive_bayes_bernoulli.predict_proba(X_teste)[:,1]\n",
    "\n",
    "#Função para Calcular e Mostrar as 5 Métricas de Avaliação:\n",
    "def funcao_funcao_calcular_metricas(y_verdadeiro, y_previsto, y_prob, modelo):\n",
    "    print(f\"5 Métricas de Avaliação para o Modelo {modelo}:\\n\")\n",
    "    print(f\"Exatidão: {accuracy_score(y_verdadeiro, y_previsto):.2f}\")\n",
    "    print(f\"Sensibilidade: {recall_score(y_verdadeiro, y_previsto, pos_label=1):.2f}\")\n",
    "    print(f\"Precisao: {precision_score(y_verdadeiro, y_previsto, pos_label=1):.2f}\")\n",
    "    print(f\"AUC: {roc_auc_score(y_verdadeiro, y_prob):.2f}\")\n",
    "    print(f\"F1: {f1_score(y_verdadeiro, y_previsto, pos_label=1):.2f}\\n\")\n",
    "\n",
    "#Resultados - Calcular as 5 Métricas de Avaliação:\n",
    "funcao_funcao_calcular_metricas(Y_teste, Y_previsto_gaussiano, Y_probabilidades_gaussiano, \"Naïve Bayes Gaussiano\")\n",
    "funcao_funcao_calcular_metricas(Y_teste, Y_previsto_bernoulli, Y_probabilidades_bernoulli, \"Naïve Bayes Bernoulli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb984e",
   "metadata": {},
   "source": [
    "<H5>4.1.2 - Modelo de Naïve Bayes - Modelos de Naïve Bayes Gaussiano e Bernoulli - Sensibilidade - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Modelos de Naïve Bayes - Gaussiano e Bernoulli:\n",
    "modelos_naive_bayes_gaussiano_bernoulli = ['Modelo de Naïve Bayes Gaussiano', 'Modelo de Naïve Bayes Bernoulli']\n",
    "\n",
    "#Resultados das Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "sensibilidade = [0.73, 0.71]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título, Espaçamento, Cor, Grelha e Layout:\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação da Sensibilidade dos Modelos de Naïve Bayes Gaussiano e Bernoulli', fontsize=16, pad=20, color='black')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Índice, Largura, Cores, Deslocamento e Valores:\n",
    "indice_barras = np.arange(len(modelos_naive_bayes_gaussiano_bernoulli))\n",
    "largura_barras = 0.4\n",
    "cores_barras = {\"Sensibilidade\": (sensibilidade, ['#ff7f0e', '#2ca02c'])}\n",
    "deslocamento_barras = -largura_barras/2 \n",
    "def funcao_adicionar_barras(indices, valores, largura, deslocamento, cor, nome_metrica):\n",
    "    barras_atual = plt.bar(indices + deslocamento, valores, largura, label=nome_metrica, color=cor)\n",
    "    for i, barra in enumerate(barras_atual):\n",
    "        altura_y = barra.get_height()\n",
    "        x_centro = barra.get_x() + barra.get_width() / 2\n",
    "        plt.text(x_centro, altura_y, f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=12)\n",
    "    return barras_atual\n",
    "barras_adicionadas = funcao_adicionar_barras(indice_barras, sensibilidade, largura_barras, deslocamento_barras, ['#ff7f0e', '#2ca02c'], 'Sensibilidade')\n",
    "centros_barras = [barra.get_x() + barra.get_width()/2 for barra in barras_adicionadas]\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Rotação e Posição:\n",
    "plt.xlabel('Modelos de Naïve Bayes', fontsize=14, labelpad=25, color='black')\n",
    "plt.xticks(centros_barras, modelos_naive_bayes_gaussiano_bernoulli, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "plt.ylabel('Sensibilidade', fontsize=14, labelpad=15, color='black')\n",
    "plt.tick_params(axis='y', colors='black', labelsize=12)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.gca().yaxis.set_ticks(np.arange(0, 1.01, 0.20))\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = plt.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f0f90",
   "metadata": {},
   "source": [
    "<H5>4.1.3 - Modelo de Naïve Bayes - Modelos de Naïve Bayes Gaussiano e Bernoulli - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Modelos de Naïve Bayes Gaussiano e Bernoulli:\n",
    "modelos_naive_bayes_gaussiano_bernoulli = ['Modelo de Naïve Bayes Gaussiano', 'Modelo de Naïve Bayes Bernoulli']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.74, 0.73]\n",
    "sensibilidade = [0.73, 0.71]\n",
    "precisao = [0.44, 0.43]\n",
    "auc = [0.81, 0.79]\n",
    "f1 = [0.55, 0.53]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título, Espaçamento, Cores, Legenda, Grelha e Ajustar o Layout:\n",
    "matplotlib.pyplot.figure(figsize=(12, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação dos Modelos de Naïve Bayes Gaussiano e Bernoulli', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Índice, Largura, Cores, Deslocamento e Valores:\n",
    "indice_barras = numpy.arange(len(modelos_naive_bayes_gaussiano_bernoulli)) * 1.4\n",
    "largura_barras = 0.15\n",
    "cores_barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'), \"F1\": (f1, '#9467bd')}\n",
    "deslocamento_barras = 0\n",
    "def funcao_adicionar_barras(indices, valores, largura_barras, deslocamento_barras, cor, nome_metrica):\n",
    "    barras_atual = matplotlib.pyplot.bar(indices + deslocamento_barras, valores, largura_barras, label=nome_metrica, color=cor)\n",
    "    for barra in barras_atual:\n",
    "        altura_y = barra.get_height()\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2, altura_y, f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=12)\n",
    "for nome_metrica, (valores, cor) in cores_barras.items():\n",
    "    funcao_adicionar_barras(indice_barras, valores, largura_barras, deslocamento_barras, cor, nome_metrica)\n",
    "    deslocamento_barras += largura_barras\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores, Rotação e Posição:\n",
    "matplotlib.pyplot.xlabel('Modelos de Naïve Bayes', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, modelos_naive_bayes_gaussiano_bernoulli, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=12)\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e68342",
   "metadata": {},
   "source": [
    "<H5>4.1.4 - Modelo de Naïve Bayes - Modelo de Naïve Bayes Gaussiano - Matriz de Confusão:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do SKLearn.Naive_Bayes, Importar o Modelo de Naïve Bayes Gaussiano:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Importar o Seaborn:\n",
    "import seaborn\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para os Conjuntos de Treino e de Teste:\n",
    "variaveis_preditoras_treino = conjunto_treino.iloc[:, :-1]\n",
    "variavel_alvo_treino = conjunto_treino.iloc[:, -1]\n",
    "variaveis_preditoras_teste = conjunto_teste.iloc[:, :-1]\n",
    "variavel_alvo_teste = conjunto_teste.iloc[:, -1]\n",
    "\n",
    "#Definir o Modelo de Naïve Bayes Gaussiano:\n",
    "modelo_naive_bayes = GaussianNB()\n",
    "\n",
    "#Treinar o Modelo de Naïve Bayes Gaussiano no Conjunto de Treino:\n",
    "modelo_naive_bayes.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer as Previsões no Conjunto de Teste:\n",
    "variavel_alvo_prevista_teste = modelo_naive_bayes.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão:\n",
    "matriz_confusao = confusion_matrix(variavel_alvo_teste, variavel_alvo_prevista_teste)\n",
    "\n",
    "#Configurações do Gráfico da Matriz de Confusão - Tamanhos, Título, Cor, Mapa de Calor, Limites Mínimo e Máximo, Incremento, Escala de Cores, Fundo e Valores:\n",
    "matplotlib.pyplot.figure(figsize=(8, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de Naïve Bayes Gaussiano\\n', color='black', fontsize=16)\n",
    "mapa_calor = seaborn.heatmap(matriz_confusao, annot=False, fmt='d', cmap='Greens', vmin=0, vmax=26000, xticklabels=numpy.unique(variavel_alvo_teste), yticklabels=numpy.unique(variavel_alvo_teste), cbar=True, linewidths=0.5)\n",
    "escala_cores = mapa_calor.collections[0].colorbar\n",
    "escala_cores.ax.yaxis.set_tick_params(color='black')\n",
    "valores = numpy.arange(0, 26000 + 2000, 2000)\n",
    "escala_cores.set_ticks(valores)\n",
    "escala_cores.ax.set_yticklabels([f\"{int(valor):,}\".replace(',', '.') for valor in valores], color='black')\n",
    "matplotlib.pyplot.gca().set_facecolor('#2ca02c')\n",
    "for linha in range(matriz_confusao.shape[0]):\n",
    "    for coluna in range(matriz_confusao.shape[1]):\n",
    "        matplotlib.pyplot.text(coluna + 0.5, linha + 0.5, f\"{matriz_confusao[linha, coluna]:,}\".replace(',', '.'), color='#ff7f0e', ha='center', va='center', fontsize=16)\n",
    "\n",
    "#Configurações do Eixo X - Título, Cores, Tamanhos, Espaçamento e Valores:\n",
    "matplotlib.pyplot.xlabel('Rótulo Previsto', color='black', fontsize=14, labelpad=10)\n",
    "matplotlib.pyplot.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Cores, Tamanhos, Valores e Rotação:\n",
    "matplotlib.pyplot.ylabel('Verdadeiro Rótulo', color='black', fontsize=14)\n",
    "matplotlib.pyplot.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13, rotation=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor:\n",
    "for spine in ['top', 'right', 'left', 'bottom']:\n",
    "    matplotlib.pyplot.gca().spines[spine].set_color('black')\n",
    "\n",
    "#Resultados - Matriz de Confusão:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37198365",
   "metadata": {},
   "source": [
    "<H5>4.2. - Modelo de KNN:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7a505",
   "metadata": {},
   "source": [
    "<H5>4.2.1 - Modelo de KNN - Métrica de Avaliação Sensibilidade em Função do Número de Vizinhos (k) e Distâncias de Manhattan, Euclidiana e de Chebyshev - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir da Biblioteca Numerical Python, Importar as Estruturas dos Dados:\n",
    "from numpy import array, ndarray\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as Métricas de Avaliação para Classificação, Mínimo Necessário para Melhoria e Função Ler Dados dos Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files\n",
    "\n",
    "#Dicionário das Distâncias:\n",
    "distancias_portugues = {'manhattan': 'Distância de Manhattan', 'euclidean': 'Distância Euclidiana', 'chebyshev': 'Distância de Chebyshev', 'minkowski': 'Distância de Minkowski', 'cosine': 'Distância de Cosseno', 'jaccard': 'Distância de Jaccard', 'cityblock': 'Distância de Cityblock', 'mahalanobis': 'Distância de Mahalanobis','correlation': 'Distância de Correlação', 'hamming': 'Distância de Hamming', 'braycurtis': 'Distância de Bray-Curtis', 'canberra': 'Distância de Canberra', 'sqeuclidean': 'Distância Quadrática Euclidiana', 'rogerstanimoto': 'Distância Rogers-Tanimoto'}\n",
    "\n",
    "#Função para Estudo e Seleção de Modelos de KNN com base na Métrica de Avaliação Sensibilidade:\n",
    "def estudo_modelo_classificador_knn(X_treino: ndarray, Y_treino: array, X_teste: ndarray, Y_teste: array, k_vizinhos_maximo: int = 25, intervalo: int = 2, metrica='recall', distancias=['manhattan', 'euclidean', 'chebyshev']) -> tuple[KNeighborsClassifier | None, dict]:\n",
    "    melhor_modelo = None\n",
    "    melhores_parametros = {'Nome': 'KNN', 'Métrica': metrica, 'Parâmetros': ()}\n",
    "    melhor_performance = 0.0\n",
    "    valores = {}\n",
    "\n",
    "    #Avaliação de Modelos de KNN para Diferentes Valores de K Vizinhos e Distâncias:\n",
    "    for distancia in distancias:\n",
    "        valores_teste = []\n",
    "        distancia_traduzida = distancias_portugues.get(distancia, distancia)\n",
    "        for k in range(1, k_vizinhos_maximo + 1, intervalo):\n",
    "            classificador = KNeighborsClassifier(n_neighbors=k, metric=distancia)\n",
    "            classificador.fit(X_treino, Y_treino)\n",
    "            previsao_Y = classificador.predict(X_teste)\n",
    "            avaliacao = CLASS_EVAL_METRICS[metrica](Y_teste, previsao_Y)\n",
    "            valores_teste.append(avaliacao)\n",
    "            \n",
    "            #Atualização do Melhor Modelo de KNN e Parâmetros K Vizinhos e Distâncias com base na Métrica de Avaliação Sensibilidade:\n",
    "            if avaliacao - melhor_performance > DELTA_IMPROVE:\n",
    "                melhor_performance = avaliacao\n",
    "                melhores_parametros['Parâmetros'] = (k, distancia)\n",
    "                melhor_modelo = classificador\n",
    "            \n",
    "            #Modelo de KNN: Distância ; K Vizinhos ; Sensibilidade:\n",
    "            print(f'Modelo de KNN: {distancia_traduzida} ; K Vizinhos = {k} ; Sensibilidade = {avaliacao:.2f}')\n",
    "        \n",
    "        valores[distancia] = valores_teste\n",
    "    \n",
    "    #Melhor Modelo de KNN: Melhor K Vizinhos e Melhor Distância:\n",
    "    print(f'\\nMelhor Modelo de KNN: {distancias_portugues} ; K Vizinhos = {melhores_parametros[\"Parâmetros\"][0]} ; Sensibilidade = {melhor_performance:.2f}')\n",
    "    return melhor_modelo, melhores_parametros, valores\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = 'conjunto_treino_balanceado_sobreamostragem_SMOTE.csv'\n",
    "conjunto_teste = 'conjunto_teste_normalizado_z-score.csv'\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Definir a Métrica de Avaliação (Sensibilidade):\n",
    "metrica_avaliacao = 'recall'\n",
    "\n",
    "#Carregar os Dados de Treino e de Teste:\n",
    "X_treino, X_teste, Y_treino, Y_teste, etiquetas, variaveis = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Resultados - Melhor Modelo KNN, com Melhor K Vizinhos e Melhor Distância:\n",
    "melhor_modelo, parâmetros, valores = estudo_modelo_classificador_knn(X_treino, Y_treino, X_teste, Y_teste, k_vizinhos_maximo=25, metrica=metrica_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a5913",
   "metadata": {},
   "source": [
    "<H5>4.2.2 - Modelo de KNN - Análise da Sensibilidade para diferentes Parametrizações do Modelo de KNN - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b85557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker Importar Formatações:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Número de K Vizinhos:\n",
    "numero_k_vizinhos = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25]\n",
    "\n",
    "#Métrica de Avaliação Sensibilidade para as Distâncias de Manhattan, Euclidiana e de Chebyshev:\n",
    "sensibilidade_distancia_manhattan = [0.59, 0.70, 0.73, 0.75, 0.76, 0.76, 0.77, 0.77, 0.78, 0.78, 0.78, 0.79, 0.79]\n",
    "sensibilidade_distancia_euclidiana = [0.63, 0.72, 0.76, 0.78, 0.79, 0.80, 0.81, 0.81, 0.81, 0.82, 0.82, 0.82, 0.82]\n",
    "sensibilidade_distancia_chebyshev = [0.64, 0.71, 0.74, 0.76, 0.77, 0.77, 0.78, 0.78, 0.76, 0.79, 0.79, 0.79, 0.79]\n",
    "\n",
    "#Configurações do Gráfico - Tamanhos, Título Geral, Rótulos, Cores, Espessuras, Legenda de Cores, Grelha e Ajustar o Layout:\n",
    "matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\n Análise da Sensibilidade para diferentes Parametrizações do Modelo de KNN', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.plot(numero_k_vizinhos, sensibilidade_distancia_manhattan, label='Distância de Manhattan', color='#2ca02c', linewidth=2)\n",
    "matplotlib.pyplot.plot(numero_k_vizinhos, sensibilidade_distancia_euclidiana, label='Distância Euclidiana', color='#ff7f0e', linewidth=2)\n",
    "matplotlib.pyplot.plot(numero_k_vizinhos, sensibilidade_distancia_chebyshev, label='Distância de Chebyshev', color='#87CEEB', linewidth=2)\n",
    "matplotlib.pyplot.legend(title=\"Distâncias:\", loc='upper left', bbox_to_anchor=(1, 0.5), facecolor='white', edgecolor='gray', labelcolor='black', fontsize=10, title_fontsize=10, handlelength=1)\n",
    "matplotlib.pyplot.grid(True)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Espaçamento, Cores e Limites Mínimo e Máximo:\n",
    "matplotlib.pyplot.xlabel('Número de Vizinhos (k)', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(numpy.arange(1, 26, 2), fontsize=14, color='black')\n",
    "matplotlib.pyplot.xlim(1, 25)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo e Ajustes:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.yticks(numpy.arange(0.0, 1.1, 0.20), fontsize=14, color='black')\n",
    "matplotlib.pyplot.ylim(0.00, 1.00)\n",
    "def format_func(valor, numero_tique):\n",
    "    return f'{valor:.2f}'\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for spine in ['left', 'bottom']:\n",
    "    eixos_atuais.spines[spine].set_color('black')\n",
    "    eixos_atuais.spines[spine].set_linewidth(2.5)\n",
    "eixos_atuais.spines['top'].set_color('none')\n",
    "eixos_atuais.spines['right'].set_color('none')\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d25ae",
   "metadata": {},
   "source": [
    "<H5>4.2.3 - Modelo de KNN - Estudo de Overfitting - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Métrica de Avaliação Sensibilidade:\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Configurações do Número de Vizinhos (k) - Valores Mínimo e Máximo e Incremento:\n",
    "k_vizinhos = [i for i in range(1, 26, 2)]\n",
    "\n",
    "#Armazenar as Sensibilidades dos Conjuntos de Treino e de Teste:\n",
    "treino_sensibilidades = []\n",
    "teste_sensibilidades = []\n",
    "\n",
    "#Definir o Modelo de KNN com a Métrica de Manhattan:\n",
    "modelo_knn = KNeighborsClassifier(metric='euclidean')\n",
    "\n",
    "#Calcular a Sensibilidade para cada Número de Vizinhos (k):\n",
    "for k in k_vizinhos:\n",
    "    \n",
    "    #Atualizar o Número de Vizinhos (k) no Modelo:\n",
    "    modelo_knn.set_params(n_neighbors=k)\n",
    "    \n",
    "    #Treinar o Modelo de KNN:\n",
    "    modelo_knn.fit(X_treino, Y_treino)\n",
    "    \n",
    "    #Calcular as Sensibilidades para os Conjuntos de Treino e de Teste:\n",
    "    treino_sensibilidades.append(recall_score(Y_treino, modelo_knn.predict(X_treino)))\n",
    "    teste_sensibilidades.append(recall_score(Y_teste, modelo_knn.predict(X_teste)))\n",
    "\n",
    "#Resultados - Sensibilidades dos Conjuntos de Treino e de Teste:\n",
    "for k, treino_sens, teste_sens in zip(k_vizinhos, treino_sensibilidades, teste_sensibilidades):\n",
    "    print(f\"k = {k}: Sensibilidade do Conjunto Treino = {treino_sens:.2f} ; Sensibilidade do Conjunto de Teste = {teste_sens:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796804d",
   "metadata": {},
   "source": [
    "<H5>4.2.4 - Modelo de KNN - Estudo de Overfitting para o Modelo de KNN (Distância Euclidiana) - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcee090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#Número de K Vizinhos (1 até 25, incremento = 2):\n",
    "numero_k_vizinhos = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25]\n",
    "\n",
    "#Sensibilidades do Conjunto de Treino:\n",
    "sensibilidades_conjunto_treino = [1.00, 1.00, 0.99, 0.98, 0.97, 0.97, 0.96, 0.95, 0.95, 0.94, 0.94, 0.93, 0.93]\n",
    "\n",
    "#Sensibilidades do Conjunto de Teste:\n",
    "sensibilidades_conjunto_teste = [0.63, 0.72, 0.76, 0.78, 0.79, 0.80, 0.81, 0.81, 0.81, 0.82, 0.82, 0.82, 0.82]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Legenda de Cores e Grelha:\n",
    "matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nEstudo de Overfitting para o Modelo de KNN (Distância Euclidiana)\\n', fontsize=14)\n",
    "matplotlib.pyplot.plot(numero_k_vizinhos, sensibilidades_conjunto_treino, label='Conjunto de Treino', color='#2ca02c')\n",
    "matplotlib.pyplot.plot(numero_k_vizinhos, sensibilidades_conjunto_teste, label='Conjunto de Teste', color='#ff7f0e')\n",
    "matplotlib.pyplot.legend(fontsize=14)\n",
    "matplotlib.pyplot.grid()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Valores e Limites Mínimo e Máximo:\n",
    "matplotlib.pyplot.xlabel('Número de k Vizinhos', fontsize=14)\n",
    "matplotlib.pyplot.xticks(numero_k_vizinhos, fontsize=14)\n",
    "matplotlib.pyplot.xlim(1, 25)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14)\n",
    "matplotlib.pyplot.yticks([round(i * 0.20, 2) for i in range(6)], fontsize=14)\n",
    "matplotlib.pyplot.gca().set_yticklabels([f\"{y:.2f}\" for y in matplotlib.pyplot.yticks()[0]], fontsize=14)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for lado in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[lado].set_color('black')\n",
    "    eixos_atuais.spines[lado].set_linewidth(2.5)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fae56",
   "metadata": {},
   "source": [
    "<H5>4.2.5 - Modelo de KNN - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "##A partir do SKLearn.Neighbors, Importar o Modelo de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação:\n",
    "def funcao_calcular_metricas(Y_verdadeiro, Y_previsto, Y_probabilidade):\n",
    "    exatidao = accuracy_score(Y_verdadeiro, Y_previsto)\n",
    "    sensibilidade = recall_score(Y_verdadeiro, Y_previsto)\n",
    "    precisao = precision_score(Y_verdadeiro, Y_previsto)\n",
    "    auc = roc_auc_score(Y_verdadeiro, Y_probabilidade[:, 1])\n",
    "    f1 = f1_score(Y_verdadeiro, Y_previsto)\n",
    "\n",
    "    print(f\"Exatidão: {exatidao:.2f}\")\n",
    "    print(f\"Sensibilidade: {sensibilidade:.2f}\")\n",
    "    print(f\"Precisão: {precisao:.2f}\")\n",
    "    print(f\"AUC: {auc:.2f}\")\n",
    "    print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Definir o Modelo de KNN (Número de K Vizinhos = 23, Distância Euclidiana):\n",
    "knn = KNeighborsClassifier(n_neighbors=23, metric='euclidean')\n",
    "\n",
    "#Treinar o Modelo de KNN no Conjunto de Treino:\n",
    "knn.fit(X_treino, Y_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Treino:\n",
    "Y_treino_previsto = knn.predict(X_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste:\n",
    "Y_teste_previsto = knn.predict(X_teste)\n",
    "\n",
    "#Obter as Probabilidades dos Conjuntos de Treino e de Teste para Calcular a Métrica de Avaliação AUC:\n",
    "Y_treino_probabilidade_auc = knn.predict_proba(X_treino)\n",
    "Y_teste_probabilidade_auc = knn.predict_proba(X_teste)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Treino:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Treino:\")\n",
    "funcao_calcular_metricas(Y_treino, Y_treino_previsto, Y_treino_probabilidade_auc)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Teste:\")\n",
    "funcao_calcular_metricas(Y_teste, Y_teste_previsto, Y_teste_probabilidade_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42f976",
   "metadata": {},
   "source": [
    "<H5>4.2.6 - Modelo de KNN - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ff99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Melhor Modelo de KNN - Conjunto de Treino vs Conjunto de Teste:\n",
    "melhor_modelo_KNN_treino_teste = ['Melhor Modelo de KNN - Conjunto de Treino', 'Melhor Modelo de KNN - Conjunto de Teste']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.85, 0.76]\n",
    "sensibilidade = [0.93, 0.82]\n",
    "precisao = [0.79, 0.47]\n",
    "auc = [0.94, 0.86]\n",
    "f1 = [0.86, 0.60]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título Geral, Espaçamento, Cor, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(12, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação do Melhor Modelo de KNN (k=23, Distância Euclidiana)', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Índice, Largura, Cores, Deslocamento e Valores:\n",
    "indice_barras = numpy.arange(len(melhor_modelo_KNN_treino_teste)) * 1.4\n",
    "largura_barras = 0.15\n",
    "cores_barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'), \"F1\": (f1, '#9467bd')}\n",
    "deslocamento_barras = 0\n",
    "for nome_metrica, (valores, cor) in cores_barras.items():\n",
    "    barras_atual = matplotlib.pyplot.bar(indice_barras + deslocamento_barras, valores, largura_barras, label=nome_metrica, color=cor)\n",
    "    for barra in barras_atual:\n",
    "        altura_y = barra.get_height()\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2, altura_y, f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=14)\n",
    "    deslocamento_barras += largura_barras\n",
    "\n",
    "#Configurações do Eixo X - Tamanho, Rotação, Posição e Cor:\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, melhor_modelo_KNN_treino_teste, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=14)\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276d3f4",
   "metadata": {},
   "source": [
    "<H5>4.2.7 - Modelo de KNN - Conjunto de Teste - Matriz de Confusão:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do SKLearn.Neighbors, Importar o Modelo de KNN:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Importar o Seaborn:\n",
    "import seaborn\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e variavel Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino = conjunto_treino.iloc[:, :-1]\n",
    "variavel_alvo_treino = conjunto_treino.iloc[:, -1]\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e variavel Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste = conjunto_teste.iloc[:, :-1]\n",
    "variavel_alvo_teste = conjunto_teste.iloc[:, -1]\n",
    "\n",
    "#Definir o Modelo de KNN (Número de Vizinhos (k) = 23 ; Distância Euclidiana):\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=23, metric='euclidean', p=2)\n",
    "\n",
    "#Treinar o Modelo de KNN no Conjunto de Treino:\n",
    "modelo_knn.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer as Previsões no Conjunto de Teste:\n",
    "variavel_alvo_prevista_teste = modelo_knn.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão:\n",
    "matriz_confusao = confusion_matrix(variavel_alvo_teste, variavel_alvo_prevista_teste)\n",
    "\n",
    "#Configurações do Gráfico da Matriz de Confusão - Tamanhos, Título Geral, Cores, Mapa de Calor, Escala de Cores, Fundo, Limites Mínimo e Máximo, Incremento e Valores:\n",
    "matplotlib.pyplot.figure(figsize=(8, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de KNN (k=23, Distância Euclidiana)\\n', color='black', fontsize=16)\n",
    "mapa_calor = seaborn.heatmap(matriz_confusao, annot=False, fmt='d', cmap='Greens', vmin=0, vmax=26000, xticklabels=numpy.unique(variavel_alvo_teste), yticklabels=numpy.unique(variavel_alvo_teste), cbar=True, linewidths=0.5)\n",
    "escala_cores = mapa_calor.collections[0].colorbar\n",
    "escala_cores.ax.yaxis.set_tick_params(color='black')\n",
    "valores = numpy.arange(0, 26000 + 2000, 2000)\n",
    "escala_cores.set_ticks(valores)\n",
    "escala_cores.ax.set_yticklabels([f\"{int(valor):,}\".replace(',', '.') for valor in valores], color='black')\n",
    "matplotlib.pyplot.gca().set_facecolor('#2ca02c')\n",
    "for linha in range(matriz_confusao.shape[0]):\n",
    "    for coluna in range(matriz_confusao.shape[1]):\n",
    "        matplotlib.pyplot.text(coluna + 0.5, linha + 0.5, f\"{matriz_confusao[linha, coluna]:,}\".replace(',', '.'), color='#ff7f0e', ha='center', va='center', fontsize=16)\n",
    "\n",
    "#Configurações do Eixo X - Título, Cores, Tamanhos, Espaçamento e Valores:\n",
    "matplotlib.pyplot.xlabel('Rótulo Previsto', color='black', fontsize=14, labelpad=10)\n",
    "matplotlib.pyplot.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Cores, Tamanhos, Valores e Rotação:\n",
    "matplotlib.pyplot.ylabel('Verdadeiro Rótulo', color='black', fontsize=14)\n",
    "matplotlib.pyplot.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13, rotation=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor:\n",
    "for spine in ['top', 'right', 'left', 'bottom']:\n",
    "    matplotlib.pyplot.gca().spines[spine].set_color('black')\n",
    "\n",
    "#Resultados - Matriz de Confusão:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a028c4",
   "metadata": {},
   "source": [
    "<H5>4.3 - Modelo de Árvores de Decisão:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4581c5",
   "metadata": {},
   "source": [
    "<H5>4.3.1 - Modelo de Árvores de Decisão - Métrica de Avaliação Sensibilidade em Função dos Critérios Entropia e Gini e da Profundidade Máxima - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30325be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Tree, Importar o Modelo de Árvores de Decisão:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Definir as Profundidades - Valores Mínimo e Máximo e Incremento:\n",
    "profundidades = range(2, 25, 2)\n",
    "\n",
    "#Função para Avaliar os Critérios Entropia e Gini para Diferentes Profundidades:\n",
    "def funcao_calcular_criterios_entropia_gini(dados_treino_X, dados_treino_Y, dados_teste_X, dados_teste_Y, profundidades):\n",
    "    criterios_entropia_gini = ['entropy', 'gini']\n",
    "    resultados = {criterio: [] for criterio in criterios_entropia_gini}\n",
    "    melhor_combinacao = {\"critério\": None, \"profundidade_maxima\": None, \"sensibilidade\": 0}\n",
    "\n",
    "    #Iterar sobre os Critérios:\n",
    "    for criterio in criterios_entropia_gini:\n",
    "        \n",
    "        #Iterar sobre as Profundidades Máximas:\n",
    "        for profundidade_maxima in profundidades:\n",
    "            \n",
    "            #Definir o Modelo de Árvores de Decisão:\n",
    "            arvores_de_decisao = DecisionTreeClassifier(max_depth=profundidade_maxima, criterion=criterio)\n",
    "\n",
    "            #Treinar o Modelo de Árvores de Decisão no Conjunto de Treino:\n",
    "            arvores_de_decisao.fit(dados_treino_X, dados_treino_Y)\n",
    "\n",
    "            #Criar Previsões e Calcular a Sensibilidade:\n",
    "            Y_previsoes = arvores_de_decisao.predict(dados_teste_X)\n",
    "            tp = sum((dados_teste_Y == 1) & (Y_previsoes == 1))\n",
    "            fn = sum((dados_teste_Y == 1) & (Y_previsoes == 0))\n",
    "            sensibilidade = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            resultados[criterio].append(sensibilidade)\n",
    "\n",
    "            #Atualizar a Melhor Combinação de Parâmetros, Critério e Profundidade Máxima, com base na Sensibilidade:\n",
    "            if sensibilidade > melhor_combinacao[\"sensibilidade\"]:\n",
    "                melhor_combinacao = {\"critério\": criterio, \"profundidade_maxima\": profundidade_maxima, \"sensibilidade\": sensibilidade}\n",
    "    \n",
    "    #Devolver a Melhor Combinação:\n",
    "    return resultados, melhor_combinacao\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo (Chuva_Amanha) para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo (Chuva_Amanha) para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Cálculo dos Critérios Entropia e Gini para os Conjuntos de Treino e de Teste:\n",
    "criterios_entropia_gini, melhor_combinacao = funcao_calcular_criterios_entropia_gini(X_treino, Y_treino, X_teste, Y_teste, profundidades)\n",
    "\n",
    "#Resultados - Critério ; Profundidade Máxima ; Sensibilidade:\n",
    "print(\"Resultados:\")\n",
    "print()\n",
    "nomenclatura = {'entropy': 'Entropia', 'gini': 'Gini'}\n",
    "for criterio, valores in criterios_entropia_gini.items():\n",
    "    for profundidade_maxima, sensibilidade in zip(profundidades, valores):\n",
    "        print(f\"Critério {nomenclatura[criterio]} ; Profundidade Máxima = {profundidade_maxima} ; Sensibilidade = {sensibilidade:.2f}\")\n",
    "\n",
    "#Resultados - Melhor Combinação de Parâmetros: Critério ; Profundidade Máxima ; Sensibilidade:\n",
    "melhor_criterio = nomenclatura[melhor_combinacao[\"critério\"]]\n",
    "print(f\"\\nMelhor Combinação de Parâmetros: Critério {melhor_criterio} ; Profundidade Máxima = {melhor_combinacao['profundidade_maxima']} ; Sensibilidade = {melhor_combinacao['sensibilidade']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf11cc",
   "metadata": {},
   "source": [
    "<H5>4.3.2 - Modelo de Árvores de Decisão - Métrica de Avaliação Sensibilidade em Função dos Critérios Entropia e Gini e da Profundidade Máxima - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Profundidade Máxima - Valores:\n",
    "profundidade_maxima = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "\n",
    "#Sensibilidades do Critério Entropia - Valores:\n",
    "sensibilidades_criterio_entropia = [0.77, 0.71, 0.68, 0.69, 0.68, 0.68, 0.66, 0.65, 0.63, 0.62, 0.60, 0.59]\n",
    "\n",
    "#Sensibilidades do Critério Gini - Valores:\n",
    "sensibilidades_criterio_gini = [0.65, 0.76, 0.67, 0.71, 0.67, 0.66, 0.64, 0.62, 0.62, 0.61, 0.60, 0.59]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Legenda de Cores e Grelha:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação da Sensibilidade para diferentes Parametrizações do Modelo de Árvores de Decisão\\n', fontsize=16)\n",
    "plt.plot(profundidade_maxima, sensibilidades_criterio_entropia, label='Critério Entropia', color='#2ca02c')\n",
    "plt.plot(profundidade_maxima, sensibilidades_criterio_gini, label='Critério Gini', color='#ff7f0e')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos e Limites:\n",
    "plt.xlabel('Profundidade Máxima', fontsize=14)\n",
    "plt.xticks(profundidade_maxima, fontsize=14)\n",
    "plt.xlim(min(profundidade_maxima), max(profundidade_maxima))\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Limites e Formatações:\n",
    "plt.ylabel('Sensibilidade', fontsize=14)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.yticks([i * 0.2 for i in range(6)], fontsize=14)\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Espessura:\n",
    "eixos_atuais = plt.gca()\n",
    "eixos_atuais.spines['bottom'].set_linewidth(2.5)\n",
    "eixos_atuais.spines['left'].set_linewidth(2.5)\n",
    "eixos_atuais.spines['top'].set_visible(False)\n",
    "eixos_atuais.spines['right'].set_visible(False)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c9f5d",
   "metadata": {},
   "source": [
    "<H5>4.3.3 - Modelo de Árvores de Decisão - Estudo de Overfitting - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Tree, Importar o Modelo de Árvores de Decisão:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Métrica de Avaliação Sensibilidade:\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Configurações das Profundidades - Valores Mínimo e Máximo:\n",
    "profundidades = range(2, 26)\n",
    "\n",
    "#Iterar sobre as Profundidades Máximas:\n",
    "for profundidade_maxima in profundidades:\n",
    "\n",
    "    #Definir o Modelo de Árvores de Decisão com a Profundidade Máxima Específica:\n",
    "    modelo_arvores_decisao = DecisionTreeClassifier(max_depth=profundidade_maxima)\n",
    "    \n",
    "    #Treinar o Modelo de Árvores de Decisão no Conjunto de Treino:\n",
    "    modelo_arvores_decisao.fit(X_treino, Y_treino)\n",
    "    \n",
    "    #Calcular as Sensibilidades para os Conjuntos de Treino e de Teste:\n",
    "    treino_sensibilidades = recall_score(Y_treino, modelo_arvores_decisao.predict(X_treino))\n",
    "    teste_sensibilidades = recall_score(Y_teste, modelo_arvores_decisao.predict(X_teste))\n",
    "    \n",
    "    #Resultados - Profundidade Máxima ; Sensibilidade do Conjunto de Treino ; Sensibilidade do Conjunto de Teste:\n",
    "    print(f\"Profundidade Máxima = {profundidade_maxima}: Sensibilidade do Conjunto Treino = {treino_sensibilidades:.2f} ; Sensibilidade do Conjunto de Teste = {teste_sensibilidades:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a72da",
   "metadata": {},
   "source": [
    "<H5>4.3.4 - Modelo de Árvores de Decisão - Estudo de Overfitting - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ab5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#Profundidade Máxima - Valores:\n",
    "profundidade_maxima = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "#Sensibilidades do Conjunto de Treino - Valores:\n",
    "sensibilidades_treino = [0.67, 0.61, 0.83, 0.74, 0.75, 0.79, 0.81, 0.81, 0.82, 0.84, 0.86, 0.87, 0.89, 0.91, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 0.99, 0.99]\n",
    "\n",
    "#Sensibilidades do Conjunto de Teste - Valores:\n",
    "sensibilidades_teste = [0.65, 0.54, 0.76, 0.68, 0.67, 0.70, 0.71, 0.68, 0.67, 0.68, 0.66, 0.64, 0.64, 0.64, 0.63, 0.62, 0.62, 0.61, 0.61, 0.60, 0.59, 0.59, 0.59, 0.58]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Legenda de Cores e Grelha:\n",
    "matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nEstudo de Overfitting para o Modelo de Árvores de Decisão (Critério Entropia)\\n', fontsize=16)\n",
    "matplotlib.pyplot.plot(profundidade_maxima, sensibilidades_treino, label='Conjunto de Treino', color='#2ca02c')\n",
    "matplotlib.pyplot.plot(profundidade_maxima, sensibilidades_teste, label='Conjunto de Teste', color='#ff7f0e')\n",
    "matplotlib.pyplot.legend(fontsize=12)\n",
    "matplotlib.pyplot.grid()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos e Limites Mínimo e Máximo:\n",
    "matplotlib.pyplot.xlabel('Profundidade Máxima', fontsize=14)\n",
    "matplotlib.pyplot.xticks(profundidade_maxima, fontsize=14)\n",
    "matplotlib.pyplot.xlim(2, 25)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Incremento e Ajustes:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14)\n",
    "matplotlib.pyplot.yticks([round(i * 0.20, 2) for i in range(6)], fontsize=14)\n",
    "matplotlib.pyplot.gca().set_yticklabels([f\"{y:.2f}\" for y in matplotlib.pyplot.yticks()[0]], fontsize=14)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for lado in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[lado].set_color('black')\n",
    "    eixos_atuais.spines[lado].set_linewidth(2.5)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c150696",
   "metadata": {},
   "source": [
    "<H5>4.3.5 - Modelo de Árvores de Decisão - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1be34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.DecisionTree, Importar o Modelo de Árvores de Decisão:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação:\n",
    "def funcao_calcular_metricas(Y_verdadeiro, Y_previsto, Y_probabilidade):\n",
    "    exatidao = accuracy_score(Y_verdadeiro, Y_previsto)\n",
    "    sensibilidade = recall_score(Y_verdadeiro, Y_previsto)\n",
    "    precisao = precision_score(Y_verdadeiro, Y_previsto)\n",
    "    auc = roc_auc_score(Y_verdadeiro, Y_probabilidade[:, 1])\n",
    "    f1 = f1_score(Y_verdadeiro, Y_previsto)\n",
    "    \n",
    "    print(f\"Exatidão: {exatidao:.2f}\")\n",
    "    print(f\"Sensibilidade: {sensibilidade:.2f}\")\n",
    "    print(f\"Precisão: {precisao:.2f}\")\n",
    "    print(f\"AUC: {auc:.2f}\")\n",
    "    print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Independentes e Variável Alvo para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Definir o Modelo de Árvores de Decisão (Critério Entropia, Profundidade Máxima = 4):\n",
    "arvores_decisao = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "\n",
    "#Treinar o Modelo de Árvores de Decisão no Conjunto de Treino:\n",
    "arvores_decisao.fit(X_treino, Y_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Treino:\n",
    "Y_treino_previsto = arvores_decisao.predict(X_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste:\n",
    "Y_teste_previsto = arvores_decisao.predict(X_teste)\n",
    "\n",
    "#Obter as Probabilidades dos Conjuntos de Treino e de Teste para Calcular a Métrica de Avaliação AUC:\n",
    "Y_treino_probabilidade_auc = arvores_decisao.predict_proba(X_treino)\n",
    "Y_teste_probabilidade_auc = arvores_decisao.predict_proba(X_teste)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Treino:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Treino:\")\n",
    "funcao_calcular_metricas(Y_treino, Y_treino_previsto, Y_treino_probabilidade_auc)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Teste:\")\n",
    "funcao_calcular_metricas(Y_teste, Y_teste_previsto, Y_teste_probabilidade_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3c472",
   "metadata": {},
   "source": [
    "<H5>4.3.6 - Modelo de Árvores de Decisão - Conjunto de Treino vs Conjunto de Teste - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d781b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Melhor Modelo de Árvores de Decisão - Conjunto de Treino vs Conjunto de Teste:\n",
    "melhor_modelo_arvores_decisao_treino_teste = ['Melhor Modelo de Árvores de Decisão - Conjunto de Treino', 'Melhor Modelo de Árvores de Decisão - Conjunto de Teste']\n",
    "\n",
    "#5 Métricas de Avaliação - Resultados:\n",
    "exatidao = [0.75, 0.72]\n",
    "sensibilidade = [0.78, 0.71]\n",
    "precisao = [0.74, 0.42]\n",
    "auc = [0.84, 0.80]\n",
    "f1 = [0.76, 0.53]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título Geral, Espaçamento, Cor, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(12, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação do Melhor Modelo de Árvores de Decisão\\n\\n(Critério Entropia, Profundidade Máxima = 4)', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Índice, Largura, Cores, Deslocamento e Valores:\n",
    "indice_barras = numpy.arange(len(melhor_modelo_arvores_decisao_treino_teste)) * 1.4\n",
    "largura_barras = 0.15\n",
    "cores_barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'), \"F1\": (f1, '#9467bd')}\n",
    "deslocamento_barras = 0\n",
    "for nome_metrica, (valores, cor) in cores_barras.items():\n",
    "    barras_atual = matplotlib.pyplot.bar(indice_barras + deslocamento_barras, valores, largura_barras, label=nome_metrica, color=cor)\n",
    "    for barra in barras_atual:\n",
    "        altura_y = barra.get_height()\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2, altura_y, f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=14)\n",
    "    deslocamento_barras += largura_barras\n",
    "\n",
    "#Configurações do Eixo X - Tamanho, Rotação, Posição e Cor:\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, melhor_modelo_arvores_decisao_treino_teste, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=14)\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd81a97",
   "metadata": {},
   "source": [
    "<H5>4.3.7 - Modelo de Árvores de Decisão - Conjunto de Teste - Matriz de Confusão:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a73149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do SKLearn.Tree, Importar o Modelo de Árvores de Decisão:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Importar o Seaborn:\n",
    "import seaborn\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Treino:\n",
    "def funcao_dividir_dados(conjunto):\n",
    "    variaveis_preditoras = conjunto.iloc[:, :-1]\n",
    "    variavel_alvo = conjunto.iloc[:, -1]\n",
    "    return variaveis_preditoras, variavel_alvo\n",
    "variaveis_preditoras_treino, variavel_alvo_treino = funcao_dividir_dados(conjunto_treino)\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste, variavel_alvo_teste = funcao_dividir_dados(conjunto_teste)\n",
    "\n",
    "#Definir o Modelo de Árvores de Decisão (Critério = Entropia, Profundidade Máxima = 4):\n",
    "modelo_arvores_decisao = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "\n",
    "#Treinar o Modelo de Árvores de Decisão no Conjunto de Treino:\n",
    "modelo_arvores_decisao.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer as Previsões no Conjunto de Teste:\n",
    "variavel_alvo_prevista_teste = modelo_arvores_decisao.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão:\n",
    "matriz_confusao = confusion_matrix(variavel_alvo_teste, variavel_alvo_prevista_teste)\n",
    "\n",
    "#Configurações da Matriz de Confusão - Tamanhos, Título Geral, Cores, Escala de Cores, Valores, Limites Mínimo e Máximo, Incremento e Ajustes:\n",
    "def configurar_grafico(matriz_confusao):\n",
    "    matplotlib.pyplot.figure(figsize=(8, 6))\n",
    "    matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de Árvores de Decisão\\n\\n(Critério Entropia, Profundidade Máxima = 4)\\n', color='black', fontsize=16)\n",
    "    mapa_calor = seaborn.heatmap(matriz_confusao, annot=False, fmt='d', cmap='Greens', vmin=0, vmax=26000, xticklabels=numpy.unique(variavel_alvo_teste), yticklabels=numpy.unique(variavel_alvo_teste), cbar=True, linewidths=0.5)\n",
    "    escala_cores = mapa_calor.collections[0].colorbar\n",
    "    escala_cores.ax.yaxis.set_tick_params(color='black')\n",
    "    valores = numpy.arange(0, 26000 + 2000, 2000)\n",
    "    escala_cores.set_ticks(valores)\n",
    "    escala_cores.ax.set_yticklabels([f\"{int(valor):,}\".replace(',', '.') for valor in valores], color='black')\n",
    "    matplotlib.pyplot.gca().set_facecolor('#2ca02c')\n",
    "    for linha in range(matriz_confusao.shape[0]):\n",
    "        for coluna in range(matriz_confusao.shape[1]):\n",
    "            matplotlib.pyplot.text(coluna + 0.5, linha + 0.5, f\"{matriz_confusao[linha, coluna]:,}\".replace(',', '.'), color='#ff7f0e', ha='center', va='center', fontsize=16)\n",
    "\n",
    "    #Configurações do Eixo X - Título, Cores, Tamanhos e Valores:\n",
    "    matplotlib.pyplot.xlabel('Rótulo Previsto', color='black', fontsize=14, labelpad=10)\n",
    "    matplotlib.pyplot.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=14)\n",
    "\n",
    "    #Configurações do Eixo Y - Título, Cores, Tamanhos, Valores e Rotação:\n",
    "    matplotlib.pyplot.ylabel('Verdadeiro Rótulo', color='black', fontsize=14)\n",
    "    matplotlib.pyplot.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=14, rotation=0)\n",
    "\n",
    "    #Configurações das Margens dos Eixos - Cor:\n",
    "    for spine in ['top', 'right', 'left', 'bottom']:\n",
    "        matplotlib.pyplot.gca().spines[spine].set_color('black')\n",
    "\n",
    "#Resultados - Matriz de Confusão:\n",
    "configurar_grafico(matriz_confusao)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63426fe4",
   "metadata": {},
   "source": [
    "<H5>4.3.8 - Modelo de Árvores de Decisão - Melhor Árvore de Decisão:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#Importar o Shutil:\n",
    "import shutil\n",
    "\n",
    "#Importar o OS:\n",
    "import os\n",
    "\n",
    "#A partir do Matplotlib.Pyplot, Importar Funções Ler e Exibir Imagem, Mostrar, Eixos e Figura:\n",
    "from matplotlib.pyplot import imread, imshow, show, axis, figure\n",
    "\n",
    "#A partir do SKLearn.Tree, Importar Modelo de Árvores de Decisão e Função Exportação de Árvores de Decisão:\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "#A partir do Subprocess, Importar Função Executar Comandos Externos:\n",
    "from subprocess import call\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as 5 Métricas de Avaliação, Melhoria Delta e Função Ler Ficheiros de Treino e de Teste:\n",
    "from dslabs_functions import CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = 'conjunto_treino_balanceado_sobreamostragem_SMOTE.csv'\n",
    "conjunto_teste = 'conjunto_teste_normalizado_z-score.csv'\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Ler e Atribuir as Características e Rótulos dos Dados de Treino e Teste:\n",
    "caracteristicas_treino, caracteristicas_teste, variavel_alvo_treino, variavel_alvo_teste, rotulos, lista_variaveis = read_train_test_from_files(\n",
    "    conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Rótulo do Ficheiro para Guardar a Melhor Árvore de Decisão:\n",
    "rotulo_ficheiro_melhor_arvore_decisao = variavel_alvo\n",
    "\n",
    "#Definir a Métrica de Avaliação (Sensibilidade):\n",
    "metrica_avaliacao = 'recall'\n",
    "\n",
    "#Definir o Nome do Ficheiro para Guardar a Melhor Árvore de Decisão:\n",
    "ficheiro_melhor_arvore_decisao = f\"imagens/{rotulo_ficheiro_melhor_arvore_decisao}_árvore_decisão_melhor_{metrica_avaliacao}\"\n",
    "\n",
    "#Criar o Diretório \"Imagens\":\n",
    "os.makedirs(\"imagens\", exist_ok=True)\n",
    "\n",
    "#Definir a Profundidade Máxima:\n",
    "profundidade_maxima = 3\n",
    "\n",
    "#Converter os Rótulos em Texto:\n",
    "rotulos_texto: list[str] = [str(valor) for valor in rotulos]\n",
    "\n",
    "#Adicionar o Prefixo Variável aos Nomes das Variáveis:\n",
    "variaveis = [f\"Variável {variavel}\" for variavel in lista_variaveis]\n",
    "\n",
    "#Iniciar o Modelo de Árvores de Decisão:\n",
    "modelo_arvore_decisao = DecisionTreeClassifier(max_depth=profundidade_maxima)\n",
    "\n",
    "#Treinar o Modelo de Árvores de Decisão no Conjunto de Treino:\n",
    "modelo_arvore_decisao.fit(caracteristicas_treino, variavel_alvo_treino)\n",
    "\n",
    "#Exportar a Árvore de Decisão para o Formato DOT:\n",
    "representacao_grafo: str = export_graphviz(\n",
    "    \n",
    "    #Modelo de Árvores de Decisão a ser Exportado:\n",
    "    modelo_arvore_decisao,\n",
    "    \n",
    "    #Definir o Nome do Ficheiro de Saída com Extensão:\n",
    "    out_file=ficheiro_melhor_arvore_decisao + \".dot\",\n",
    "    \n",
    "    #Limitar a Profundidade Máxima da Árvore de Decisão:\n",
    "    max_depth=profundidade_maxima,\n",
    "    \n",
    "    #Definir os Nomes das Variáveis como Rótulos nos Nós:\n",
    "    feature_names=variaveis,\n",
    "    \n",
    "    #Definir os Rótulos das Classes como Nomes Legíveis:\n",
    "    class_names=rotulos_texto,\n",
    "    \n",
    "    #Preencher os Nós com Cores:\n",
    "    filled=True,\n",
    "    \n",
    "    #Arredondar os Cantos dos Nós:\n",
    "    rounded=True,\n",
    "\n",
    "    #Remover a Exibição dos Valores de Impureza:\n",
    "    impurity=False,\n",
    "\n",
    "    #Permitir Carateres Especiais nos Rótulos:\n",
    "    special_characters=True,\n",
    "\n",
    "    #Definir a Precisao dos Números:\n",
    "    precision=2)\n",
    "\n",
    "#Abrir o Ficheiro DOT para Leitura:\n",
    "with open(ficheiro_melhor_arvore_decisao + \".dot\", \"r\") as ficheiro:\n",
    "\n",
    "    #Ler o Ficheiro DOT:\n",
    "    representacao_dot = ficheiro.read()\n",
    "\n",
    "#Ajustar os Nomes e Valores do Ficheiro DOT:\n",
    "representacao_dot = (representacao_dot.replace(\"True\", \"Verdadeiro\").replace(\"False\", \"Falso\").replace(\"samples\", \"Amostras\").replace(\"value\", \"Valor\")\n",
    "                     .replace(\"class\", \"Classe\").replace(\"0.0\", \"0\").replace(\"1.0\", \"1\"))\n",
    "\n",
    "#Abrir o Ficheiro DOT para Gravação:\n",
    "with open(ficheiro_melhor_arvore_decisao + \".dot\", \"w\") as ficheiro:\n",
    "\n",
    "    #Gravar a Representação Ajustada no Ficheiro DOT:\n",
    "    ficheiro.write(representacao_dot)\n",
    "\n",
    "#Verificar se o Programa DOT está Disponível no Sistema:\n",
    "if shutil.which(\"dot\") is not None:\n",
    "\n",
    "    #Criar Imagem PNG a partir do Ficheiro DOT:\n",
    "    call([\"dot\", \"-Tpng\", ficheiro_melhor_arvore_decisao + \".dot\", \"-o\", ficheiro_melhor_arvore_decisao + \".png\", \"-Gdpi=600\"])\n",
    "\n",
    "#Senão:\n",
    "else:\n",
    "    \n",
    "    #O Programa DOT Não Está Disponível no Sistema.\n",
    "    print(\"O Programa DOT Não Está Disponível no Sistema.\")\n",
    "\n",
    "#Configurações da Figura - Tamanho:\n",
    "figure(figsize=(16, 12))\n",
    "\n",
    "#Ler a Imagem PNG da Melhor Árvore de Decisão e Exibi-la na Figura:\n",
    "imshow(imread(ficheiro_melhor_arvore_decisao + \".png\"))\n",
    "\n",
    "#Remover os Eixos:\n",
    "axis(\"off\")\n",
    "\n",
    "#Definições da Figura - Título - Designação, Tamanho e Cor:\n",
    "matplotlib.pyplot.title(\"Conjunto de Dados 1 - Melhor Árvore de Decisão (Profundidade Máxima = 3)\\n\", fontsize=12, color='black')\n",
    "\n",
    "#Resultados - Melhor Árvore de Decisão:\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528311d3",
   "metadata": {},
   "source": [
    "<H5><H5>4.4 - Modelo de Florestas Aleatórias:</H5></H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab9493",
   "metadata": {},
   "source": [
    "<H5><H5>4.4.1 - Modelo de Florestas Aleatórias - Métrica de Avaliação Sensibilidade em Função dos Parâmetros Profundidade Máxima, Número Máximo de Características e Número de Estimadores - Resultados:</H5></H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir da Biblioteca Numerical Python, Importar as Estruturas de Dados:\n",
    "from numpy import array, ndarray\n",
    "\n",
    "#A partir de SKLearn.Ensemble, Importar o Modelo de Florestas Aleatórias:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as Métricas de Avaliação, Delta de Melhoria e Função de Leitura dos Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import (CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files)\n",
    "\n",
    "#Função de Estudo do Modelo de Florestas Aleatórias com Diferentes Parâmetros:\n",
    "def funcao_estudo_florestas_aleatorias(X_treino: ndarray, Y_treino: array, X_teste: ndarray, Y_teste: array,\n",
    "                                       numeros_estimadores: list[int], metrica: str = \"recall\") -> tuple[RandomForestClassifier | None, dict, pandas.DataFrame]:\n",
    "    \n",
    "    #Definir as Profundidades Máximas das Árvores:\n",
    "    profundidades_maximas_arvores: list[int] = [2, 5, 7]\n",
    "\n",
    "    #Definir os Números Máximos de Características:\n",
    "    numeros_maximos_caracteristicas: list[float] = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "    #Variável para Guardar o Melhor Modelo de Florestas Aleatórias:\n",
    "    melhor_modelo_florestas_aleatorias: RandomForestClassifier | None = None\n",
    "\n",
    "    #Dicionário para Armazenar os Melhores Parâmetros:\n",
    "    melhores_parametros: dict = {\"nome\": \"RandomForest\", \"metrica\": metrica, \"parametros\": ()}\n",
    "\n",
    "    #Variável para Armazenar o Melhor Desempenho:\n",
    "    melhor_desempenho: float = 0.0\n",
    "\n",
    "    #Criar uma Lista para Armazenar os Resultados de Todas as Configurações:\n",
    "    resultados: list[dict] = []\n",
    "\n",
    "    #Iterar sobre as Profundidades Máximas das Árvores:\n",
    "    for profundidade_maxima_arvores in profundidades_maximas_arvores:\n",
    "        \n",
    "        #Iterar sobre os Números Máximos de Características:\n",
    "        for numero_maximo_caracteristicas in numeros_maximos_caracteristicas:\n",
    "            \n",
    "            #Iterar sobre os Números de Estimadores:\n",
    "            for numero_estimadores in numeros_estimadores:\n",
    "                \n",
    "                #Criar e Configurar o Modelo de Florestas Aleatórias:\n",
    "                modelo_florestas_aleatorias = RandomForestClassifier(max_depth=profundidade_maxima_arvores, max_features=numero_maximo_caracteristicas,\n",
    "                    n_estimators=numero_estimadores)\n",
    "                \n",
    "                #Treinar o Modelo no Conjunto de Treino:\n",
    "                modelo_florestas_aleatorias.fit(X_treino, Y_treino)\n",
    "\n",
    "                #Prever os Resultados no Conjunto de Teste:\n",
    "                previsoes_teste: array = modelo_florestas_aleatorias.predict(X_teste)\n",
    "\n",
    "                #Calcular a Métrica de Avaliação:\n",
    "                avaliacao: float = round(CLASS_EVAL_METRICS[metrica](Y_teste, previsoes_teste), 2)\n",
    "\n",
    "                #Armazenar os Resultados da Configuração:\n",
    "                resultados.append({'Profundidade Máxima': profundidade_maxima_arvores, 'Número Máximo de Características': numero_maximo_caracteristicas,\n",
    "                    'Número de Estimadores': numero_estimadores, 'Sensibilidade': avaliacao})\n",
    "                \n",
    "                #Se o Desempenho for Superior ao Anterior:\n",
    "                if avaliacao - melhor_desempenho > DELTA_IMPROVE:\n",
    "                    \n",
    "                    #Atualizar o Melhor Desempenho:\n",
    "                    melhor_desempenho = avaliacao\n",
    "\n",
    "                    #Guardar os Melhores Parâmetros:\n",
    "                    melhores_parametros[\"parametros\"] = (profundidade_maxima_arvores, numero_maximo_caracteristicas, numero_estimadores)\n",
    "\n",
    "                    #Guardar o Melhor Modelo de Florestas Aleatórias:\n",
    "                    melhor_modelo_florestas_aleatorias = modelo_florestas_aleatorias\n",
    "\n",
    "    #Criar um DataFrame com os Resultados:\n",
    "    resultados_dataframe = pandas.DataFrame(resultados)\n",
    "\n",
    "    #Mostrar os Resultados numa única linha:\n",
    "    print(\"Resultados:\\n\")\n",
    "    print(resultados_dataframe.to_string(index=False))\n",
    "\n",
    "    #Mostrar o Melhor Modelo de Florestas Aleatórias:\n",
    "    print(f'\\nMelhor Modelo de Florestas Aleatórias: Profundidade Máxima = {melhores_parametros[\"parametros\"][0]}, '\n",
    "          f'Número Máximo de Características = {melhores_parametros[\"parametros\"][1]}, 'f'Número de Estimadores = {melhores_parametros[\"parametros\"][2]}')\n",
    "\n",
    "    #Devolver o Melhor Modelo, os Melhores Parâmetros e o DataFrame de Resultados:\n",
    "    return melhor_modelo_florestas_aleatorias, melhores_parametros, resultados_dataframe\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = \"conjunto_treino_balanceado_sobreamostragem_SMOTE.csv\"\n",
    "conjunto_teste = \"conjunto_teste_normalizado_z-score.csv\"\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "X_treino, X_teste, Y_treino, Y_teste, rotulos, variaveis = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Definir a Métrica de Avaliação (Sensibilidade):\n",
    "metrica_avaliacao = \"recall\"\n",
    "\n",
    "#Definir os Números de Estimadores:\n",
    "numeros_estimadores = [100, 250, 500, 750, 1000]\n",
    "\n",
    "#Executar a Função de Estudo do Modelo de Florestas Aleatórias:\n",
    "melhor_modelo_florestas_aleatorias, parametros, resultados = funcao_estudo_florestas_aleatorias(X_treino, Y_treino, X_teste, Y_teste, numeros_estimadores=numeros_estimadores,\n",
    "    metrica=metrica_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842aef6",
   "metadata": {},
   "source": [
    "<H5><H5>4.4.2 - Modelo de Florestas Aleatórias - Métrica de Avaliação Sensibilidade em Função dos Parâmetros Profundidade Máxima, Número Máximo de Características e Número de Estimadores - Gráfico de Linhas:</H5></H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15179407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#A partir do Matplotlib.Pyplot, Importar as Funções de Subgráficos e Exibição:\n",
    "from matplotlib.pyplot import subplots, show\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar a Altura:\n",
    "from dslabs_functions import HEIGHT\n",
    "\n",
    "#Definir os Dados com os Valores obtidos para os Hiperparâmetros e com os Valores obtidos para a Métrica de Avaliação Sensibilidade:\n",
    "dados = {\n",
    "    \n",
    "    #Profundidade Máxima:\n",
    "    'profundidade_maxima': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "                            7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
    "\n",
    "    #Número Máximo de Características:\n",
    "    'número_máximo_características': [0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9,\n",
    "                                      0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9,\n",
    "                                      0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9],\n",
    "\n",
    "    #Número de Estimadores:\n",
    "    'número_estimadores': [100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000,\n",
    "                           100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000,\n",
    "                           100, 500, 750, 1000, 100, 500, 750, 1000],\n",
    "    \n",
    "    #Métrica de Avaliação Sensibilidade:\n",
    "    'sensibilidade': [0.71, 0.71, 0.71, 0.70, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.68, 0.71, 0.69, 0.71, 0.67, 0.68, 0.67, 0.67, 0.72, 0.72, 0.72, 0.72, 0.70, 0.71,\n",
    "                      0.71, 0.71, 0.71, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.71, 0.71, 0.71, 0.71, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.70, 0.71, 0.70, 0.70,\n",
    "                      0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70]}\n",
    "\n",
    "#Criar um DataFrame com os Resultados:\n",
    "resultados_dataframe = pd.DataFrame(dados)\n",
    "\n",
    "#Obter os Valores Únicos das Profundidades Máximas:\n",
    "profundidades_maximas = resultados_dataframe['profundidade_maxima'].unique()\n",
    "\n",
    "#Definir o Número de Colunas do Subgráfico:\n",
    "colunas: int = len(profundidades_maximas)\n",
    "\n",
    "#Criar os Subgráficos:\n",
    "_, eixos = subplots(1, colunas, figsize=(colunas * HEIGHT, HEIGHT), squeeze=False)\n",
    "\n",
    "#Definir as Cores para cada Número Máximo de Características:\n",
    "cores_numero_maximo_caracteristicas = {0.1: '#ff7f0e', 0.3: '#ffdd57', 0.5: '#2ca02c', 0.7: '#87CEEB', 0.9: '#9467bd'}\n",
    "\n",
    "#Iterar pelos Índices e Profundidades Máximas:\n",
    "for indice, profundidade_maxima in enumerate(profundidades_maximas):\n",
    "    \n",
    "    #Filtrar os Resultados por Profundidade Máxima:\n",
    "    resultados_filtrados = resultados_dataframe[resultados_dataframe['profundidade_maxima'] == profundidade_maxima]\n",
    "    \n",
    "    #Criar um Dicionário Vazio para Armazenar os Valores de Sensibilidade por Número Máximo de Características:\n",
    "    valores_sensibilidade_numero_maximo_caracteristicas = {}\n",
    "    \n",
    "    #Iterar por cada Valor Único do Número Máximo de Características:\n",
    "    for valor in resultados_filtrados['número_máximo_características'].unique():\n",
    "        \n",
    "        #Associar a cada Valor a Sensibilidade Correspondente:\n",
    "        valores_sensibilidade_numero_maximo_caracteristicas[valor] = resultados_filtrados[resultados_filtrados['número_máximo_características'] == valor]['sensibilidade'].tolist()\n",
    "    \n",
    "    #Selecionar o Eixo correspondente à Coluna Atual:\n",
    "    eixo = eixos[0, indice]\n",
    "    \n",
    "    #Iterar sobre os Valores do Número Máximo de Características Disponíveis no Dicionário:\n",
    "    for valor in valores_sensibilidade_numero_maximo_caracteristicas.keys():\n",
    "        \n",
    "        #Criar uma Linha no Gráfico para cada Característica:\n",
    "        eixo.plot(resultados_filtrados['número_estimadores'].unique(), valores_sensibilidade_numero_maximo_caracteristicas[valor],color=cores_numero_maximo_caracteristicas[valor],\n",
    "                  label=f'{valor}')\n",
    "    \n",
    "    #Configurações do Gráfico - Título Individual - Designação, Tamanho e Cor:\n",
    "    eixo.set_title(f\"Profundidade Máxima = {profundidade_maxima}\\n\", fontsize=12, color='black')\n",
    "    \n",
    "    #Configurações do Eixo X - Título, Tamanho, Cores, Valores, Rotação e Limite Máximo:\n",
    "    eixo.set_xlabel(\"Número de Estimadores\", fontsize=12, color='black')\n",
    "    eixo.set_xticks([100, 250, 500, 750, 1000])\n",
    "    for etiqueta in eixo.get_xticklabels():\n",
    "        etiqueta.set_color('black')\n",
    "        etiqueta.set_rotation(0)\n",
    "    eixo.set_xlim(left=100)\n",
    "    \n",
    "    #Configurações do Eixo Y - Título, Tamanho, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "    eixo.set_ylabel(\"Sensibilidade\", fontsize=12, color='black')\n",
    "    for etiqueta in eixo.get_yticklabels():\n",
    "        etiqueta.set_color('black')\n",
    "    eixo.set_yticks(np.arange(0.0, 1.1, 0.2))\n",
    "    eixo.set_ylim(0.0, 1.0)\n",
    "    eixo.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "    \n",
    "    #Configurações Margens dos Eixos - Cor:\n",
    "    eixo.tick_params(axis='both', labelsize=8)\n",
    "    eixo.spines['left'].set_color('black')\n",
    "    eixo.spines['bottom'].set_color('black')\n",
    "    eixo.spines['top'].set_visible(False)\n",
    "    eixo.spines['right'].set_visible(False)\n",
    "    \n",
    "    #Configurações da Grelha - Eixo, Cor, Estilo e Espessura de Linha:\n",
    "    eixo.grid(axis='y', color='gray', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    #Obter os Objetos e Rótulos da Legenda:\n",
    "    handles, labels = eixo.get_legend_handles_labels()\n",
    "    \n",
    "    #Criar um Dicionário para Remover Duplicados:\n",
    "    rótulos_únicos = dict(zip(labels, handles))\n",
    "    \n",
    "    #Configurações da Legenda - Designação, Tamanhos, Posição, Cores e Espessura de Linha:\n",
    "    legenda = eixo.legend(rótulos_únicos.values(), rótulos_únicos.keys(), title=\"Número Máximo de Características:\", fontsize=8, loc='lower right', title_fontsize='small',\n",
    "                          frameon=True)\n",
    "    if legenda is not None:\n",
    "        legenda.get_title().set_color('black')\n",
    "        for texto in legenda.get_texts():\n",
    "            texto.set_color('black')\n",
    "        moldura = legenda.get_frame()\n",
    "        moldura.set_edgecolor('gray')\n",
    "        moldura.set_linewidth(1.0)\n",
    "        moldura.set_facecolor('none')\n",
    "\n",
    "#Configuração do Gráfico -  Título Geral - Designação, Tamanho, Fonte e Cor:\n",
    "plt.suptitle(\"Conjunto de Dados 1 - Conjunto de Teste\\n\\nAnálise da Sensibilidade para diferentes Parametrizações do Modelo de Florestas Aleatórias\", fontsize=13,\n",
    "             fontweight='normal', color='black')\n",
    "\n",
    "#Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Linhas:\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251736c",
   "metadata": {},
   "source": [
    "<H5>4.4.3 - Modelo de Florestas Aleatórias - Estudo de Overfitting - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9789da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir da Biblioteca Numerical Python, Importar Array:\n",
    "from numpy import array\n",
    "\n",
    "#A partir do Scikit-Learn.Ensemble, Importar o Modelo Classificador de Florestas Aleatórias:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as Funções Métricas de Avaliação de Classificação e Ler Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import CLASS_EVAL_METRICS, read_train_test_from_files\n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Florestas Aleatórias:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir o Número Máximo de Características do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_maximo_caracteristicas = 0.3\n",
    "\n",
    "#Definir a Métrica de Avaliação a Utilizar (Sensibilidade/Recall):\n",
    "metrica_avaliacao = \"recall\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = \"conjunto_treino_balanceado_sobreamostragem_SMOTE.csv\"\n",
    "conjunto_teste = \"conjunto_teste_normalizado_z-score.csv\"\n",
    "\n",
    "#Definir a Variável Alvo:\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Carregar os Conjuntos de Treino e de Teste:\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Exibir o Número de Instâncias dos Conjuntos de Treino e de Teste:\n",
    "print(f\"Conjunto de Treino: {len(trnX)} ; Conjunto de Teste: {len(tstX)}\")\n",
    "\n",
    "#Iniciar a Lista para Guardar os Valores da Métrica Sensibilidade no Conjunto de Treino:\n",
    "valores_sensibilidade_treino: list[float] = []\n",
    "\n",
    "#Iniciar a Lista para Guardar os Valores da Métrica Sensibilidade no Conjunto de Teste:\n",
    "valores_sensibilidade_teste: list[float] = []\n",
    "\n",
    "#Criar a Lista de Número de Estimadores a Testar:\n",
    "lista_numero_estimadores = [2, 252, 502, 752, 1002]\n",
    "\n",
    "#Iterar sobre cada Número de Estimadores Definido:\n",
    "for numero_estimadores in lista_numero_estimadores:\n",
    "    \n",
    "    #Criar o Melhor Modelo de Florestas Aleatórias com os Parâmetros Definidos:\n",
    "    melhor_modelo_florestas_aleatorias = RandomForestClassifier(n_estimators=numero_estimadores, max_depth=profundidade_maxima, max_features=numero_maximo_caracteristicas, \n",
    "        random_state=42)\n",
    "    \n",
    "    #Treinar o Modelo de Florestas Aleatórias com o Conjunto de Treino:\n",
    "    melhor_modelo_florestas_aleatorias.fit(trnX, trnY)\n",
    "    \n",
    "    #Realizar Previsões no Conjunto de Treino:\n",
    "    previsoes_treino: array = melhor_modelo_florestas_aleatorias.predict(trnX)\n",
    "\n",
    "    #Realizar Previsões no Conjunto de Teste:\n",
    "    previsoes_teste: array = melhor_modelo_florestas_aleatorias.predict(tstX)\n",
    "    \n",
    "    #Calcular a Métrica de Sensibilidade no Conjunto de Treino e Guardar na Lista:\n",
    "    valores_sensibilidade_treino.append(CLASS_EVAL_METRICS[metrica_avaliacao](trnY, previsoes_treino))\n",
    "\n",
    "    #Calcular a Métrica de Sensibilidade no Conjunto de Teste e Guardar na Lista:\n",
    "    valores_sensibilidade_teste.append(CLASS_EVAL_METRICS[metrica_avaliacao](tstY, previsoes_teste))\n",
    "\n",
    "#Exibir a Lista de Número de Estimadores:\n",
    "print(\"\\nNúmero de Estimadores:\", lista_numero_estimadores)\n",
    "\n",
    "#Exibir os Valores da Sensibilidade no Conjunto de Treino:\n",
    "print(\"\\nSensibilidade - Conjunto de Treino:\", [round(v, 2) for v in valores_sensibilidade_treino])\n",
    "\n",
    "#Exibir os Valores da Sensibilidade no Conjunto de Teste:\n",
    "print(\"\\nSensibilidade - Conjunto de Teste:\", [round(v, 2) for v in valores_sensibilidade_teste])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24afeb99",
   "metadata": {},
   "source": [
    "<H5>4.4.4 - Modelo de Florestas Aleatórias - Estudo de Overfitting - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c02194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir o Tipo de Letra para todos os Textos (sans-serif):\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#Definir os Valores do Número de Estimadores do Modelo de Florestas Aleatórias:\n",
    "numero_estimadores = [2, 252, 502, 752, 1002]\n",
    "\n",
    "#Definir os Valores da Métrica Sensibilidade do Conjunto de Treino:\n",
    "sensibilidade_conjunto_treino = [0.71, 0.76, 0.76, 0.76, 0.75]\n",
    "\n",
    "#Definir os Valores da Métrica Sensibilidade do Conjunto de Teste:\n",
    "sensibilidade_conjunto_teste = [0.68, 0.72, 0.72, 0.72, 0.72]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "#Configurações do Gráfico - Linha do Conjunto de Treino - Rótulo, Cor e Estilo de Linha:\n",
    "plt.plot(numero_estimadores, sensibilidade_conjunto_treino, label='Conjunto de Treino', color='#2ca02c', linestyle='-') \n",
    "\n",
    "#Configurações do Gráfico - Linha do Conjunto de Teste - Rótulo, Cor e Estilo de Linha:\n",
    "plt.plot(numero_estimadores, sensibilidade_conjunto_teste, label='Conjunto de Teste', color='#ff7f0e', linestyle='-')\n",
    "\n",
    "#Configurações do Gráfico - Título - Designação e Tamanho:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nEstudo de Overfitting para o Modelo de Florestas Aleatórias\\n\\n(Profundidade Máxima = 2, Número Máximo de Características = 0.3)\\n', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanho, Valores e Limites Mínimo e Máximo:\n",
    "plt.xlabel('Número de Estimadores', fontsize=14)\n",
    "plt.xticks([2, 252, 502, 752, 1002]) \n",
    "plt.xlim(0, 1002)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanho, Valores, Limites Mínimo e Máximo e Incremento:\n",
    "plt.ylabel('Sensibilidade', fontsize=14)\n",
    "plt.yticks([i/100 for i in range(0, 101, 20)], [f\"{i/100:.2f}\" for i in range(0, 101, 20)])\n",
    "plt.ylim(0.0, 1.005)\n",
    "\n",
    "#Configurar as Margens dos Eixos - Cor e Espessura:\n",
    "plt.gca().spines['bottom'].set(color='black', linewidth=2.5)\n",
    "plt.gca().spines['left'].set(color='black', linewidth=2.5)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#Configurações do Gráfico - Legenda - Posição:\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1, 0.70))\n",
    "\n",
    "#Configurações do Gráfico - Ativar a Grelha:\n",
    "plt.grid(True)\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Linhas:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7caf8a6",
   "metadata": {},
   "source": [
    "<H5>4.4.5 - Modelo de Florestas Aleatórias - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32654e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas: \n",
    "import pandas as pd\n",
    "\n",
    "#A partir do SKLearn.Model_Selection, Importar Funções para Divisão do Treino e Teste:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importar o Modelo Classificador de Florestas Aleatórias:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, F1 e AUC):\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Florestas Aleatórias:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir o Número Máximo de Características do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_maximo_caracteristicas = 0.3\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_estimadores = 250\n",
    "\n",
    "#Criar o Modelo de Florestas Aleatórias com os Parâmetros Definidos:\n",
    "modelo_florestas_aleatorias = RandomForestClassifier(max_depth=profundidade_maxima, max_features=numero_maximo_caracteristicas, n_estimators=numero_estimadores,\n",
    "                                                     random_state=42)\n",
    "\n",
    "#Treinar o Modelo de Florestas Aleatórias com os Dados de Treino:\n",
    "modelo_florestas_aleatorias.fit(X_treino, y_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Treino:\n",
    "previsoes_treino = modelo_florestas_aleatorias.predict(X_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste:\n",
    "previsoes_teste = modelo_florestas_aleatorias.predict(X_teste)\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação:\n",
    "metricas_avaliacao = {'Métrica': ['Exatidão', 'Sensibilidade', 'Precisão', 'AUC', 'F1'],\n",
    "    'Conjunto de Treino': [round(accuracy_score(y_treino, previsoes_treino), 2),  round(recall_score(y_treino, previsoes_treino), 2),\n",
    "                           round(precision_score(y_treino, previsoes_treino), 2), round(roc_auc_score(y_treino, modelo_florestas_aleatorias.predict_proba(X_treino)[:, 1]), 2),\n",
    "                           round(f1_score(y_treino, previsoes_treino), 2)],\n",
    "    'Conjunto de Teste': [round(accuracy_score(y_teste, previsoes_teste), 2), round(recall_score(y_teste, previsoes_teste), 2),\n",
    "                          round(precision_score(y_teste, previsoes_teste), 2), round(roc_auc_score(y_teste, modelo_florestas_aleatorias.predict_proba(X_teste)[:, 1]), 2),\n",
    "                          round(f1_score(y_teste, previsoes_teste), 2)]}\n",
    "\n",
    "#Criar um DataFrame das 5 Métricas de Avaliação:\n",
    "dataframe_metricas_avaliacao = pd.DataFrame(metricas_avaliacao)\n",
    "\n",
    "#Resultados - Exibir as 5 Métricas de Avaliação:\n",
    "print(dataframe_metricas_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca83e2",
   "metadata": {},
   "source": [
    "<H5>4.4.6 - Modelo de Florestas Aleatórias - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Rótulos - Melhor Modelo de Florestas Aleatórias - Conjunto de Treino vs Conjunto de Teste:\n",
    "rotulos = ['Melhor Modelo de Florestas Aleatórias - Conjunto de Treino', 'Melhor Modelo de Florestas Aleatórias - Conjunto de Teste']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.76, 0.75]\n",
    "sensibilidade = [0.76, 0.72]\n",
    "precisao = [0.76, 0.45]\n",
    "auc = [0.84, 0.81]\n",
    "f1 = [0.76, 0.56]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "#Definir os Índices do Eixo X:\n",
    "indices_x = np.arange(len(rotulos)) * 1.4  \n",
    "\n",
    "#Configurações das Barras - Largura:\n",
    "largura_barras = 0.15\n",
    "\n",
    "#Configurações das Barras - Cores:\n",
    "barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'),\n",
    "          \"F1\": (f1, '#9467bd')}\n",
    "\n",
    "#Definir o Deslocamento Horizontal das Barras:\n",
    "deslocamento_horizontal_barras = 0\n",
    "\n",
    "#Iterar sobre cada Métrica de Avaliação:\n",
    "for metrica_avaliacao, (valores, cor) in barras.items():  \n",
    "    \n",
    "    #Criar as Barras para a Métrica Atual:\n",
    "    barras_atuais = plt.bar(indices_x + deslocamento_horizontal_barras, valores, largura_barras, label=metrica_avaliacao, color=cor)  \n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras_atuais:  \n",
    "        \n",
    "        #Obter a Altura de cada Barra:\n",
    "        altura_barra = barra.get_height()  \n",
    "        \n",
    "        #Configurações do Valor Numérico Acima de cada Barra - Posição, Cor e Tamanho:\n",
    "        plt.text(barra.get_x() + barra.get_width()/2, altura_barra, f'{altura_barra:.2f}', ha='center', va='bottom', color='black', fontsize=10)  \n",
    "        \n",
    "    #Atualizar o Deslocamento Horizontal:\n",
    "    deslocamento_horizontal_barras += largura_barras  \n",
    "    \n",
    "#Configurações do Eixo X - Rótulos - Tamanho, Rotação, Posição e Cor:\n",
    "plt.xticks(indices_x + 2 * largura_barras, rotulos, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo e Formatações:\n",
    "plt.ylabel('Valor da Métrica', fontsize=16, labelpad=15, color='black')\n",
    "plt.tick_params(axis='y', colors='black', labelsize=10)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho, Espaçamento e Cor:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\n Comparação das Métricas de Avaliação do Melhor Modelo de Florestas Aleatórias\\n\\n(Profundidade Máxima = 2, Número de Características = 0.3, Número de Estimadores = 250)\\n',\n",
    "          fontsize=16, pad=25, color='black')\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = plt.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Texto, Tamanho e Cores:\n",
    "legenda = plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=10, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Configurações do Gráfico - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Configurações do Gráfico - Desativar a Grelha:\n",
    "plt.grid(False)\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19439b9d",
   "metadata": {},
   "source": [
    "<H5>4.4.7 - Modelo de Florestas Aleatórias - Matriz de Confusão - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422521eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#A partir do Scikit-Learn.Ensemble, Importar o Modelo Classificador de Florestas Aleatórias:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A partir do Scikit-Learn.Metrics, Importar a Função para Calcular a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Florestas Aleatórias:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir o Número Máximo de Características do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_maximo_caracteristicas = 0.3\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_estimadores = 250\n",
    "\n",
    "#Criar o Modelo de Florestas Aleatórias com os Parâmetros Definidos:\n",
    "modelo_florestas_aleatorias = RandomForestClassifier(max_depth=profundidade_maxima, max_features=numero_maximo_caracteristicas, n_estimators=numero_estimadores,\n",
    "    random_state=42)\n",
    "\n",
    "#Treinar o Modelo de Florestas Aleatórias com os Dados de Treino:\n",
    "modelo_florestas_aleatorias.fit(X_treino, y_treino)\n",
    "\n",
    "#Fazer Previsões para o Conjunto de Teste:\n",
    "y_teste_previsto = modelo_florestas_aleatorias.predict(X_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão para o Conjunto de Teste:\n",
    "matriz_confusao_conjunto_teste = confusion_matrix(y_teste, y_teste_previsto)\n",
    "\n",
    "#Exibir a Matriz de Confusão do Conjunto de Teste:\n",
    "print(\"\\nMatriz de Confusão - Conjunto de Teste:\")\n",
    "print(matriz_confusao_conjunto_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737f5cd",
   "metadata": {},
   "source": [
    "<H5>4.4.8 - Modelo de Florestas Aleatórias - Matriz de Confusão - Matriz:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd  \n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np  \n",
    "\n",
    "#Importar A Biblioteca Seaborn:\n",
    "import seaborn as sns  \n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#Definir os Resultados da Matriz de Confusão:\n",
    "matriz_confusao = np.array([[25755, 8320], \n",
    "                        [2649, 6914]])  \n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(8, 6))  \n",
    "\n",
    "#Configurações do Mapa de Calor da Matriz de Confusão - Valores, Cores, Rótulos, Espessura das Linhas e Anotações:\n",
    "mapa_calor = sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Greens', vmin=0, vmax=26000, xticklabels=['0', '1'], yticklabels=['0', '1'], cbar=True, linewidths=0.5,\n",
    "                         annot_kws={\"color\": \"#ff7f0e\", \"size\": 16})\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Cor e Tamanho:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de Florestas Aleatórias\\n\\n(Profundidade Máxima = 2, Número Máximo de Características = 0.3, Número de Estimadores = 250)\\n', color='black', fontsize=15)  \n",
    "\n",
    "#Configurações do Gráfico - Fundo - Cor:\n",
    "plt.gca().set_facecolor('#2ca02c')\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Cores, Tamanhos, Espaçamento e Valores:\n",
    "plt.xlabel('Rótulo Previsto', color='black', fontsize=13, labelpad=10)  \n",
    "plt.gca().xaxis.set_tick_params(color='black')  \n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13)  \n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Cores, Tamanhos, Valores e Rotação:\n",
    "plt.ylabel('Verdadeiro Rótulo', color='black', fontsize=13)  \n",
    "plt.gca().yaxis.set_tick_params(color='black')  \n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13, rotation=0)  \n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor:\n",
    "for spine in ['top', 'right', 'left', 'bottom']:\n",
    "    plt.gca().spines[spine].set_color('black')\n",
    "\n",
    "#Iterar sobre os Textos do Gráfico Atual:\n",
    "for texto in plt.gca().texts:  \n",
    "    \n",
    "    #Converter o Valor Numérico para um Número Inteiro:\n",
    "    numero_inteiro = int(texto.get_text())\n",
    "    \n",
    "    #Formatação do Número Inteiro - Substituir Vírgula por Ponto:\n",
    "    texto.set_text(f\"{numero_inteiro:,}\".replace(',', '.'))  \n",
    "    \n",
    "    #Definir a Cor do Texto como Laranja:\n",
    "    texto.set_color('#ff7f0e')  \n",
    "\n",
    "#Configurar a Barra de Cores do Mapa de Calor:\n",
    "barra_cores = mapa_calor.collections[0].colorbar  \n",
    "\n",
    "#Configurações da Barra de Cores - Valores - Cor:\n",
    "barra_cores.ax.yaxis.set_tick_params(color='black')  \n",
    "\n",
    "#Configurações da Barra de Cores - Valor Máximo:\n",
    "barra_cores_valor_máximo = 26000  \n",
    "\n",
    "#Configurações da Barra de Cores - Valor Mínimo e Incremento:\n",
    "valores = np.arange(0, barra_cores_valor_máximo + 2000, 2000)  \n",
    "\n",
    "#Aplicar os Valores na Barra de Cores:\n",
    "barra_cores.set_ticks(valores)  \n",
    "\n",
    "#Configurações da Barra de Cores - Rótulos - Formatação e Cor:\n",
    "barra_cores.ax.set_yticklabels([f\"{int(valor):,}\".replace(',', '.') for valor in valores], color='black')  \n",
    "\n",
    "#Resultados - Exibir o Gráfico da Matriz de Confusão:\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67581d",
   "metadata": {},
   "source": [
    "<H5>4.4.9 - Modelo de Florestas Aleatórias - Importância de cada Variável - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Scikit-Learn.Ensemble, Importar o Modelo Classificador de Florestas Aleatórias:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A partir da Biblioteca Numerical Python, Importar as Funções para Calcular o Desvio Padrão e Ordenar os Índices:\n",
    "from numpy import std, argsort\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo do Conjunto de Treino:\n",
    "X_treino = conjunto_treino.iloc[:, :-1]\n",
    "y_treino = conjunto_treino.iloc[:, -1]  \n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Florestas Aleatórias:\n",
    "profundidade_maxima=2\n",
    "\n",
    "#Definir o Número Máximo de Características do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_maximo_caracteristicas=0.3\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Florestas Aleatórias:\n",
    "numero_estimadores=250\n",
    "\n",
    "#Iniciar o Melhor Modelo de Florestas Aleatórias:\n",
    "melhor_modelo_florestas_aleatorias = RandomForestClassifier(max_depth=profundidade_maxima, n_estimators=numero_estimadores, max_features=numero_maximo_caracteristicas)\n",
    "\n",
    "#Treinar o Melhor Modelo de Florestas Aleatórias com os Dados de Treino:\n",
    "melhor_modelo_florestas_aleatorias.fit(X_treino, y_treino)\n",
    "\n",
    "#Iniciar uma Lista para Armazenar as Importâncias de cada Árvore de Decisão:\n",
    "importancias_arvores_decisao: list[float] = []\n",
    "\n",
    "#Iterar sobre cada Árvore de Decisão do Melhor Modelo de Florestas Aleatórias:\n",
    "for arvore_decisao in melhor_modelo_florestas_aleatorias.estimators_:\n",
    "    \n",
    "    #Adicionar à Lista de Importâncias as Importâncias das Variáveis calculada por cada Árvore de Decisão:\n",
    "    importancias_arvores_decisao.append(arvore_decisao.feature_importances_)\n",
    "\n",
    "#Calcular o Desvio Padrão das Importâncias de cada Variável:\n",
    "desvios_padrao: list[float] = list(std(importancias_arvores_decisao, axis=0))\n",
    "\n",
    "#Obter as Importâncias Médias das Variáveis do Melhor Modelo de Florestas Aleatórias:\n",
    "importancias_medias = melhor_modelo_florestas_aleatorias.feature_importances_\n",
    "\n",
    "#Obter os Índices das Variáveis Ordenados por Importância Decrescente:\n",
    "indices_variaveis: list[int] = argsort(importancias_medias)[::-1]\n",
    "\n",
    "#Extrair as Variáveis:\n",
    "variaveis = X_treino.columns.tolist()\n",
    "\n",
    "#Iniciar uma Lista para Armazenar os Nomes das Variáveis:\n",
    "nomes_variaveis: list[str] = []\n",
    "\n",
    "#Iniciar uma Lista para Armazenar os Valores das Importâncias:\n",
    "valores_importancia: list[float] = []\n",
    "\n",
    "#Iterar sobre o Índice de cada Variável:\n",
    "for índice in range(len(variaveis)):\n",
    "    \n",
    "    #Adicionar o Nome da Variável correspondente ao Índice Ordenado à Lista de Nomes das Variáveis:\n",
    "    nomes_variaveis.append(variaveis[indices_variaveis[índice]])\n",
    "    \n",
    "    #Adicionar à Lista de Importâncias o Valor da Importância de cada Variável:\n",
    "    valores_importancia.append(importancias_medias[indices_variaveis[índice]])\n",
    "\n",
    "#Exibir o Cabeçalho das Importâncias das Variáveis:\n",
    "print(\"\\nImportâncias das Variáveis:\")\n",
    "\n",
    "#Iterar sobre cada variavel Ordenada pelo indice:\n",
    "for indice, variavel in enumerate(nomes_variaveis):\n",
    "    \n",
    "    #Exibir o Ranking da Variável, o Valor da respetiva Importância e o Desvio Padrão:\n",
    "    print(f\"{indice + 1}. {variavel}: {valores_importancia[indice]:.4f} (± {desvios_padrao[indice]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209264b2",
   "metadata": {},
   "source": [
    "<H5>4.4.10 - Modelo de Florestas Aleatórias - Importância de cada Variável - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir as Variáveis:\n",
    "variaveis = ['Humidade_15h', 'Precipitacao', 'Chuva_Hoje', 'Sol', 'Nuvens_15h', 'Humidade_09h', 'Velocidade_Rajada_Vento', 'Nuvens_09h', 'Pressao_Atmosferica_09h',\n",
    "             'Pressao_Atmosferica_15h', 'Direcao_Vento_09h_Cos', 'Velocidade_Vento_09h', 'Local_Alt', 'Temperatura_Maxima', 'Temperatura_15h', 'Direcao_Vento_15h_Sin',\n",
    "             'Temperatura_Minima', 'Direcao_Vento_09h_Sin', 'Direcao_Rajada_Vento_Sin', 'Evaporacao', 'Temperatura_09h', 'Direcao_Vento_15h_Cos', 'Velocidade_Vento_15h',\n",
    "             'Direcao_Rajada_Vento_Cos', 'Local_Long', 'Local_Lat', 'Dia', 'Mes', 'Ano']\n",
    "\n",
    "#Definir os Valores da Importância de cada Variável (2 casas decimais):\n",
    "valores_importancia_variavel = [0.39, 0.21, 0.13, 0.07, 0.07, 0.04, 0.04, 0.02, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
    "                                0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "#Configurações das Barras - Cores, Tamanho das Extremidades e Estilo da Linha:\n",
    "barras = plt.bar(variaveis, valores_importancia_variavel, color='#2ca02c', capsize=5, ecolor='#ff7f0e', linestyle='-')\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho e Espaçamento:\n",
    "plt.title('Conjunto de Dados 1 - Importância das Variáveis para o Modelo de Florestas Aleatórias', fontsize=15, pad=20)\n",
    "\n",
    "#Iterar sobre cada Barra:\n",
    "for barra in barras:\n",
    "    \n",
    "    #Definir a Altura de cada Barra:\n",
    "    altura_barra = barra.get_height()\n",
    "    \n",
    "    #Adicionar o Valor Numérico Acima de cada Barra - Posição e Tamanho:\n",
    "    plt.text(barra.get_x() + barra.get_width()/2, altura_barra + 0.01, f'{altura_barra:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanho, Cores, Rotação e Posição:\n",
    "plt.xlabel('Variáveis', fontsize=14)\n",
    "plt.xticks(color='black', rotation=45, ha='right') \n",
    "plt.gca().xaxis.set_tick_params(color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanho,  Cores, Rotação, Limites Mínimo e Máximo e Incremento:\n",
    "plt.ylabel('Importância', fontsize=14)\n",
    "plt.yticks(color='black', rotation=0)  \n",
    "plt.gca().yaxis.set_tick_params(color='black')\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), ['{:.2f}'.format(x) for x in np.arange(0, 1.1, 0.2)])\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "#Configurar as Margens dos Eixos - Cor e Espessura:\n",
    "for margem in plt.gca().spines.values():\n",
    "    margem.set_color('black') \n",
    "    margem.set_linewidth(2.5)  \n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#Configurações do Gráfico - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37328b",
   "metadata": {},
   "source": [
    "<H5>4.5 - Modelo de Gradient Boosting:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0102a58",
   "metadata": {},
   "source": [
    "<H5>4.5.1 - Modelo de Gradient Boosting - Melhor Combinação de Parâmetros - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df510c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir da Biblioteca Numerical Python, Importar as Estruturas de Dados:\n",
    "from numpy import array, ndarray\n",
    "\n",
    "#A partir da SKLearn.Ensemble, Importar o Modelo de Gradient Boosting:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as 5 Métricas de Avaliação para Classificação, Mínimo Necessário para Melhoria e Função Ler Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import (CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files)\n",
    "\n",
    "#Função para Estudo do Modelo de Gradient Boosting com Diferentes Configurações:\n",
    "def funcao_estudo_gradient_boosting(X_treino: ndarray, Y_treino: array, X_teste: ndarray, Y_teste: array, numeros_estimadores: list[int], métrica: str = \"recall\") -> tuple[GradientBoostingClassifier | None, dict, pandas.DataFrame]:\n",
    "    \n",
    "    #Definir as Profundidades Máximas das Árvores:\n",
    "    profundidades_maximas_árvores: list[int] = [2, 5, 7]\n",
    "\n",
    "    #Definir as Taxas de Aprendizagem:\n",
    "    taxas_aprendizagem: list[float] = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "    #Variável para Guardar o Melhor Modelo de Gradient Boosting:\n",
    "    melhor_modelo_gradient_boosting: GradientBoostingClassifier | None = None\n",
    "\n",
    "    #Dicionário para Armazenar os Melhores Parâmetros:\n",
    "    melhores_parametros: dict = {\"nome\": \"GradientBoosting\", \"métrica\": métrica, \"parâmetros\": ()}\n",
    "\n",
    "    #Variável para Armazenar o Melhor Desempenho:\n",
    "    melhor_desempenho: float = 0.0\n",
    "\n",
    "    #Criar uma Lista para Armazenar os Resultados de Todas as Configurações:\n",
    "    resultados: list[dict] = []\n",
    "\n",
    "    #Ciclo pelas Profundidades Máximas:\n",
    "    for profundidade_maxima_arvores in profundidades_maximas_árvores:\n",
    "        \n",
    "        #Ciclo pelas Taxas de Aprendizagem:\n",
    "        for taxa_aprendizagem in taxas_aprendizagem:\n",
    "            \n",
    "            #Ciclo pelos Números de Estimadores:\n",
    "            for número_estimadores in numeros_estimadores:\n",
    "                \n",
    "                #Criar e Configurar o Modelo de Gradient Boosting:\n",
    "                modelo_gradient_boosting = GradientBoostingClassifier(n_estimators=número_estimadores, max_depth=profundidade_maxima_arvores,\n",
    "                                                                      learning_rate=taxa_aprendizagem)\n",
    "                \n",
    "                #Treinar o Modelo no Conjunto de Treino:\n",
    "                modelo_gradient_boosting.fit(X_treino, Y_treino)\n",
    "\n",
    "                #Prever os Resultados no Conjunto de Teste:\n",
    "                previsões_Y: array = modelo_gradient_boosting.predict(X_teste)\n",
    "\n",
    "                #Calcular a Métrica de Avaliação:\n",
    "                avaliação: float = round(CLASS_EVAL_METRICS[métrica](Y_teste, previsões_Y), 2)\n",
    "\n",
    "                #Armazenar os Resultados da Configuração (tudo na mesma linha)\n",
    "                resultados.append({'Profundidade Máxima': profundidade_maxima_arvores, 'Taxa de Aprendizagem': taxa_aprendizagem, 'Número de Estimadores': número_estimadores,\n",
    "                                   'Sensibilidade': avaliação})\n",
    "                \n",
    "                #Se o Desempenho for Melhor do que o Anterior:\n",
    "                if avaliação - melhor_desempenho > DELTA_IMPROVE:\n",
    "                    \n",
    "                    #Atualizar o Melhor Desempenho:\n",
    "                    melhor_desempenho = avaliação\n",
    "\n",
    "                    #Guardar os Melhores Parâmetros:\n",
    "                    melhores_parametros[\"parâmetros\"] = (profundidade_maxima_arvores, taxa_aprendizagem, número_estimadores)\n",
    "\n",
    "                    #Guardar o Melhor Modelo de Gradient Boosting:\n",
    "                    melhor_modelo_gradient_boosting = modelo_gradient_boosting\n",
    "\n",
    "    #Criar um DataFrame com os Resultados (colunas lado a lado):\n",
    "    resultados_dataframe = pandas.DataFrame(resultados)\n",
    "\n",
    "    #Configurar a Biblioteca Pandas para Mostrar Todas as Linhas e Colunas:\n",
    "    pandas.set_option('display.max_rows', None)\n",
    "    pandas.set_option('display.max_columns', None)\n",
    "\n",
    "    #Mostrar os Resultados de Desempenho:\n",
    "    print(\"Resultados de Desempenho:\\n\")\n",
    "    print(resultados_dataframe.to_string(index=False))\n",
    "    print(f'\\nMelhor Modelo de Gradient Boosting: Profundidade Máxima = {melhores_parametros[\"parâmetros\"][0]}, '\n",
    "          f'Taxa de Aprendizagem = {melhores_parametros[\"parâmetros\"][1]}, '\n",
    "          f'Número de Estimadores = {melhores_parametros[\"parâmetros\"][2]}')\n",
    "\n",
    "    #Repor a Configuração Padrão do Pandas:\n",
    "    pandas.reset_option('display.max_rows')\n",
    "    pandas.reset_option('display.max_columns')\n",
    "\n",
    "    #Devolver o Melhor Modelo, os Melhores Parâmetros e o DataFrame de Resultados:\n",
    "    return melhor_modelo_gradient_boosting, melhores_parametros, resultados_dataframe\n",
    "\n",
    "\n",
    "#Carregar os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = \"conjunto_treino_balanceado_sobreamostragem_SMOTE.csv\"\n",
    "conjunto_teste = \"conjunto_teste_normalizado_z-score.csv\"\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "X_treino, X_teste, Y_treino, Y_teste, rótulos, variáveis = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Definir a Métrica de Avaliação (Sensibilidade):\n",
    "metrica_avaliacao = \"recall\"\n",
    "\n",
    "#Definir os Números de Estimadores:\n",
    "numeros_estimadores = [100, 250, 500, 750, 1000]\n",
    "\n",
    "#Executar a Função de Estudo do Modelo de Gradient Boosting:\n",
    "melhor_modelo_gradient_boosting, parâmetros, resultados = funcao_estudo_gradient_boosting(X_treino, Y_treino, X_teste, Y_teste, numeros_estimadores=numeros_estimadores,\n",
    "                                                                                          métrica=metrica_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37294390",
   "metadata": {},
   "source": [
    "<H5>4.5.2 - Modelo de Gradient Boosting - Métrica de Avaliação Sensibilidade em Função dos Parâmetros Profundidade Máxima, Taxa de Aprendizagem e Número de Estimadores - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca379a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas: \n",
    "import pandas as pd\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Matplotlib.Pyplot, Importar as Funções de Subgráficos e Exibição:\n",
    "from matplotlib.pyplot import subplots, show\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar Altura:\n",
    "from dslabs_functions import HEIGHT\n",
    "\n",
    "#Definir os Dados com os Valores obtidos para os Hiperparâmetros e com os Valores obtidos para a Métrica de Avaliação Sensibilidade:\n",
    "dados = {\n",
    "    \n",
    "    #Profundidade Máxima\n",
    "    'profundidade_maxima': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7,\n",
    "                            7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
    "\n",
    "    #Taxa de Aprendizagem:\n",
    "    'taxa_aprendizagem': [0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5,\n",
    "                          0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9,\n",
    "                          0.9, 0.9],\n",
    "\n",
    "    #Número de Estimadores:\n",
    "    'número_estimadores': [100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000,\n",
    "                           100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000, 100, 500, 750, 1000,\n",
    "                           100, 500, 750, 1000],\n",
    "\n",
    "    #Métrica Sensibilidade:\n",
    "    'sensibilidade': [0.70, 0.57, 0.56, 0.55, 0.60, 0.56, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.56, 0.56, 0.57, 0.57, 0.55, 0.57, 0.57, 0.57, 0.60, 0.58, 0.58, 0.59, 0.57,\n",
    "                      0.59, 0.60, 0.60, 0.58, 0.59, 0.60, 0.60, 0.58, 0.59, 0.59, 0.59, 0.58, 0.59, 0.59, 0.59, 0.58, 0.59, 0.59, 0.60, 0.58, 0.59, 0.60, 0.60, 0.59, 0.60,\n",
    "                      0.60, 0.61, 0.59, 0.59, 0.60, 0.60, 0.58, 0.59, 0.61, 0.61]}\n",
    "\n",
    "#Criar um DataFrame com os Resultados:\n",
    "resultados_dataframe = pd.DataFrame(dados)\n",
    "\n",
    "#Obter os Valores Únicos da Profundidade Máxima:\n",
    "profundidades_maximas = resultados_dataframe['profundidade_maxima'].unique()\n",
    "\n",
    "#Definir o Número de Colunas do Subgráfico:\n",
    "colunas: int = len(profundidades_maximas)\n",
    "\n",
    "#Criar os Subgráficos:\n",
    "_, eixos = subplots(1, colunas, figsize=(colunas * HEIGHT, HEIGHT), squeeze=False)\n",
    "\n",
    "#Definir as Cores para cada Taxa de Aprendizagem:\n",
    "cores_taxa_aprendizagem = {0.1: '#ff7f0e', 0.3: '#ffdd57', 0.5: '#2ca02c', 0.7: '#87CEEB', 0.9: '#9467bd'}\n",
    "\n",
    "#Iterar pelos Índices e Profundidades Máximas:\n",
    "for indice, profundidade_maxima in enumerate(profundidades_maximas):\n",
    "    \n",
    "    #Filtrar os Resultados por Profundidade Máxima:\n",
    "    resultados_filtrados = resultados_dataframe[resultados_dataframe['profundidade_maxima'] == profundidade_maxima]\n",
    "\n",
    "    #Criar um Dicionário de Valores para cada Taxa de Aprendizagem:\n",
    "    valores_taxa_aprendizagem = {}\n",
    "\n",
    "    #Iterar sobre cada Taxa de Aprendizagem nos Resultados Filtrados:\n",
    "    for taxa in resultados_filtrados['taxa_aprendizagem'].unique():\n",
    "        \n",
    "        #Guardar a Lista de Valores de Sensibilidade por Taxa de Aprendizagem:\n",
    "        valores_taxa_aprendizagem[taxa] = resultados_filtrados[resultados_filtrados['taxa_aprendizagem'] == taxa]['sensibilidade'].tolist()\n",
    "\n",
    "    #Iterar sobre cada Taxa de Aprendizagem presente no Dicionário de Valores por Taxa:\n",
    "    for taxa in valores_taxa_aprendizagem.keys():\n",
    "\n",
    "        #Selecionar o Eixo correspondente à Coluna Atual para Desenhar o Gráfico:\n",
    "        eixo = eixos[0, indice]\n",
    "        \n",
    "        #Construir a Curva:\n",
    "        eixo.plot(resultados_filtrados['número_estimadores'].unique(), valores_taxa_aprendizagem[taxa], color=cores_taxa_aprendizagem[taxa], label=f'{taxa}')\n",
    "    \n",
    "    #Configurações do Gráfico - Título Individual - Designação, Tamanho e Cor:\n",
    "    eixo.set_title(f\"Profundidade Máxima = {profundidade_maxima}\\n\", fontsize=12, color='black')\n",
    "    \n",
    "    #Configurações do Eixo X - Título, Tamanho, Cores, Valores e Limite Máximo:\n",
    "    eixo.set_xlabel(\"Número de Estimadores\", fontsize=12, color='black')\n",
    "    eixo.set_xticks([100, 250, 500, 750, 1000])\n",
    "    for etiqueta in eixo.get_xticklabels():\n",
    "        etiqueta.set_color('black')\n",
    "        etiqueta.set_rotation(0)\n",
    "    eixo.set_xlim(left=100)\n",
    "\n",
    "    #Configurações do Eixo Y - Título, Tamanho, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "    eixo.set_ylabel(\"Sensibilidade\", fontsize=12, color='black')\n",
    "    eixo.set_ylim(0.0, 1.0)  \n",
    "    eixo.set_yticks(np.arange(0.0, 1.1, 0.2))  \n",
    "    for etiqueta in eixo.get_yticklabels():\n",
    "        etiqueta.set_color('black')\n",
    "    eixo.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "\n",
    "    #Configurações dos Eixos X e Y - Tamanho:\n",
    "    eixo.tick_params(axis='both', labelsize=8)  \n",
    "\n",
    "    #Obter os Objetos da Legenda e os Respetivos Rótulos do Eixo Atual:\n",
    "    handles, labels = eixo.get_legend_handles_labels()\n",
    "\n",
    "    #Criar um Dicionário de Rótulos:\n",
    "    rótulos = dict(zip(labels, handles))\n",
    "\n",
    "    #Adicionar a Legenda de Cores - Rótulo, Tamanhos, Posição, Contorno e Cores:\n",
    "    legenda_eixo = eixo.legend(rótulos.values(), rótulos.keys(), title=\"Taxa de Aprendizagem:\", fontsize=8, loc='lower right', title_fontsize='small', frameon=True)\n",
    "    if legenda_eixo is not None:\n",
    "        legenda_eixo.get_title().set_color('black')\n",
    "        for texto_legenda in legenda_eixo.get_texts():\n",
    "            texto_legenda.set_color('black')\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "for linha_eixos in eixos:\n",
    "    for eixo_individual in linha_eixos:\n",
    "        for margem_eixo in eixo_individual.spines.values():\n",
    "            margem_eixo.set_color('black')\n",
    "            margem_eixo.set_linewidth(2.5)\n",
    "        legenda_atual = eixo_individual.get_legend()\n",
    "        if legenda_atual is not None:\n",
    "            legenda_atual.get_title().set_color('black')\n",
    "            for texto_legenda in legenda_atual.get_texts():\n",
    "                texto_legenda.set_color('black')\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho da Fonte, Tipo de Fonte e Cor:\n",
    "plt.suptitle(\"Conjunto de Dados 1 - Conjunto de Teste\\n\\nAnálise da Sensibilidade para diferentes Parametrizações do Modelo de Gradient Boosting\", fontsize=13, fontweight='normal', color='black')\n",
    "\n",
    "#Configurações do Gráfico - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Resultados - Exibir o Gráfico:\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833203f",
   "metadata": {},
   "source": [
    "<H5>4.5.3 - Modelo de Gradient Boosting - Estudo de Overfitting - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564491c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir da Biblioteca Numerical Python, Importar Array:\n",
    "from numpy import array\n",
    "\n",
    "#A partir do Scikit-Learn.Ensemble, Importar o Modelo Classificador de Gradient Boosting:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as Funções Métricas de Avaliação de Classificação e Ler Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import CLASS_EVAL_METRICS, read_train_test_from_files\n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Gradient Boosting:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir a Taxa de Aprendizagem do Melhor Modelo de Gradient Boosting:\n",
    "taxa_aprendizagem = 0.1\n",
    "\n",
    "#Definir o Número de Estimadores:\n",
    "numero_estimadores = 1000\n",
    "\n",
    "#Definir a Métrica de Avaliação a Utilizar (Sensibilidade):\n",
    "metrica_avaliacao = \"recall\"\n",
    "\n",
    "#Definir os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = \"conjunto_treino_balanceado_sobreamostragem_SMOTE.csv\"\n",
    "conjunto_teste = \"conjunto_teste_normalizado_z-score.csv\"\n",
    "\n",
    "#Definir a Variável Alvo:\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Carregar os Conjuntos de Treino e de Teste:\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Exibir o Número de Instâncias nos Conjuntos de Treino e de Teste:\n",
    "print(f\"Conjunto de Treino: {len(trnX)}, Conjunto de Teste: {len(tstX)}\")\n",
    "\n",
    "#Iniciar a Lista para Guardar os Valores da Métrica Sensibilidade no Conjunto de Treino:\n",
    "valores_treino: list[float] = []\n",
    "\n",
    "#Iniciar a Lista para Guardar os Valores da Métrica Sensibilidade no Conjunto de Teste:\n",
    "valores_teste: list[float] = []\n",
    "\n",
    "#Criar a Lista de Estimadores a Testar:\n",
    "lista_estimadores = list(range(2, numero_estimadores + 1, 50))\n",
    "\n",
    "#Iterar sobre cada Número de Estimadores Definido:\n",
    "for número_estimadores in lista_estimadores:\n",
    "    \n",
    "    #Criar o Melhor Modelo de Gradient Boosting com os Parâmetros Definidos:\n",
    "    modelo = GradientBoostingClassifier(n_estimators=número_estimadores, max_depth=profundidade_maxima, learning_rate=taxa_aprendizagem)\n",
    "    \n",
    "    #Treinar o Modelo de Gradient Boosting com o Conjunto de Treino:\n",
    "    modelo.fit(trnX, trnY)\n",
    "    \n",
    "    #Realizar Previsões no Conjunto de Treino:\n",
    "    previsoes_treino: array = modelo.predict(trnX)\n",
    "\n",
    "    #Realizar Previsões no Conjunto de Teste:\n",
    "    previsoes_teste: array = modelo.predict(tstX)\n",
    "    \n",
    "    #Calcular a Métrica de Sensibilidade no Conjunto de Treino e Guardar na Lista:\n",
    "    valores_treino.append(CLASS_EVAL_METRICS[metrica_avaliacao](trnY, previsoes_treino))\n",
    "\n",
    "    #Calcular a Métrica de Sensibilidade no Conjunto de Teste e Guardar na Lista:\n",
    "    valores_teste.append(CLASS_EVAL_METRICS[metrica_avaliacao](tstY, previsoes_teste))\n",
    "\n",
    "#Exibir a Lista de Número de Estimadores:\n",
    "print(\"\\nNúmero de Estimadores:\", lista_estimadores)\n",
    "\n",
    "#Exibir os Valores da Sensibilidade no Conjunto de Treino:\n",
    "print(\"\\nSensibilidade - Conjunto de Treino:\", [round(v, 2) for v in valores_treino])\n",
    "\n",
    "#Exibir os Valores da Sensibilidade no Conjunto de Teste:\n",
    "print(\"\\nSensibilidade - Conjunto de Teste:\", [round(v, 2) for v in valores_teste])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e89b79",
   "metadata": {},
   "source": [
    "<H5>4.5.4 - Modelo de Gradient Boosting - Estudo de Overfitting - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir os Valores do Número de Estimadores do Modelo de Gradient Boosting:\n",
    "numero_estimadores = [2, 52, 102, 152, 202, 252, 302, 352, 402, 452, 502, 552, 602, 652, 702, 752, 802, 852, 902, 952, 1002]\n",
    "\n",
    "#Definir os Valores da Métrica Sensibilidade do Conjunto de Treino:\n",
    "sensibilidade_conjunto_treino = [0.82, 0.81, 0.83, 0.85, 0.86, 0.86, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87]\n",
    "\n",
    "#Definir os Valores da Métrica Sensibilidade do Conjunto de Teste:\n",
    "sensibilidade_conjunto_teste = [0.77, 0.72, 0.69, 0.66, 0.64, 0.63, 0.61, 0.60, 0.59, 0.58, 0.57, 0.57, 0.56, 0.55, 0.55, 0.56, 0.56, 0.55, 0.56, 0.55, 0.55]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "#Configurações do Gráfico - Linha do Conjunto de Treino - Rótulo, Cor e Estilo de Linha:\n",
    "plt.plot(numero_estimadores, sensibilidade_conjunto_treino, label='Conjunto de Treino', color='#2ca02c', linestyle='-') \n",
    "\n",
    "#Configurações do Gráfico - Linha do Conjunto de Teste - Rótulo, Cor e Estilo de Linha:\n",
    "plt.plot(numero_estimadores, sensibilidade_conjunto_teste, label='Conjunto de Teste', color='#ff7f0e', linestyle='-')\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação e Tamanho:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nEstudo de Overfitting para o Modelo de Gradient Boosting (Profundidade Máxima = 2, Taxa de Aprendizagem = 0.1)\\n', fontsize=14)\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanho, Valores e Limites Mínimo e Máximo:\n",
    "plt.xlabel('Número de Estimadores', fontsize=14)\n",
    "plt.xticks([2, 252, 502, 752, 1002]) \n",
    "plt.xlim(0, 1002)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanho, Valores, Limites Mínimo e Máximo e Incremento:\n",
    "plt.ylabel('Sensibilidade', fontsize=14)\n",
    "plt.yticks([i/100 for i in range(0, 101, 20)], [f\"{i/100:.2f}\" for i in range(0, 101, 20)])\n",
    "plt.ylim(0.0, 1.005)\n",
    "\n",
    "#Configurar as Margens dos Eixos - Cor e Espessura:\n",
    "plt.gca().spines['bottom'].set(color='black', linewidth=2.5)\n",
    "plt.gca().spines['left'].set(color='black', linewidth=2.5)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#Configurações do Gráfico - Legenda - Posição:\n",
    "plt.legend(loc='center right', bbox_to_anchor=(1, 0.70))\n",
    "\n",
    "#Configurações do Gráfico - Ativar a Grelha:\n",
    "plt.grid(True)\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Linhas:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bfcd4",
   "metadata": {},
   "source": [
    "<H5>4.5.5 - Modelo de Gradient Boosting - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67237569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#A partir do SKLearn.Model_Selection, Importar Funções para Divisão do Treino do Teste:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importar o Modelo Classificador de Gradient Boosting:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as Métricas de Avaliação:\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])  \n",
    "y_treino = conjunto_treino['Chuva_Amanha']                \n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])  \n",
    "y_teste = conjunto_teste['Chuva_Amanha']              \n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Gradient Boosting:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir a Taxa de Aprendizagem do Melhor Modelo de Gradient Boosting:\n",
    "taxa_aprendizagem = 0.1\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Gradient Boosting:\n",
    "numero_estimadores = 100\n",
    "\n",
    "#Criar o Modelo de Gradient Boosting com os Parâmetros Definidos:\n",
    "modelo_gradient_boosting = GradientBoostingClassifier(max_depth=profundidade_maxima, learning_rate=taxa_aprendizagem, n_estimators=numero_estimadores)\n",
    "\n",
    "#Treinar o Modelo de Gradient Boosting com os Dados de Treino:\n",
    "modelo_gradient_boosting.fit(X_treino, y_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Treino:\n",
    "previsoes_treino = modelo_gradient_boosting.predict(X_treino)\n",
    "\n",
    "#Fazer Previsões no Conjunto de Teste:\n",
    "previsoes_teste = modelo_gradient_boosting.predict(X_teste)\n",
    "\n",
    "#Calcular as Métricas de Avaliação e Arredondar para 2 Casas Decimais:\n",
    "metricas_avaliacao = {'Métrica': ['Exatidão', 'Sensibilidade', 'Precisão', 'AUC', 'F1'],  \n",
    "    'Conjunto de Treino': [round(accuracy_score(y_treino, previsoes_treino), 2), round(recall_score(y_treino, previsoes_treino), 2),\n",
    "                           round(precision_score(y_treino, previsoes_treino), 2), round(roc_auc_score(y_treino, modelo_gradient_boosting.predict_proba(X_treino)[:, 1]), 2),\n",
    "        round(f1_score(y_treino, previsoes_treino), 2)],\n",
    "    'Conjunto de Teste': [round(accuracy_score(y_teste, previsoes_teste), 2), round(recall_score(y_teste, previsoes_teste), 2), round(precision_score(y_teste, previsoes_teste), 2),\n",
    "        round(roc_auc_score(y_teste, modelo_gradient_boosting.predict_proba(X_teste)[:, 1]), 2), round(f1_score(y_teste, previsoes_teste), 2)]}\n",
    "\n",
    "#Criar um DataFrame com os Valores das Métricas de Avaliação:\n",
    "dataframe_metricas_avaliacao = pd.DataFrame(metricas_avaliacao)\n",
    "\n",
    "#Resultados - Exibir as Métricas de Avaliação:\n",
    "print(dataframe_metricas_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba50c0",
   "metadata": {},
   "source": [
    "<H5>4.5.6 - Modelo de Gradient Boosting - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb800da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Rótulos - Melhor Modelo de Gradient Boosting - Conjunto de Treino vs Conjunto de Teste:\n",
    "rotulos = ['Melhor Modelo de Gradient Boosting - Conjunto de Treino', 'Melhor Modelo de Gradient Boosting - Conjunto de Teste']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.84, 0.81]\n",
    "sensibilidade = [0.83, 0.70]\n",
    "precisao = [0.84, 0.56]\n",
    "auc = [0.92, 0.86]\n",
    "f1 = [0.84, 0.62]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "#Definir os Índices do Eixo X:\n",
    "indices_eixo_x = np.arange(len(rotulos)) * 1.4  \n",
    "\n",
    "#Configurações do Gráfico - Barras - Largura:\n",
    "largura_barras = 0.15\n",
    "\n",
    "#Configurações do Gráfico - Barras - Cores:\n",
    "cores_barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'),\n",
    "          \"F1\": (f1, '#9467bd')}\n",
    "\n",
    "#Definir o Deslocamento Horizontal das Barras:\n",
    "deslocamento_horizontal_barras = 0\n",
    "\n",
    "#Iterar sobre cada Métrica de Avaliação:\n",
    "for metrica_avaliacao, (valores, cor) in cores_barras.items():  \n",
    "    \n",
    "    #Criar as Barras para a Métrica Atual:\n",
    "    barras_atuais = plt.bar(indices_eixo_x + deslocamento_horizontal_barras, valores, largura_barras, label=metrica_avaliacao, color=cor)  \n",
    "    \n",
    "    #Iterar sobre cada Barra:\n",
    "    for barra in barras_atuais:  \n",
    "        \n",
    "        #Obter a Altura de cada Barra:\n",
    "        altura_barra = barra.get_height()  \n",
    "        \n",
    "        #Configurações do Valor Numérico acima de cada Barra - Posição, Cor e Tamanho:\n",
    "        plt.text(barra.get_x() + barra.get_width()/2, altura_barra, f'{altura_barra:.2f}', ha='center', va='bottom', color='black', fontsize=10)  \n",
    "        \n",
    "    #Atualizar o Deslocamento Horizontal:\n",
    "    deslocamento_horizontal_barras += largura_barras  \n",
    "    \n",
    "#Configurações do Eixo X - Rótulos - Tamanho, Rotação, Posição e Cor:\n",
    "plt.xticks(indices_eixo_x + 2 * largura_barras, rotulos, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo e Formatações:\n",
    "plt.ylabel('Valor da Métrica', fontsize=16, labelpad=15, color='black')\n",
    "plt.tick_params(axis='y', colors='black', labelsize=10)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho, Espaçamento e Cor:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\n Comparação das Métricas de Avaliação do Melhor Modelo de Gradient Boosting\\n\\n(Profundidade Máxima = 2, Taxa de Aprendizagem = 0.1, Número de Estimadores = 100)\\n',\n",
    "          fontsize=16, pad=25, color='black')\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = plt.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Texto, Tamanhos e Cores:\n",
    "legenda = plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=10, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Configurações do Gráfico - Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Configurações do Gráfico - Desativar a Grelha:\n",
    "plt.grid(False)\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24befb9",
   "metadata": {},
   "source": [
    "<H5>4.5.7 - Modelo de Gradient Boosting - Matriz de Confusão - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#A partir do Scikit-Learn.Ensemble, Importar o Modelo Classificador de Gradient Boosting:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#A partir do Scikit-Learn, Importar a Função para Calcular a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo no Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Gradient Boosting:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir a Taxa de Aprendizagem do Melhor Modelo de Gradient Boosting:\n",
    "taxa_aprendizagem = 0.1\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Gradient Boosting:\n",
    "numero_estimadores = 100\n",
    "\n",
    "#Criar o Modelo de Gradient Boosting com os Parâmetros Definidos:\n",
    "melhor_modelo_gradient_boosting = GradientBoostingClassifier(max_depth=profundidade_maxima, learning_rate=taxa_aprendizagem, n_estimators=numero_estimadores)\n",
    "\n",
    "#Treinar o Modelo de Gradient Boosting com os Dados de Treino:\n",
    "melhor_modelo_gradient_boosting.fit(X_treino, y_treino)\n",
    "\n",
    "#Fazer Previsões para o Conjunto de Teste:\n",
    "y_teste_previsto = melhor_modelo_gradient_boosting.predict(X_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão para o Conjunto de Teste:\n",
    "matriz_confusao_conjunto_teste = confusion_matrix(y_teste, y_teste_previsto)\n",
    "\n",
    "#Exibir a Matriz de Confusão do Conjunto de Teste:\n",
    "print(\"\\nMatriz de Confusão - Conjunto de Teste:\")\n",
    "print(matriz_confusao_conjunto_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879fc80",
   "metadata": {},
   "source": [
    "<H5>4.5.8 - Modelo de Gradient Boosting - Matriz de Confusão - Matriz:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b182186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd  \n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np  \n",
    "\n",
    "#Importar a Biblioteca Seaborn:\n",
    "import seaborn as sns  \n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#Definir os Resultados da Matriz de Confusão:\n",
    "matriz_confusao = np.array([[28829, 5246], \n",
    "                        [2914, 6649]])  \n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(8, 6))  \n",
    "\n",
    "#Configurações do Mapa de Calor da Matriz de Confusão - Valores, Cores, Rótulos, Espessura das Linhas e Anotações:\n",
    "mapa_calor_matriz_confusao = sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Greens', vmin=0, vmax=30000, xticklabels=['0', '1'], yticklabels=['0', '1'], cbar=True,\n",
    "                         linewidths=0.5, annot_kws={\"color\": \"#ff7f0e\", \"size\": 16})\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Cor e Tamanho:\n",
    "plt.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de Gradient Boosting\\n\\n(Profundidade Máxima = 2, Taxa de Aprendizagem = 0.1, Número de Estimadores = 100)\\n', color='black', fontsize=15)  \n",
    "\n",
    "#Configurações do Gráfico - Fundo - Cor:\n",
    "plt.gca().set_facecolor('#2ca02c')\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Cores, Tamanhos, Espaçamento e Valores:\n",
    "plt.xlabel('Rótulo Previsto', color='black', fontsize=13, labelpad=10)  \n",
    "plt.gca().xaxis.set_tick_params(color='black')  \n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13)  \n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Cores, Tamanhos, Valores e Rotação:\n",
    "plt.ylabel('Verdadeiro Rótulo', color='black', fontsize=13)  \n",
    "plt.gca().yaxis.set_tick_params(color='black')  \n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13, rotation=0)  \n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor:\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_color('black')\n",
    "\n",
    "#Iterar sobre os Textos do Gráfico Atual:\n",
    "for texto in plt.gca().texts:  \n",
    "    \n",
    "    #Converter o Valor Numérico para um Número Inteiro:\n",
    "    numero_inteiro = int(texto.get_text())\n",
    "    \n",
    "    #Formatação do Número Inteiro - Substituir Vírgula por Ponto:\n",
    "    texto.set_text(f\"{numero_inteiro:,}\".replace(',', '.'))  \n",
    "    \n",
    "    #Definir a Cor do Texto como Laranja:\n",
    "    texto.set_color('#ff7f0e')  \n",
    "\n",
    "#Configurar a Barra de Cores do Mapa de Calor:\n",
    "barra_cores = mapa_calor_matriz_confusao.collections[0].colorbar  \n",
    "\n",
    "#Configurações da Barra de Cores - Valores - Cor:\n",
    "barra_cores.ax.yaxis.set_tick_params(color='black')  \n",
    "\n",
    "#Configurações da Barra de Cores - Valores Mínimo e Máximo:\n",
    "barra_cores_valor_máximo = 30000  \n",
    "ticks = np.arange(0, barra_cores_valor_máximo + 2000, 2000)  \n",
    "\n",
    "#Aplicar os Ticks na Barra de Cores:\n",
    "barra_cores.set_ticks(ticks)  \n",
    "\n",
    "#Configurações da Barra de Cores - Formatação dos Rótulos:\n",
    "barra_cores.ax.set_yticklabels([f\"{int(tick):,}\".replace(',', '.') for tick in ticks], color='black')  \n",
    "\n",
    "#Resultados - Exibir o Gráfico da Matriz de Confusão:\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cb8c7",
   "metadata": {},
   "source": [
    "<H5>4.5.9 - Modelo de Gradient Boosting - Importância de cada Variável - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#A partir da Biblioteca Numerical Python, Importar as Funções para Calcular o Desvio Padrão e Ordenar os Índices:\n",
    "from numpy import std, argsort\n",
    "\n",
    "#A partir do Scikit-Learn, Importar o Modelo Classificador de Gradient Boosting:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pd.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pd.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Separar as Variáveis Independentes e a Variável Alvo:\n",
    "X_treino = conjunto_treino.iloc[:, :-1]\n",
    "y_treino = conjunto_treino.iloc[:, -1]  \n",
    "\n",
    "#Definir a Profundidade Máxima do Melhor Modelo de Gradient Boosting:\n",
    "profundidade_maxima = 2\n",
    "\n",
    "#Definir a Taxa de Aprendizagem do Melhor Modelo de Gradient Boosting:\n",
    "taxa_aprendizagem = 0.1\n",
    "\n",
    "#Definir o Número de Estimadores do Melhor Modelo de Gradient Boosting:\n",
    "numero_estimadores = 100\n",
    "\n",
    "#Criar o Modelo de Gradient Boosting com os Parâmetros Definidos:\n",
    "melhor_modelo_gradient_boosting = GradientBoostingClassifier(max_depth=profundidade_maxima, learning_rate=taxa_aprendizagem, n_estimators=numero_estimadores)\n",
    "\n",
    "#Treinar o Melhor Modelo de Gradient Boosting com os Dados de Treino:\n",
    "melhor_modelo_gradient_boosting.fit(X_treino, y_treino)\n",
    "\n",
    "#Iniciar uma Lista para Armazenar as Importâncias de cada Árvore de Decisão:\n",
    "importancias_arvores_decisao: list[float] = []\n",
    "\n",
    "#Iterar sobre cada Lista de Árvores de Decisão do Melhor Modelo de Gradient Boosting:\n",
    "for lista_arvores_decisao in melhor_modelo_gradient_boosting.estimators_:\n",
    "    \n",
    "    #Iterar sobre cada Árvore de Decisão da Lista:\n",
    "    for arvore_decisao in lista_arvores_decisao:\n",
    "        \n",
    "        #Adicionar à Lista de Importâncias as Importâncias das Variáveis calculada por cada Árvore de Decisão:\n",
    "        importancias_arvores_decisao.append(arvore_decisao.feature_importances_)\n",
    "\n",
    "#Calcular o Desvio Padrão das Importâncias de cada Variável:\n",
    "desvios_padrao: list[float] = list(std(importancias_arvores_decisao, axis=0))\n",
    "\n",
    "#Obter as Importâncias Médias das Variáveis do Melhor Modelo de Gradient Boosting:\n",
    "importancias_medias = melhor_modelo_gradient_boosting.feature_importances_\n",
    "\n",
    "#Obter os Índices das Variáveis Ordenados por Importância Decrescente:\n",
    "indices_variaveis: list[int] = argsort(importancias_medias)[::-1]\n",
    "\n",
    "#Extrair as Variáveis:\n",
    "variaveis = X_treino.columns.tolist()\n",
    "\n",
    "#Iniciar uma Lista para Armazenar os Nomes das Variáveis:\n",
    "nomes_variaveis: list[str] = []\n",
    "\n",
    "#Iniciar uma Lista para Armazenar os Valores das Importâncias:\n",
    "valores_importancia: list[float] = []\n",
    "\n",
    "#Iterar sobre o Índice de cada Variável:\n",
    "for indice in range(len(variaveis)):\n",
    "    \n",
    "    #Adicionar o Nome da Variável correspondente ao Índice Ordenado à Lista de Nomes das Variáveis:\n",
    "    nomes_variaveis.append(variaveis[indices_variaveis[indice]])\n",
    "    \n",
    "    #Adicionar à Lista de Importâncias o Valor da Importância de cada Variável:\n",
    "    valores_importancia.append(importancias_medias[indices_variaveis[indice]])\n",
    "\n",
    "#Exibir o Cabeçalho das Importâncias das Variáveis:\n",
    "print(\"\\nImportâncias das Variáveis:\")\n",
    "\n",
    "#Iterar sobre cada variavel Ordenada pelo Índice:\n",
    "for indice, variavel in enumerate(nomes_variaveis):\n",
    "    \n",
    "    #Exibir o Ranking da Variável, o Valor da respetiva Importância e o Desvio Padrão:\n",
    "    print(f\"{indice + 1}. {variavel}: {valores_importancia[indice]:.4f} (± {desvios_padrao[indice]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c3692",
   "metadata": {},
   "source": [
    "<H5>4.5.10 - Modelo de Gradient Boosting - Importância de cada Variável - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir as Variáveis:\n",
    "variaveis = ['Humidade_15h', 'Precipitacao', 'Velocidade_Rajada_Vento', 'Nuvens_15h', 'Pressao_Atmosferica_15h', 'Sol', 'Chuva_Hoje', 'Direcao_Vento_15h_Cos',\n",
    "             'Nuvens_09h', 'Direcao_Vento_09h_Cos', 'Mes', 'Direcao_Vento_15h_Sin', 'Ano', 'Direcao_Rajada_Vento_Sin', 'Local_Long', 'Direcao_Rajada_Vento_Cos',\n",
    "             'Local_Lat', 'Local_Alt', 'Direcao_Vento_09h_Sin', 'Velocidade_Vento_15h', 'Temperatura_Minima', 'Dia', 'Temperatura_15h', 'Temperatura_Maxima', 'Temperatura_09h',\n",
    "             'Pressao_Atmosferica_09h', 'Humidade_09h', 'Evaporacao', 'Velocidade_Vento_09h']\n",
    "\n",
    "#Definir os Valores da Importância de cada variavel:\n",
    "valores_importancia_variavel = [0.4530, 0.1108, 0.0881, 0.0729, 0.0599, 0.0509, 0.0369, 0.0331, 0.0239, 0.0183, 0.0138, 0.0074, 0.0055, 0.0052, 0.0046, 0.0040, 0.0030,\n",
    "                                0.0020, 0.0019, 0.0019, 0.0018, 0.0009, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "#Configurações das Barras - Cores, Tamanho das Extremidades e Estilo da Linha:\n",
    "barras = plt.bar(variaveis, valores_importancia_variavel, color='#2ca02c', capsize=5, ecolor='#ff7f0e', linestyle='-')\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho e Espaçamento:\n",
    "plt.title('Conjunto de Dados 1 - Importância das Variáveis para o Modelo de Gradient Boosting', fontsize=15, pad=20)\n",
    "\n",
    "#Iterar sobre cada Barra:\n",
    "for barra in barras:\n",
    "    altura_barra = barra.get_height()\n",
    "    plt.text(barra.get_x() + barra.get_width()/2, altura_barra + 0.00, f'{altura_barra:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanho, Cores, Rotação e Posição:\n",
    "plt.xlabel('Variáveis', fontsize=15)\n",
    "plt.xticks(color='black', rotation=45, ha='right') \n",
    "plt.gca().xaxis.set_tick_params(color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanho, Cores, Limites Mínimo e Máximo, Incremento e Rotação:\n",
    "plt.ylabel('Importância', fontsize=15)\n",
    "plt.gca().yaxis.set_tick_params(color='black')\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), ['{:.2f}'.format(x) for x in np.arange(0, 1.1, 0.2)])\n",
    "plt.yticks(color='black', rotation=0)  \n",
    "plt.ylim(0, 1)\n",
    "\n",
    "#Configurar as Margens dos Eixos - Cor, Espessura e remover superior e direita:\n",
    "eixo_atual = plt.gca()\n",
    "for lado in ['bottom', 'left']:\n",
    "    eixo_atual.spines[lado].set_color('black')\n",
    "    eixo_atual.spines[lado].set_linewidth(2.5)\n",
    "for lado in ['top', 'right']:\n",
    "    eixo_atual.spines[lado].set_visible(False)\n",
    "\n",
    "#Ajustar o Layout:\n",
    "plt.tight_layout()\n",
    "\n",
    "#Resultados - Exibir o Gráfico de Barras:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f632066",
   "metadata": {},
   "source": [
    "<H5>4.6 - Modelo de Percetrão Multicamadas:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132732f5",
   "metadata": {},
   "source": [
    "<H5><H5>4.6.1 - Modelo de Percetrão Multicamadas - Métrica de Avaliação Sensibilidade em Função dos Parâmetros Tipo de Taxa de Aprendizagem, Taxa de Aprendizagem e Número de Iterações - Resultados:</H5></H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir da Biblioteca Numerical Python, Importar as Estruturas de Dados:\n",
    "from numpy import array, ndarray\n",
    "\n",
    "#A partir do Typing, Importar os Tipos Literais para Restrição de Valores Específicos:\n",
    "from typing import Literal\n",
    "\n",
    "#A partir da SKLearn.Neural_Network, Importar o Modelo de Percetrão Multicamadas:\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "#A partir das Funções do DSLabs, Importar as 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1), Mínimo Necessário para Melhoria e Função Ler Conjuntos de Treino e de Teste:\n",
    "from dslabs_functions import (CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files)\n",
    "\n",
    "#Função para Estudo do Modelo de Percetrão Multicamadas com Diferentes Configurações:\n",
    "def funcao_estudo_modelo_percetrao_multicamadas(X_treino: ndarray, Y_treino: array, X_teste: ndarray, Y_teste: array, iteracoes_maximas: int = 1000, intervalo: int = 250, metrica: str = \"recall\") -> tuple[MLPClassifier | None, dict]:\n",
    "    \n",
    "    #Dicionário para Mostrar os Nomes das Taxas de Aprendizagem:\n",
    "    nomes_taxas_aprendizagem = {\"constant\": \"Constante\", \"invscaling\": \"Escala Inversa\", \"adaptive\": \"Adaptativa\"}\n",
    "\n",
    "    #Criar Lista de Iterações a Testar:\n",
    "    numeros_iteracoes: list[int] = [intervalo] + [i for i in range(2 * intervalo, iteracoes_maximas + 1, intervalo)]\n",
    "\n",
    "    #Definir os Tipos de Taxas de Aprendizagem:\n",
    "    tipos_taxas_aprendizagem: list[Literal[\"constant\", \"invscaling\", \"adaptive\"]] = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "    #Definir as Taxas de Aprendizagem:\n",
    "    taxas_aprendizagem: list[float] = [0.5, 0.05, 0.005, 0.0005]\n",
    "\n",
    "    #Variável para Guardar o Melhor Modelo de Percetrão Multicamadas:\n",
    "    melhor_modelo_percetrao_multicamadas: MLPClassifier | None = None\n",
    "\n",
    "    #Dicionário para Guardar os Melhores Parâmetros:\n",
    "    melhores_parametros: dict = {\"nome\": \"MLP\", \"métrica\": metrica, \"parâmetros\": ()} \n",
    "\n",
    "    #Variável para Armazenar o Melhor Desempenho:\n",
    "    melhor_desempenho: float = 0.0\n",
    "\n",
    "    #Dicionário para Armazenar os Resultados de cada Configuração:\n",
    "    resultados: dict = {}  \n",
    "\n",
    "    #Iterar pelos Tipos de Taxas de Aprendizagem:\n",
    "    for tipo_taxa_aprendizagem in tipos_taxas_aprendizagem:\n",
    "        \n",
    "        #Iniciar o Subdicionário para o Tipo de Taxa de Aprendizagem:\n",
    "        resultados[tipo_taxa_aprendizagem] = {}\n",
    "        \n",
    "        #Iterar pelos Valores de Taxa de Aprendizagem:\n",
    "        for taxa_aprendizagem in taxas_aprendizagem:\n",
    "            \n",
    "            #Lista para Armazenar os Resultados da Métrica no Conjunto de Teste:\n",
    "            valores_y_teste: list[float] = []  \n",
    "            \n",
    "            #Iterar pelos Números de Iterações:\n",
    "            for numero_iteracoes in numeros_iteracoes:\n",
    "                \n",
    "                #Criar e Configurar o Modelo de Percetrão Multicamadas:\n",
    "                modelo_percetrao_multicamadas = MLPClassifier(learning_rate=tipo_taxa_aprendizagem, learning_rate_init=taxa_aprendizagem, max_iter=numero_iteracoes, warm_start=False, activation=\"logistic\",  \n",
    "                                    solver=\"sgd\", verbose=False)\n",
    "\n",
    "                #Treinar o Modelo no Conjunto de Treino:\n",
    "                modelo_percetrao_multicamadas.fit(X_treino, Y_treino)  \n",
    "                \n",
    "                #Prever os Resultados no Conjunto de Teste:\n",
    "                previsoes_teste: array = modelo_percetrao_multicamadas.predict(X_teste)  \n",
    "                \n",
    "                #Calcular a Métrica de Avaliação:\n",
    "                metrica_avaliacao: float = CLASS_EVAL_METRICS[metrica](Y_teste, previsoes_teste)\n",
    "                \n",
    "                #Adicionar o Resultado à Lista de Métricas:\n",
    "                valores_y_teste.append(metrica_avaliacao)  \n",
    "                \n",
    "                #Se o Desempenho for Superior ao Desempenho Anterior:\n",
    "                if metrica_avaliacao - melhor_desempenho > DELTA_IMPROVE:\n",
    "                    melhor_desempenho = metrica_avaliacao\n",
    "                    melhores_parametros[\"parâmetros\"] = (tipo_taxa_aprendizagem, taxa_aprendizagem, numero_iteracoes)\n",
    "                    melhor_modelo_percetrao_multicamadas = modelo_percetrao_multicamadas\n",
    "            \n",
    "            #Guardar os Resultados da Melhor Configuração:\n",
    "            resultados[tipo_taxa_aprendizagem][taxa_aprendizagem] = valores_y_teste\n",
    "\n",
    "    #Mostrar o Melhor Modelo de Percetrão Multicamadas:\n",
    "    tipo_taxa_aprendizagem = nomes_taxas_aprendizagem[melhores_parametros[\"parâmetros\"][0]]\n",
    "    print(f'Melhor Modelo de Percetrão Multicamadas: Tipo de Taxa de Aprendizagem {tipo_taxa_aprendizagem}, Taxa de Aprendizagem = {melhores_parametros[\"parâmetros\"][1]} e Número de Iterações = {melhores_parametros[\"parâmetros\"][2]}')\n",
    "    \n",
    "    #Iterar pelos Tipos de Taxa de Aprendizagem:\n",
    "    for tipo_taxa_aprendizagem, valores_taxa_aprendizagem in resultados.items():  \n",
    "        tipo_taxa_aprendizagem = nomes_taxas_aprendizagem[tipo_taxa_aprendizagem]\n",
    "        print(f\"\\nTipo de Taxa de Aprendizagem: {tipo_taxa_aprendizagem}\")\n",
    "        \n",
    "        #Iterar pelos Valores de Taxa de Aprendizagem:\n",
    "        for taxa_aprendizagem, sensibilidades in valores_taxa_aprendizagem.items():  \n",
    "            print(f\"  Taxa de Aprendizagem: {taxa_aprendizagem}\")\n",
    "            \n",
    "            #Iterar pelos Números das Iterações:\n",
    "            for i, sensibilidade in enumerate(sensibilidades):  \n",
    "                print(f\"    Iteração Número {numeros_iteracoes[i]}: Sensibilidade = {sensibilidade:.2f}\")\n",
    "    \n",
    "    #Devolver o Melhor Modelo e os Melhores Parâmetros:\n",
    "    return melhor_modelo_percetrao_multicamadas, melhores_parametros\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = \"conjunto_treino_balanceado_sobreamostragem_SMOTE.csv\" \n",
    "conjunto_teste = \"conjunto_teste_normalizado_z-score.csv\"\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = \"Chuva_Amanha\"\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "X_treino, X_teste, Y_treino, Y_teste, labels, variáveis = read_train_test_from_files(conjunto_treino, conjunto_teste, variavel_alvo)\n",
    "\n",
    "#Definir a Métrica de Avaliação (Sensibilidade):\n",
    "metrica_avaliacao = \"recall\"\n",
    "\n",
    "#Executar a Função de Estudo do Modelo de Percetrão Multicamadas:\n",
    "melhor_modelo_percetrao_multicamadas, parametros = funcao_estudo_modelo_percetrao_multicamadas(X_treino, Y_treino, X_teste, Y_teste, iteracoes_maximas=1000, intervalo=250, metrica=metrica_avaliacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596f4fd",
   "metadata": {},
   "source": [
    "<H5>4.6.2 - Modelo de Percetrão Multicamadas - Métrica de Avaliação Sensibilidade em Função dos Números Máximos de Iterações, Tipos de Taxa de Aprendizagem e Taxas de Aprendizagem - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c07685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy as np\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Definir os Números de Iterações:\n",
    "numeros_iteracoes = [250, 500, 750, 1000]\n",
    "\n",
    "#Valores das Sensibilidades por Tipo de Taxa de Aprendizagem:\n",
    "sensibilidades_tipos_taxas_aprendizagem = {\n",
    "    \"taxa_aprendizagem_constante\": {0.5:[0.77,0.80,0.66,0.72], 0.05:[0.72,0.69,0.74,0.70], 0.005:[0.75,0.75,0.72,0.72], 0.0005:[0.76,0.76,0.76,0.76]},\n",
    "    \"taxa_aprendizagem_escala_inversa\": {0.5:[0.78,0.78,0.78,0.78], 0.05:[0.76,0.76,0.76,0.76], 0.005:[0.75,0.76,0.76,0.76], 0.0005:[0.76,0.71,0.73,0.77]},\n",
    "    \"taxa_aprendizagem_adaptativa\": {0.5:[0.73,0.72,0.71,0.74], 0.05:[0.70,0.70,0.70,0.68], 0.005:[0.77,0.76,0.73,0.72], 0.0005:[0.76,0.76,0.76,0.76]}}\n",
    "\n",
    "#Função para Configurar e Criar os Gráficos de Linhas:\n",
    "def funcao_configurar_criar_graficos_linhas(subplot_posicao, resultados, titulo, numeros_iteracoes, cores):\n",
    "    plt.subplot(1, 3, subplot_posicao)\n",
    "    for taxa, valores in resultados.items():\n",
    "        plt.plot(numeros_iteracoes, valores, label=f'Taxa de Aprendizagem = {taxa}', color=cores[taxa], marker='o')\n",
    "    \n",
    "    #Configurações dos Gráficos de Linhas - Tamanho, Espaçamento e Ativar Linhas de Grelha:\n",
    "    plt.title(titulo, fontsize=14, pad=20)\n",
    "    plt.grid(True)\n",
    "\n",
    "    #Configurações do Eixo X - Título, Tamanhos e Limites Mínimo e Máximo:\n",
    "    plt.xlabel('Números de Iterações', fontsize=14)\n",
    "    plt.xticks(numeros_iteracoes, fontsize=14)\n",
    "    plt.xlim(min(numeros_iteracoes), max(numeros_iteracoes))\n",
    "    \n",
    "    #Configurações do Eixo Y - Título, Tamanhos, Limites Mínimo e Máximo, Incremento e Ajustes:\n",
    "    plt.ylabel('Sensibilidade', fontsize=14)\n",
    "    valores_Y = np.arange(0.0, 1.1, 0.20)\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.yticks(valores_Y, [f'{i:.2f}' for i in valores_Y], fontsize=14)\n",
    "    \n",
    "    #Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "    eixos_atuais = plt.gca()\n",
    "    for eixo in ['left', 'bottom']:\n",
    "        eixos_atuais.spines[eixo].set(color='black', linewidth=2.5)\n",
    "    for eixo in ['top', 'right']:\n",
    "        eixos_atuais.spines[eixo].set_visible(False)\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "#Configurações dos Gráficos de Linhas - Tamanho, Títulos, Cores e Espaçamentos:\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.suptitle('Conjunto de Dados 1 - Conjunto de Teste\\nAnálise da Sensibilidade para diferentes Parametrizações do Modelo de Percetrão Multicamadas',\n",
    "    fontsize=16, y=1.05)\n",
    "titulos_individuais = {\"taxa_aprendizagem_constante\": \"Taxa de Aprendizagem Constante\", \"taxa_aprendizagem_escala_inversa\": \"Taxa de Aprendizagem Escala Inversa\", \"taxa_aprendizagem_adaptativa\": \"Taxa de Aprendizagem Adaptativa\"}\n",
    "cores_linhas = {0.5: '#2ca02c', 0.05: '#ff7f0e', 0.005: '#87CEEB', 0.0005: '#ffdd57'}\n",
    "plt.subplots_adjust(top=0.85, hspace=0.7, wspace=0.3)\n",
    "\n",
    "#Resultados - Gráficos de Linhas:\n",
    "for numero_iteracoes, (tipo, resultados) in enumerate(sensibilidades_tipos_taxas_aprendizagem.items(), 1):\n",
    "    funcao_configurar_criar_graficos_linhas(subplot_posicao=numero_iteracoes, resultados=resultados, titulo=titulos_individuais[tipo], numeros_iteracoes=numeros_iteracoes, cores=cores_linhas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8e697",
   "metadata": {},
   "source": [
    "<H5>4.6.3 - Modelo de Percetrão Multicamadas - Curva de Perda - Resultados e Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29357265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.PyPlot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar as Formatações:\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#A partir do SKLearn.Neural_Network, Importar o Modelo de Percetrão Multicamadas:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "X_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "X_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Separar as Variáveis Preditoras e a Variável Alvo:\n",
    "Y_treino = X_treino.pop(variavel_alvo)\n",
    "Y_teste = X_teste.pop(variavel_alvo)\n",
    "\n",
    "#Função para Formatar os Resultados:\n",
    "def funcao_formatar_resultados():\n",
    "    for numero_iteracoes, perda in enumerate(melhor_modelo_percetrao_multicamadas.loss_curve_):\n",
    "        print(f\"Iteração Número {numero_iteracoes}: Perda = {perda:.2f}\")\n",
    "\n",
    "#Definir o Melhor Modelo de Percetrão Multicamadas (Número Máximo de Iterações, Tipo de Taxa de Aprendizagem, Taxa de Aprendizagem):\n",
    "melhor_modelo_percetrao_multicamadas = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, learning_rate='invscaling', learning_rate_init=0.05, verbose=False, random_state=1)\n",
    "\n",
    "#Treinar o Melhor Modelo de Percetrão Multicamadas no Conjunto de Treino:\n",
    "melhor_modelo_percetrao_multicamadas.fit(X_treino, Y_treino)\n",
    "\n",
    "#Prever os Resultados no Conjunto de Teste:\n",
    "Y_previsto = melhor_modelo_percetrao_multicamadas.predict(X_teste)\n",
    "\n",
    "#Espaço:\n",
    "print()\n",
    "\n",
    "#Última Iteração com Dados da Perda:\n",
    "funcao_formatar_resultados()\n",
    "ultima_iteracao = len(melhor_modelo_percetrao_multicamadas.loss_curve_) - 1\n",
    "print(f\"\\nÚltima Iteração com Dados de Perda = {ultima_iteracao}\")\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Cor e Grelha: \n",
    "matplotlib.pyplot.figure(figsize=(12, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Curva de Perda para o Melhor Modelo de Percetrão Multicamadas\\n\\n''(Taxa de Aprendizagem Escala Inversa, Taxa de Aprendizagem = 0.05)\\n', \n",
    "    fontsize=16)\n",
    "matplotlib.pyplot.plot(melhor_modelo_percetrao_multicamadas.loss_curve_, color='#2ca02c')\n",
    "matplotlib.pyplot.grid()\n",
    "\n",
    "#Configurações do Eixo X - Título, Tamanhos, Limites Mínimo e Máximo e Incremento:\n",
    "matplotlib.pyplot.xlabel('Número de Iterações', fontsize=14)\n",
    "matplotlib.pyplot.xticks(range(0, 66, 5), fontsize=14)\n",
    "matplotlib.pyplot.xlim(0, 55)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Perda', fontsize=14)\n",
    "valores_y = numpy.arange(0.39, 0.45 + 0.01, 0.01)\n",
    "matplotlib.pyplot.yticks(valores_y, [f\"{y:.3f}\" for y in valores_y], fontsize=14)\n",
    "matplotlib.pyplot.ylim(0.39, 0.45)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.3f}'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['left', 'bottom']:\n",
    "    eixos_atuais.spines[margem].set(linewidth=2.5, edgecolor='black')\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_visible(False)\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249584a",
   "metadata": {},
   "source": [
    "<H5>4.6.4 - Modelo de Percetrão Multicamadas - Estudo de Overfitting - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neural_Network, Importar o Modelo de Percetrão Multicamadas:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Métrica de Avaliação Sensibilidade:\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Definir a Variável Alvo (Chuva_Amanha):\n",
    "variavel_alvo = 'Chuva_Amanha'\n",
    "\n",
    "#Separar as Variáveis Preditoras da Variável Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino = conjunto_treino.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_treino = conjunto_treino[variavel_alvo]\n",
    "\n",
    "#Separar as Variáveis Preditoras da Variável Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste = conjunto_teste.drop(variavel_alvo, axis=1)\n",
    "variavel_alvo_teste = conjunto_teste[variavel_alvo]\n",
    "\n",
    "#Definir os Números de Iterações - Limites Mínimo e Máximo e Intervalo:\n",
    "numeros_iteracoes = range(100, 1100, 100)\n",
    "\n",
    "#Definir o Tipo de Taxa de Aprendizagem (Escala Inversa):\n",
    "tipo_taxa_aprendizagem = \"invscaling\"\n",
    "\n",
    "#Definir a Taxa de Aprendizagem (0.05):\n",
    "taxa_aprendizagem = 0.05\n",
    "\n",
    "#Iteração sobre Diferentes Números de Iterações do Modelo de Percetrão Multicamadas:\n",
    "for numero_iteracoes in numeros_iteracoes:\n",
    "    \n",
    "    #Configurar e Iniciar o Melhor Modelo de Percetrão Multicamadas:\n",
    "    melhor_modelo_percetrao_multicamadas = MLPClassifier(learning_rate=tipo_taxa_aprendizagem, learning_rate_init=taxa_aprendizagem, max_iter=numero_iteracoes, activation=\"logistic\", solver=\"sgd\", verbose=False, random_state=1)\n",
    "\n",
    "    #Treinar o Melhor Modelo de Percetrão Multicamadas no Conjunto de Treino:\n",
    "    melhor_modelo_percetrao_multicamadas.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "    #Criar Previsões para o Conjunto de Treino:\n",
    "    previsoes_treino = melhor_modelo_percetrao_multicamadas.predict(variaveis_preditoras_treino)\n",
    "    \n",
    "    #Criar Previsões para o Conjunto de Teste:\n",
    "    previsoes_teste = melhor_modelo_percetrao_multicamadas.predict(variaveis_preditoras_teste)\n",
    "\n",
    "    #Calcular a Métrica de Avaliação Sensibilidade para os Conjuntos de Treino e de Teste:\n",
    "    sensibilidade_conjunto_treino = recall_score(variavel_alvo_treino, previsoes_treino)\n",
    "    sensibilidade_conjunto_teste = recall_score(variavel_alvo_teste, previsoes_teste)\n",
    "\n",
    "    #Resultados - Número de Iterações e Valores da Sensibilidade para os Conjuntos de Treino e de Teste:\n",
    "    print(f\"Número de Iterações = {numero_iteracoes}\")\n",
    "    print(f\"Sensibilidade - Conjunto de Treino = {sensibilidade_conjunto_treino:.2f}\")\n",
    "    print(f\"Sensibilidade - Conjunto de Teste = {sensibilidade_conjunto_teste:.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e2a82",
   "metadata": {},
   "source": [
    "<H5>4.6.5 - Modelo Classificador Percetrão Multicamadas - Estudo de Overfitting - Gráfico de Linhas:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#Definir os Números de Iterações:\n",
    "numeros_iteracoes = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "#Definir as Sensibilidades do Conjunto de Treino:\n",
    "sensibilidades_treino = [0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77]\n",
    "\n",
    "#Definir as Sensibilidades do Conjunto de Teste:\n",
    "sensibilidades_teste = [0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76]\n",
    "\n",
    "#Configurações do Gráfico de Linhas - Tamanhos, Título Geral, Legenda de Cores e Grelha:\n",
    "matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\n Estudo de Overfitting para o Modelo de Percetrão Multicamadas\\n\\n(Taxa de Aprendizagem Escala Inversa, Taxa de Aprendizagem = 0.05)\\n', fontsize=16)\n",
    "matplotlib.pyplot.plot(numeros_iteracoes, sensibilidades_treino, label='Conjunto de Treino', color='#2ca02c')\n",
    "matplotlib.pyplot.plot(numeros_iteracoes, sensibilidades_teste, label='Conjunto de Teste', color='#ff7f0e')\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.grid()\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanhos e Limites Mínimo e Máximo:\n",
    "matplotlib.pyplot.xlabel('Números de Iterações', fontsize=14)\n",
    "matplotlib.pyplot.xticks(numeros_iteracoes, fontsize=12)\n",
    "matplotlib.pyplot.xlim(100, 1000)\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanhos, Valores e Limites Mínimo e Máximo:\n",
    "matplotlib.pyplot.ylabel('Sensibilidade', fontsize=14)\n",
    "matplotlib.pyplot.yticks([round(i * 0.20, 2) for i in range(6)], fontsize=12)\n",
    "matplotlib.pyplot.gca().set_yticklabels([f\"{y:.2f}\" for y in matplotlib.pyplot.yticks()[0]])\n",
    "matplotlib.pyplot.ylim(0, 1)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos.spines[margem].set_color('black')\n",
    "    eixos.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos.spines[margem].set_color('none')\n",
    "\n",
    "#Resultados - Gráfico de Linhas:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e444a",
   "metadata": {},
   "source": [
    "<H5>4.6.6 - Modelo de Percetrão Multicamadas - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Resultados:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:\n",
    "import pandas\n",
    "\n",
    "#A partir do SKLearn.Neural_Network, Importar o Modelo de Percetrão Multicamadas:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar as 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#Calcular as 5 Métricas de Avaliação:\n",
    "def funcao_calcular_metricas(Y_real, Y_previsto, Y_probabilidades):\n",
    "    exatidao = accuracy_score(Y_real, Y_previsto)\n",
    "    sensibilidade = recall_score(Y_real, Y_previsto)\n",
    "    precisao = precision_score(Y_real, Y_previsto)\n",
    "    auc = roc_auc_score(Y_real, Y_probabilidades[:, 1])\n",
    "    f1 = f1_score(Y_real, Y_previsto)\n",
    "    \n",
    "    print(f\"Exatidão: {exatidao:.2f}\")\n",
    "    print(f\"Sensibilidade: {sensibilidade:.2f}\")\n",
    "    print(f\"Precisão: {precisao:.2f}\")\n",
    "    print(f\"AUC: {auc:.2f}\")\n",
    "    print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Treino:\n",
    "X_treino = conjunto_treino.drop(columns=['Chuva_Amanha'])\n",
    "Y_treino = conjunto_treino['Chuva_Amanha']\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Teste:\n",
    "X_teste = conjunto_teste.drop(columns=['Chuva_Amanha'])\n",
    "Y_teste = conjunto_teste['Chuva_Amanha']\n",
    "\n",
    "#Configurar o Melhor Modelo de Percetrão Multicamadas - Número Máximo de Iterações, Tipo de Taxa de Aprendizagem, Taxa de Aprendizagem, Ativação e Otimizador:\n",
    "melhor_modelo_percetrao_multicamadas = MLPClassifier(max_iter=500, learning_rate='invscaling', learning_rate_init=0.05, activation='logistic', solver='sgd', verbose=False)\n",
    "\n",
    "#Treinar o Melhor Modelo de Percetrão Multicamadas no Conjunto de Treino:\n",
    "melhor_modelo_percetrao_multicamadas.fit(X_treino, Y_treino)\n",
    "\n",
    "#Fazer Previsões nos Conjuntos de Treino e de Teste:\n",
    "Y_treino_previsto = melhor_modelo_percetrao_multicamadas.predict(X_treino)\n",
    "Y_teste_previsto = melhor_modelo_percetrao_multicamadas.predict(X_teste)\n",
    "\n",
    "#Obter as Probabilidades dos Conjuntos de Treino e de Teste para Calcular a Métrica de Avaliação AUC:\n",
    "Y_treino_probabilidades_auc = melhor_modelo_percetrao_multicamadas.predict_proba(X_treino)\n",
    "Y_teste_probabilidades_auc = melhor_modelo_percetrao_multicamadas.predict_proba(X_teste)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Treino:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Treino:\")\n",
    "funcao_calcular_metricas(Y_treino, Y_treino_previsto, Y_treino_probabilidades_auc)\n",
    "\n",
    "#Resultados - 5 Métricas de Avaliação - Conjunto de Teste:\n",
    "print(\"\\n5 Métricas de Avaliação - Conjunto de Teste:\")\n",
    "funcao_calcular_metricas(Y_teste, Y_teste_previsto, Y_teste_probabilidades_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03505999",
   "metadata": {},
   "source": [
    "<H5>4.6.7 - Modelo Classificador Percetrão Multicamadas - Conjunto de Treino vs Conjunto de Teste - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ae0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatações:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Melhor Modelo de Percetrão Multicamadas - Conjunto de Treino vs Conjunto de Teste:\n",
    "melhor_modelo_percetrao_multicamadas_treino_teste = ['Melhor Modelo de Percetrão Multicamadas - Conjunto de Treino', 'Melhor Modelo de Percetrão Multicamadas - Conjunto de Teste']\n",
    "\n",
    "#Resultados das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.78, 0.78]\n",
    "sensibilidade = [0.77, 0.76]\n",
    "precisao = [0.78, 0.50]\n",
    "auc = [0.86, 0.86]\n",
    "f1 = [0.78, 0.60]\n",
    "\n",
    "#Configurações do Gráfico de Barras - Tamanhos, Título Geral, Espaçamento, Cor, Grelha e Layout:\n",
    "matplotlib.pyplot.figure(figsize=(12, 7))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Treino vs Conjunto de Teste\\n\\nComparação das 5 Métricas de Avaliação do Melhor Modelo de Percetrão Multicamadas\\n\\n(Taxa de Aprendizagem Escala Inversa, Taxa de Aprendizagem = 0.05, Número de Iterações = 500)', fontsize=16, pad=20, color='black')\n",
    "matplotlib.pyplot.grid(False)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Índice, Largura, Cores, Deslocamento e Valores:\n",
    "indice_barras = numpy.arange(len(melhor_modelo_percetrao_multicamadas_treino_teste)) * 1.4\n",
    "largura_barras = 0.15\n",
    "cores_barras = {\"Exatidão\": (exatidao, '#ff7f0e'), \"Sensibilidade\": (sensibilidade, '#ffdd57'), \"Precisão\": (precisao, '#2ca02c'), \"AUC\": (auc, '#87CEEB'), \"F1\": (f1, '#9467bd')}\n",
    "deslocamento_barras = 0\n",
    "for nome_metrica, (valores, cor) in cores_barras.items():\n",
    "    barras_atual = matplotlib.pyplot.bar(indice_barras + deslocamento_barras, valores, largura_barras, label=nome_metrica, color=cor)\n",
    "    for barra in barras_atual:\n",
    "        altura_y = barra.get_height()\n",
    "        matplotlib.pyplot.text(barra.get_x() + barra.get_width() / 2, altura_y, f'{altura_y:.2f}', ha='center', va='bottom', color='black', fontsize=14)\n",
    "    deslocamento_barras += largura_barras\n",
    "\n",
    "#Configurações do Eixo X - Tamanho, Rotação, Posição e Cor:\n",
    "matplotlib.pyplot.xticks(indice_barras + 2 * largura_barras, melhor_modelo_percetrao_multicamadas_treino_teste, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Título, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo, Incremento e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=14)\n",
    "matplotlib.pyplot.gca().yaxis.set_ticks(numpy.arange(0, 1.1, 0.20))\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixos_atuais = matplotlib.pyplot.gca()\n",
    "for margem in ['bottom', 'left']:\n",
    "    eixos_atuais.spines[margem].set_color('black')\n",
    "    eixos_atuais.spines[margem].set_linewidth(2.5)\n",
    "for margem in ['top', 'right']:\n",
    "    eixos_atuais.spines[margem].set_color('none')\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanhos, Título e Cores:\n",
    "legenda = matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=12, frameon=True, title=\"5 Métricas de Avaliação:\", title_fontsize=12)\n",
    "legenda.get_frame().set_edgecolor('grey')\n",
    "legenda.get_frame().set_facecolor('none')\n",
    "legenda.get_title().set_color('black')\n",
    "\n",
    "#Resultados - Gráfico de Barras:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0f71c",
   "metadata": {},
   "source": [
    "<H5>4.6.8 - Modelo de Percetrão Multicamadas - Conjunto de Teste - Matriz de Confusão:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d63e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Pandas:  \n",
    "import pandas\n",
    "\n",
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do SKLearn.Neural_Network, Importar o Modelo de Percetrão Multicamadas:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#A partir do SKLearn.Metrics, Importar a Matriz de Confusão:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Importar a Biblioteca Seaborn:\n",
    "import seaborn\n",
    "\n",
    "#Ler os Conjuntos de Treino e de Teste:\n",
    "conjunto_treino = pandas.read_csv('conjunto_treino_balanceado_sobreamostragem_SMOTE.csv')\n",
    "conjunto_teste = pandas.read_csv('conjunto_teste_normalizado_z-score.csv')\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Treino:\n",
    "variaveis_preditoras_treino = conjunto_treino.iloc[:, :-1]\n",
    "variavel_alvo_treino = conjunto_treino.iloc[:, -1]\n",
    "\n",
    "#Dividir os Dados em Variáveis Preditoras e Variável Alvo para o Conjunto de Teste:\n",
    "variaveis_preditoras_teste = conjunto_teste.iloc[:, :-1]\n",
    "variavel_alvo_teste = conjunto_teste.iloc[:, -1]\n",
    "\n",
    "#Definir o Melhor Modelo de Percetrão Multicamadas - Número Máximo de Iterações e Otimizador:\n",
    "melhor_modelo_percetrao_multicamadas = MLPClassifier(max_iter=500, hidden_layer_sizes=(100,), solver='sgd', random_state=42)\n",
    "\n",
    "#Treinar o Melhor Modelo de Percetrão Multicamadas no Conjunto de Treino:\n",
    "melhor_modelo_percetrao_multicamadas.fit(variaveis_preditoras_treino, variavel_alvo_treino)\n",
    "\n",
    "#Fazer as Previsões no Conjunto de Teste:\n",
    "variavel_alvo_prevista_teste = melhor_modelo_percetrao_multicamadas.predict(variaveis_preditoras_teste)\n",
    "\n",
    "#Calcular a Matriz de Confusão:\n",
    "matriz_confusao = confusion_matrix(variavel_alvo_teste, variavel_alvo_prevista_teste)\n",
    "\n",
    "#Configurações do Gráfico da Matriz de Confusão - Tamanhos, Título Geral, Cor, Escala de Cores, Limites Mínimo e Máximo, Incremento, Fundo e Valores:\n",
    "matplotlib.pyplot.figure(figsize=(8, 6))\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nMatriz de Confusão - Melhor Modelo de Percetrão Multicamadas\\n\\n(Taxa de Aprendizagem Escala Inversa, Taxa de Aprendizagem = 0.05, Número de Iterações = 500)\\n', color='black', fontsize=16)\n",
    "mapa_calor_matriz_confusao = seaborn.heatmap(matriz_confusao, annot=False, fmt='d', cmap='Greens', vmin=0, vmax=30000, xticklabels=numpy.unique(variavel_alvo_teste), yticklabels=numpy.unique(variavel_alvo_teste), cbar=True, linewidths=0.5)\n",
    "escala_cores = mapa_calor_matriz_confusao.collections[0].colorbar\n",
    "escala_cores.ax.yaxis.set_tick_params(color='black')\n",
    "valores = numpy.arange(0, 30000 + 2000, 2000)\n",
    "escala_cores.set_ticks(valores)\n",
    "escala_cores.ax.set_yticklabels([f\"{int(valor):,}\".replace(',', '.') for valor in valores], color='black')\n",
    "matplotlib.pyplot.gca().set_facecolor('#2ca02c')\n",
    "for linha in range(matriz_confusao.shape[0]):\n",
    "    for coluna in range(matriz_confusao.shape[1]):\n",
    "        matplotlib.pyplot.text(coluna + 0.5, linha + 0.5, f\"{matriz_confusao[linha, coluna]:,}\".replace(',', '.'), color='#ff7f0e', ha='center', va='center', fontsize=16)\n",
    "\n",
    "#Configurações do Eixo X - Título, Cores, Tamanhos, Espaçamento e Valores:\n",
    "matplotlib.pyplot.xlabel('Rótulo Previsto', color='black', fontsize=14, labelpad=10)\n",
    "matplotlib.pyplot.xticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13)\n",
    "\n",
    "#Configurações do Eixo Y - Título, Cores, Tamanhos, Valores e Rotação:\n",
    "matplotlib.pyplot.ylabel('Verdadeiro Rótulo', color='black', fontsize=14)\n",
    "matplotlib.pyplot.yticks(ticks=[0.5, 1.5], labels=['Não Vai Chover Amanhã', 'Vai Chover Amanhã'], color='black', fontsize=13, rotation=0)\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor:\n",
    "for margem in matplotlib.pyplot.gca().spines.values():\n",
    "    margem.set_color('black')\n",
    "\n",
    "#Resultados - Matriz de Confusão:\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0a04f",
   "metadata": {},
   "source": [
    "<H5>4.7 - Comparação dos Modelos de Naïve Bayes, KNN, Árvores de Decisão, Florestas Aleatórias, Gradient Boosting e Percetrão Multicamadas - 5 Métricas de Avaliação - Gráfico de Barras:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar a Biblioteca Numerical Python:\n",
    "import numpy\n",
    "\n",
    "#Importar o Matplotlib.Pyplot:\n",
    "import matplotlib.pyplot\n",
    "\n",
    "#A partir do Matplotlib.Ticker, Importar Formatador:\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#Definir os Valores das 5 Métricas de Avaliação (Exatidão, Sensibilidade, Precisão, AUC e F1):\n",
    "exatidao = [0.74, 0.76, 0.72, 0.75, 0.81, 0.78]\n",
    "sensibilidade = [0.73, 0.82, 0.71, 0.72, 0.70, 0.76]\n",
    "precisao = [0.44, 0.47, 0.42, 0.45, 0.56, 0.50]\n",
    "auc = [0.81, 0.86, 0.80, 0.81, 0.86, 0.86]\n",
    "f1 = [0.55, 0.60, 0.53, 0.56, 0.62, 0.60]\n",
    "\n",
    "#Criar uma Matriz NumPy para Estruturar as 5 Métricas de Avaliação:\n",
    "valores = numpy.array([exatidao, sensibilidade, precisao, auc, f1])\n",
    "\n",
    "#Transpor a Matriz:\n",
    "valores = valores.T\n",
    "\n",
    "#Configurações do Gráfico - Figura - Tamanho:\n",
    "matplotlib.pyplot.figure(figsize=(14, 7))\n",
    "\n",
    "#Configurações do Gráfico - Título Geral - Designação, Tamanho, Espaçamento e Cor:\n",
    "matplotlib.pyplot.title('Conjunto de Dados 1 - Conjunto de Teste\\n\\nComparação das Métricas de Avaliação dos Melhores Modelos de Classificação\\n', fontsize=16, pad=25, color='black')\n",
    "\n",
    "#Ajustar o Layout:\n",
    "matplotlib.pyplot.tight_layout()\n",
    "\n",
    "#Configurações das Barras - Largura e Cores:\n",
    "largura_barras = 0.15\n",
    "cores_barras = ['#ff7f0e', '#ffdd57', '#2ca02c', '#87CEEB', '#9467bd', '#f15a22']\n",
    "\n",
    "#Definir os Rótulos das 5 Métricas de Avaliação:\n",
    "metricas_avaliacao = ['Exatidão', 'Sensibilidade', 'Precisão', 'AUC', 'F1']\n",
    "\n",
    "#Definir os Rótulos dos Modelos:\n",
    "modelos = ['Naïve Bayes', 'KNN', 'Árvores de Decisão', 'Florestas Aleatórias', 'Gradient Boosting', 'Percetrão Multicamadas']\n",
    "\n",
    "#Definir os Índices do Eixo Horizontal:\n",
    "indice_eixo_horizontal = numpy.arange(len(metricas_avaliacao)) * 1.5\n",
    "\n",
    "#Definir os Deslocamentos Horizontal e Vertical para Posicionar os Valores Numéricos Acima das Barras:\n",
    "deslocamento_horizontal = [-0.03, -0.02, 0.0, -0.04, 0.0, 0.03]\n",
    "deslocamento_vertical = [0.0, 0., 0.01, 0.0, 0.01, 0.0]\n",
    "\n",
    "#Iterar sobre cada Modelo para Representar as Barras:\n",
    "for i in range(len(modelos)):\n",
    "    matplotlib.pyplot.bar(indice_eixo_horizontal + i * largura_barras, valores[i], largura_barras, label=modelos[i], color=cores_barras[i], zorder=3)\n",
    "\n",
    "#Iterar sobre cada Modelo para Adicionar os Valores Numéricos:\n",
    "for i in range(len(modelos)):\n",
    "\n",
    "    #Iterar sobre cada Métrica de Avaliação para Posicionar os Valores Numéricos Acima das Barras:\n",
    "    for j in range(len(metricas_avaliacao)):\n",
    "\n",
    "        #Configurações dos Valores Numéricos - Posição, Cor e Tamanho:\n",
    "        matplotlib.pyplot.text(indice_eixo_horizontal[j] + i * largura_barras + deslocamento_horizontal[i], valores[i][j] + deslocamento_vertical[i], f'{valores[i][j]:.2f}',\n",
    "            ha='center', va='bottom', color='black', fontsize=10)\n",
    "\n",
    "#Configurações do Eixo X - Rótulo, Tamanhos, Espaçamento, Cores, Rotação e Posição:\n",
    "matplotlib.pyplot.xlabel('Métricas de Avaliação', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.xticks(indice_eixo_horizontal + largura_barras * (len(modelos) - 1) / 2, metricas_avaliacao, fontsize=14, rotation=0, ha='center', color='black')\n",
    "\n",
    "#Configurações do Eixo Y - Rótulo, Tamanhos, Espaçamento, Cores, Limites Mínimo e Máximo e Formatações:\n",
    "matplotlib.pyplot.ylabel('Valor da Métrica', fontsize=14, labelpad=15, color='black')\n",
    "matplotlib.pyplot.tick_params(axis='y', colors='black', labelsize=10)\n",
    "matplotlib.pyplot.ylim(0, 1.00)\n",
    "matplotlib.pyplot.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "#Configurações das Margens dos Eixos - Cor e Espessura:\n",
    "eixo_atual = matplotlib.pyplot.gca()\n",
    "eixo_atual.spines['bottom'].set(color='black', linewidth=2.5)\n",
    "eixo_atual.spines['left'].set(color='black', linewidth=2.5)\n",
    "eixo_atual.spines['top'].set_visible(False)\n",
    "eixo_atual.spines['right'].set_visible(False)\n",
    "\n",
    "#Configurações da Legenda de Cores - Posição, Tamanho e Cores:\n",
    "matplotlib.pyplot.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=10, frameon=True, facecolor='none', edgecolor='grey', labelcolor='black')\n",
    "\n",
    "#Resultados - Exibir o Gráfico:\n",
    "matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
